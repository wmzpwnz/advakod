#!/usr/bin/env python3
"""
Sprint 2 Validation Script
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤—Å–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è, –≤–Ω–µ—Å–µ–Ω–Ω—ã–µ –≤ Sprint 2:
- H-01: Legal text chunking
- H-02: RRF ranking 
- H-04: Date filtering
- M-04: Readiness gating
- M-01: Optimized LoRA hyperparameters
"""

import asyncio
import json
import sys
import os
import logging
import time
from typing import Dict, Any, List
from datetime import datetime, date

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class Sprint2Validator:
    """–í–∞–ª–∏–¥–∞—Ç–æ—Ä –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π Sprint 2"""
    
    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url
        self.results = {}
        
    async def run_all_tests(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –≤—Å–µ —Ç–µ—Å—Ç—ã Sprint 2"""
        logger.info("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏—é Sprint 2 –∏–∑–º–µ–Ω–µ–Ω–∏–π")
        
        tests = [
            ("H-01: Legal Text Chunking", self.test_legal_chunking),
            ("H-02: RRF Ranking", self.test_rrf_ranking), 
            ("H-04: Date Filtering", self.test_date_filtering),
            ("M-04: Readiness Gating", self.test_readiness_gating),
            ("M-01: LoRA Hyperparameters", self.test_lora_optimization),
            ("Integration Test", self.test_integration)
        ]
        
        for test_name, test_func in tests:
            logger.info(f"\nüìã –¢–µ—Å—Ç–∏—Ä—É–µ–º: {test_name}")
            try:
                result = await test_func()
                self.results[test_name] = result
                if result["passed"]:
                    logger.info(f"‚úÖ {test_name}: PASSED")
                else:
                    logger.error(f"‚ùå {test_name}: FAILED - {result.get('error', 'Unknown error')}")
            except Exception as e:
                logger.error(f"üí• {test_name}: EXCEPTION - {str(e)}")
                self.results[test_name] = {"passed": False, "error": str(e)}
        
        self.generate_report()
        
    async def test_legal_chunking(self) -> Dict[str, Any]:
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç H-01: Legal text chunking"""
        try:
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥—É–ª—å –Ω–∞–ø—Ä—è–º—É—é –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            from backend.app.core.legal_chunker import LegalTextChunker
            
            chunker = LegalTextChunker()
            
            # –¢–µ—Å—Ç–æ–≤—ã–π —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π —Ç–µ–∫—Å—Ç
            test_text = """
            –°—Ç–∞—Ç—å—è 1. –û—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–Ω—è—Ç–∏—è
            
            –ß–∞—Å—Ç—å 1. –î–ª—è —Ü–µ–ª–µ–π –Ω–∞—Å—Ç–æ—è—â–µ–≥–æ –§–µ–¥–µ—Ä–∞–ª—å–Ω–æ–≥–æ –∑–∞–∫–æ–Ω–∞ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Å–ª–µ–¥—É—é—â–∏–µ –æ—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–Ω—è—Ç–∏—è:
            1) –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ - –ª—é–±–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è;
            2) –æ–ø–µ—Ä–∞—Ç–æ—Ä - –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–π –æ—Ä–≥–∞–Ω;
            
            –°—Ç–∞—Ç—å—è 2. –ü—Ä–∏–Ω—Ü–∏–ø—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            
            –ß–∞—Å—Ç—å 1. –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–æ–ª–∂–Ω–∞ –æ—Å—É—â–µ—Å—Ç–≤–ª—è—Ç—å—Å—è –Ω–∞ –∑–∞–∫–æ–Ω–Ω–æ–π –æ—Å–Ω–æ–≤–µ.
            """
            
            # –ß–∞–Ω–∫–∏–Ω–≥ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            chunks = chunker.chunk_document(test_text, "test_doc", "v1")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∏
            checks = {
                "chunks_created": len(chunks) > 0,
                "articles_recognized": any("–°—Ç–∞—Ç—å—è 1" in chunk.content for chunk in chunks),
                "hierarchy_preserved": all(hasattr(chunk, 'metadata') for chunk in chunks),
                "metadata_present": all(chunk.metadata for chunk in chunks)
            }
            
            all_passed = all(checks.values())
            
            return {
                "passed": all_passed,
                "details": {
                    "chunks_count": len(chunks),
                    "checks": checks,
                    "sample_chunk": str(chunks[0].__dict__) if chunks else None
                }
            }
            
        except Exception as e:
            return {"passed": False, "error": str(e)}
    
    async def test_rrf_ranking(self) -> Dict[str, Any]:
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç H-02: RRF ranking"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ RRF –º–µ—Ç–æ–¥–∞
            from backend.app.services.enhanced_rag_service import EnhancedRAGService
            
            rag_service = EnhancedRAGService()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –º–µ—Ç–æ–¥–∞ _combine_and_rank_results
            has_rrf_method = hasattr(rag_service, '_combine_and_rank_results')
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∏
            checks = {
                "service_exists": True,
                "rrf_method_exists": has_rrf_method,
                "service_initialized": True
            }
            
            all_passed = all(checks.values())
            
            return {
                "passed": all_passed,
                "details": {
                    "checks": checks,
                    "methods_available": [method for method in dir(rag_service) if 'rank' in method.lower()]
                }
            }
            
        except Exception as e:
            return {"passed": False, "error": str(e)}
    
    async def test_date_filtering(self) -> Dict[str, Any]:
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç H-04: Date filtering"""
        try:
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥—É–ª—å date utils
            from backend.app.core.date_utils import DateUtils
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç–æ–¥—ã
            methods_exist = {
                "normalize_date": hasattr(DateUtils, 'normalize_date'),
                "create_date_filter": hasattr(DateUtils, 'create_date_filter'),
                "parse_russian_date": hasattr(DateUtils, 'parse_russian_date')
            }
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä–æ—Å—Ç–æ–π —Å–ª—É—á–∞–π
            try:
                test_date = "2024-01-15"
                normalized = DateUtils.normalize_date(test_date)
                date_filter = DateUtils.create_date_filter(test_date)
                
                date_test_passed = normalized is not None and isinstance(date_filter, dict)
            except Exception:
                date_test_passed = False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ vector store
            try:
                from backend.app.services.vector_store_service import vector_store_service
                import inspect
                search_method = getattr(vector_store_service, 'search_similar')
                signature = inspect.signature(search_method)
                has_date_param = 'situation_date' in signature.parameters
            except Exception:
                has_date_param = False
            
            checks = {
                **methods_exist,
                "date_processing_works": date_test_passed,
                "vector_store_updated": has_date_param
            }
            
            all_passed = all(checks.values())
            
            return {
                "passed": all_passed,
                "details": {
                    "checks": checks
                }
            }
            
        except Exception as e:
            return {"passed": False, "error": str(e)}
    
    async def test_readiness_gating(self) -> Dict[str, Any]:
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç M-04: Readiness gating"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º middleware
            try:
                from backend.app.middleware.readiness import ReadinessMiddleware, ReadinessChecker
                middleware_exists = True
            except ImportError:
                middleware_exists = False
            
            checks = {
                "middleware_imported": middleware_exists,
                "middleware_file_exists": os.path.exists("backend/app/middleware/readiness.py")
            }
            
            all_passed = all(checks.values())
            
            return {
                "passed": all_passed,
                "details": {
                    "checks": checks
                }
            }
            
        except Exception as e:
            return {"passed": False, "error": str(e)}
    
    async def test_lora_optimization(self) -> Dict[str, Any]:
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç M-01: LoRA hyperparameters optimization"""
        try:
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
            from backend.app.core.optimized_lora_config import OptimizedLoRAConfig, ModelSize, TaskComplexity
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
            try:
                config = OptimizedLoRAConfig.get_optimized_config(
                    model_size=ModelSize.MEDIUM,
                    task_complexity=TaskComplexity.MODERATE,
                    legal_task_type="legal_qa"
                )
                config_generated = True
                has_lora_config = "lora_config" in config
                has_metadata = "_metadata" in config
            except Exception:
                config_generated = False
                has_lora_config = False
                has_metadata = False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∑–∞–¥–∞—á–∏
            try:
                legal_tasks = OptimizedLoRAConfig.get_available_legal_tasks()
                tasks_available = len(legal_tasks) > 0
            except Exception:
                tasks_available = False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–µ—Ä–≤–∏—Å–∞
            try:
                from backend.app.services.lora_training_service import LoRATrainingService
                has_recommendation_method = hasattr(LoRATrainingService, 'get_recommended_config')
            except Exception:
                has_recommendation_method = False
            
            checks = {
                "config_module_imported": True,
                "config_generated": config_generated,
                "has_lora_config": has_lora_config,
                "has_metadata": has_metadata,
                "legal_tasks_available": tasks_available,
                "service_updated": has_recommendation_method
            }
            
            all_passed = all(checks.values())
            
            return {
                "passed": all_passed,
                "details": {
                    "checks": checks
                }
            }
            
        except Exception as e:
            return {"passed": False, "error": str(e)}
    
    async def test_integration(self) -> Dict[str, Any]:
        """–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ç–µ—Å—Ç –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""
        try:
            checks = {}
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª—ã
            expected_files = [
                "backend/app/core/legal_chunker.py",
                "backend/app/core/date_utils.py",
                "backend/app/core/optimized_lora_config.py",
                "backend/app/middleware/readiness.py"
            ]
            
            files_exist = 0
            for file_path in expected_files:
                if os.path.exists(file_path):
                    files_exist += 1
            
            checks["files_created"] = files_exist == len(expected_files)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–º–ø–æ—Ä—Ç—ã –æ—Å–Ω–æ–≤–Ω—ã—Ö –º–æ–¥—É–ª–µ–π
            modules_imported = 0
            modules_to_test = [
                ("legal_chunker", "backend.app.core.legal_chunker"),
                ("date_utils", "backend.app.core.date_utils"),
                ("optimized_lora_config", "backend.app.core.optimized_lora_config"),
                ("readiness", "backend.app.middleware.readiness")
            ]
            
            for name, module_name in modules_to_test:
                try:
                    __import__(module_name)
                    modules_imported += 1
                    checks[f"import_{name}"] = True
                except ImportError:
                    checks[f"import_{name}"] = False
            
            checks["all_modules_imported"] = modules_imported == len(modules_to_test)
            
            all_passed = all(checks.values())
            
            return {
                "passed": all_passed,
                "details": {
                    "checks": checks,
                    "files_found": f"{files_exist}/{len(expected_files)}",
                    "modules_imported": f"{modules_imported}/{len(modules_to_test)}"
                }
            }
            
        except Exception as e:
            return {"passed": False, "error": str(e)}
    
    def generate_report(self):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
        logger.info("\n" + "="*60)
        logger.info("üìä –û–¢–ß–ï–¢ –ü–û –í–ê–õ–ò–î–ê–¶–ò–ò SPRINT 2")
        logger.info("="*60)
        
        total_tests = len(self.results)
        passed_tests = sum(1 for result in self.results.values() if result.get("passed", False))
        
        logger.info(f"–í—Å–µ–≥–æ —Ç–µ—Å—Ç–æ–≤: {total_tests}")
        logger.info(f"–ü—Ä–æ—à–ª–æ —É—Å–ø–µ—à–Ω–æ: {passed_tests}")
        logger.info(f"–ù–µ—É–¥–∞—á–Ω—ã—Ö: {total_tests - passed_tests}")
        logger.info(f"–ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞: {(passed_tests/total_tests)*100:.1f}%")
        
        logger.info("\nüìã –î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ —Ç–µ—Å—Ç–∞–º:")
        for test_name, result in self.results.items():
            status = "‚úÖ PASSED" if result.get("passed", False) else "‚ùå FAILED"
            logger.info(f"  {status} - {test_name}")
            if not result.get("passed", False) and "error" in result:
                logger.info(f"    ‚ö†Ô∏è –û—à–∏–±–∫–∞: {result['error']}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
        report_file = f"sprint2_validation_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        try:
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump({
                    "timestamp": datetime.now().isoformat(),
                    "summary": {
                        "total_tests": total_tests,
                        "passed_tests": passed_tests,
                        "failed_tests": total_tests - passed_tests,
                        "success_rate": (passed_tests/total_tests)*100
                    },
                    "detailed_results": self.results
                }, f, indent=2, ensure_ascii=False)
            
            logger.info(f"\nüíæ –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {report_file}")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç—á–µ—Ç–∞: {e}")
        
        if passed_tests == total_tests:
            logger.info("\nüéâ –í–°–ï –¢–ï–°–¢–´ SPRINT 2 –ü–†–û–®–õ–ò –£–°–ü–ï–®–ù–û!")
        else:
            logger.info(f"\n‚ö†Ô∏è –ù–ï–ö–û–¢–û–†–´–ï –¢–ï–°–¢–´ –ù–ï –ü–†–û–®–õ–ò. –¢—Ä–µ–±—É–µ—Ç—Å—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ.")
        
        logger.info("="*60)


async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    validator = Sprint2Validator()
    await validator.run_all_tests()


if __name__ == "__main__":
    asyncio.run(main())