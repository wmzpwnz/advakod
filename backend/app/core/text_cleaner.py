"""
–ú–æ–¥—É–ª—å –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ –∫–æ–¥–µ–∫—Å–æ–≤ –æ—Ç —Å–ª—É–∂–µ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
–£–¥–∞–ª—è–µ—Ç –¥–∞—Ç—ã —Ä–µ–¥–∞–∫—Ü–∏–π, —ç–ª–µ–º–µ–Ω—Ç—ã –Ω–∞–≤–∏–≥–∞—Ü–∏–∏, –º–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ –¥—Ä—É–≥–æ–π –º—É—Å–æ—Ä
"""

import re
import logging
from typing import List, Optional, Tuple

logger = logging.getLogger(__name__)


class LegalTextCleaner:
    """–ö–ª–∞—Å—Å –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ –ø—Ä–∞–≤–æ–≤—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –æ—Ç —Å–ª—É–∂–µ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"""
    
    def __init__(self):
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è —Å–ª—É–∂–µ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        self.service_patterns = [
            # –î–∞—Ç—ã —Ä–µ–¥–∞–∫—Ü–∏–π
            r'–Ω–µ–¥–µ–π—Å—Ç–≤—É—é—â–∞—è –Ω–∞ \d{2}\.\d{2}\.\d{4}',
            r'–Ω–µ –≤—Å—Ç—É–ø–∏–≤—à–∞—è –≤ —Å–∏–ª—É —Ä–µ–¥–∞–∫—Ü–∏—è –Ω–∞ \d{2}\.\d{2}\.\d{4}',
            r'–∞–∫—Ç—É–∞–ª—å–Ω–∞—è, –µ—Å—Ç—å –Ω–µ –≤—Å—Ç—É–ø–∏–≤—à–∏–µ –≤ —Å–∏–ª—É —Ä–µ–¥–∞–∫—Ü–∏–∏ –Ω–∞ \d{2}\.\d{2}\.\d{4}',
            r'—Ä–µ–¥–∞–∫—Ü–∏—è –Ω–∞ \d{2}\.\d{2}\.\d{4}',
            r'—Å \d{2}\.\d{2}\.\d{4}',
            r'–Ω–∞ \d{2}\.\d{2}\.\d{4}',
            
            # –≠–ª–µ–º–µ–Ω—Ç—ã –Ω–∞–≤–∏–≥–∞—Ü–∏–∏
            r'–ø–µ—á–∞—Ç—å —Ç–µ–∫—Å—Ç–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é',
            r'–ø–µ—á–∞—Ç—å –≤—ã–¥–µ–ª–µ–Ω–Ω–æ–≥–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞',
            r'a- a\+',
            r'a\+ a-',
            r'—Ñ–æ–Ω –¥–æ–∫—É–º–µ–Ω—Ç–∞',
            r'—Ä–∞–∑–º–µ—Ä —à—Ä–∏—Ñ—Ç–∞',
            r'—Å—Ç–∞–Ω–¥–∞—Ä—Ç',
            r'–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ',
            r'–æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–∏–µ',
            r'–≤—Ö–æ–¥—è—â–∏–µ —Å–≤—è–∑–∏',
            
            # –°–ª—É–∂–µ–±–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã
            r'–∑–∞–∫—Ä—ã—Ç—å',
            r'–æ—Ç–∫—Ä—ã—Ç—å',
            r'—Å–ø—Ä–∞–≤–∫–∞',
            r'–ø–æ–º–æ—â—å',
        ]
        
        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è —Å—Ç—Ä–æ–∫ (–ø–æ–ª–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ)
        self.service_keywords = [
            'cookie',
            'javascript',
            'css',
            'script',
            'style',
            '–Ω–∞–≤–∏–≥–∞—Ü–∏—è',
            '–º–µ–Ω—é',
            'footer',
            'header',
            'sidebar',
            '–∑–∞–∫—Ä—ã—Ç—å',
            '–æ—Ç–∫—Ä—ã—Ç—å',
            'a-',
            'a+',
            '—Ñ–æ–Ω –¥–æ–∫—É–º–µ–Ω—Ç–∞',
            '–±–µ–ª—ã–π',
            '—Å–µ—Ä—ã–π',
            '—Ä–∞–∑–º–µ—Ä —à—Ä–∏—Ñ—Ç–∞',
            '—Å—Ç–∞–Ω–¥–∞—Ä—Ç',
            '—Å–≤–∏–¥–µ—Ç–µ–ª—å—Å—Ç–≤–æ –æ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏',
            '–ø–µ—á–∞—Ç—å —Ç–µ–∫—Å—Ç–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é',
            '–ø–µ—á–∞—Ç—å –≤—ã–¥–µ–ª–µ–Ω–Ω–æ–≥–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞',
        ]
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –º–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –Ω–∞—á–∞–ª–µ —Ñ–∞–π–ª–∞
        self.metadata_patterns = [
            r'–î–µ–π—Å—Ç–≤—É–µ—Ç —Å –∏–∑–º–µ–Ω–µ–Ω–∏—è–º–∏.*?–ø–µ—á–∞—Ç—å —Ç–µ–∫—Å—Ç–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é',
            r'–ö–æ–¥–µ–∫—Å –†–æ—Å—Å–∏–π—Å–∫–æ–π –§–µ–¥–µ—Ä–∞—Ü–∏–∏ –æ—Ç.*?–ø–µ—á–∞—Ç—å —Ç–µ–∫—Å—Ç–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é',
            r'–§–µ–¥–µ—Ä–∞–ª—å–Ω—ã–π –∑–∞–∫–æ–Ω.*?–ø–µ—á–∞—Ç—å —Ç–µ–∫—Å—Ç–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é',
        ]
        
        # –ö–æ–º–ø–∏–ª–∏—Ä—É–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        self.compiled_patterns = [re.compile(pattern, re.IGNORECASE | re.DOTALL) 
                                 for pattern in self.service_patterns]
        self.compiled_metadata_patterns = [re.compile(pattern, re.IGNORECASE | re.DOTALL) 
                                          for pattern in self.metadata_patterns]
    
    def is_service_line(self, line: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Ç—Ä–æ–∫–∞ —Å–ª—É–∂–µ–±–Ω–æ–π"""
        if not line or len(line.strip()) < 2:
            return True
        
        line_lower = line.lower().strip()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–ª–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
        if line_lower in self.service_keywords:
            return True
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å—Ç—Ä–æ–∫–∏ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ —Å–ª—É–∂–µ–±–Ω—ã—Ö —Å–ª–æ–≤
        if len(line) < 20:
            for keyword in self.service_keywords:
                if keyword in line_lower:
                    return True
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        for pattern in self.compiled_patterns:
            if pattern.search(line):
                return True
        
        return False
    
    def remove_metadata_header(self, text: str) -> str:
        """–£–¥–∞–ª—è–µ—Ç –º–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –Ω–∞—á–∞–ª–∞ —Ñ–∞–π–ª–∞"""
        lines = text.split('\n')
        cleaned_lines = []
        skip_until_content = True
        
        for i, line in enumerate(lines):
            line_stripped = line.strip()
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –≤ –Ω–∞—á–∞–ª–µ
            if skip_until_content and not line_stripped:
                continue
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Ç—Ä–æ–∫–∞ –º–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
            is_metadata = False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –º–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
            for pattern in self.compiled_metadata_patterns:
                if pattern.search(line):
                    is_metadata = True
                    break
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ —Å –¥–∞—Ç–∞–º–∏ (–º–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ä–µ–¥–∞–∫—Ü–∏—è—Ö)
            if len(line_stripped) > 200 and any(
                '–Ω–µ–¥–µ–π—Å—Ç–≤—É—é—â–∞—è' in line_lower or 
                '—Ä–µ–¥–∞–∫—Ü–∏—è' in line_lower or 
                '–∞–∫—Ç—É–∞–ª—å–Ω–∞—è' in line_lower
                for line_lower in [line_stripped.lower()]
            ):
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ —Ä–µ–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç –∫–æ–¥–µ–∫—Å–∞
                if not any(keyword in line_stripped.lower() for keyword in 
                          ['—Å—Ç–∞—Ç—å—è', '–≥–ª–∞–≤–∞', '—Ä–∞–∑–¥–µ–ª', '—á–∞—Å—Ç—å', '–∫–æ–¥–µ–∫—Å']):
                    is_metadata = True
            
            if is_metadata:
                continue
            
            # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ –Ω–µ –º–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è, –Ω–∞—á–∏–Ω–∞–µ–º —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç
            if skip_until_content and line_stripped:
                skip_until_content = False
            
            if not skip_until_content:
                cleaned_lines.append(line)
        
        return '\n'.join(cleaned_lines)
    
    def clean_line(self, line: str) -> Optional[str]:
        """–û—á–∏—â–∞–µ—Ç –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É –æ—Ç —Å–ª—É–∂–µ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"""
        if not line:
            return None
        
        line_stripped = line.strip()
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
        if not line_stripped:
            return None
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–µ —Å—Ç—Ä–æ–∫–∏ (–º–µ–Ω–µ–µ 2 —Å–∏–º–≤–æ–ª–æ–≤)
        if len(line_stripped) < 2:
            return None
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
        if self.is_service_line(line_stripped):
            return None
        
        return line_stripped
    
    def clean_text(self, text: str, aggressive: bool = True) -> str:
        """
        –û—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –æ—Ç —Å–ª—É–∂–µ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        
        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            aggressive: –ï—Å–ª–∏ True, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—É—é –æ—á–∏—Å—Ç–∫—É (—É–¥–∞–ª—è–µ—Ç –º–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –Ω–∞—á–∞–ª–∞)
        
        Returns:
            –û—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        if not text:
            return ""
        
        original_length = len(text)
        
        # –®–ê–ì 1: –£–¥–∞–ª—è–µ–º –º–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –Ω–∞—á–∞–ª–∞ —Ñ–∞–π–ª–∞
        if aggressive:
            text = self.remove_metadata_header(text)
        
        # –®–ê–ì 2: –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å—Ç—Ä–æ–∫–∏ –∏ –æ—á–∏—â–∞–µ–º –∫–∞–∂–¥—É—é
        lines = text.split('\n')
        cleaned_lines = []
        
        for line in lines:
            cleaned_line = self.clean_line(line)
            if cleaned_line:
                cleaned_lines.append(cleaned_line)
        
        # –®–ê–ì 3: –û–±—ä–µ–¥–∏–Ω—è–µ–º –æ–±—Ä–∞—Ç–Ω–æ
        cleaned_text = '\n'.join(cleaned_lines)
        
        # –®–ê–ì 4: –£–¥–∞–ª—è–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ (–æ—Å—Ç–∞–≤–ª—è–µ–º –º–∞–∫—Å–∏–º—É–º 2 –ø–æ–¥—Ä—è–¥)
        cleaned_text = re.sub(r'\n{3,}', '\n\n', cleaned_text)
        
        # –®–ê–ì 5: –£–¥–∞–ª—è–µ–º –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ
        cleaned_text = cleaned_text.strip()
        
        final_length = len(cleaned_text)
        removed_chars = original_length - final_length
        
        if removed_chars > 0:
            logger.info(f"üßπ –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞: —É–¥–∞–ª–µ–Ω–æ {removed_chars} —Å–∏–º–≤–æ–ª–æ–≤ ({removed_chars/original_length*100:.1f}%)")
        
        return cleaned_text
    
    def clean_file(self, file_path: str, output_path: Optional[str] = None, aggressive: bool = True) -> str:
        """
        –û—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        
        Args:
            file_path: –ü—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É
            output_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (–µ—Å–ª–∏ None, –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç –∏—Å—Ö–æ–¥–Ω—ã–π)
            aggressive: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—É—é –æ—á–∏—Å—Ç–∫—É
        
        Returns:
            –ü—É—Ç—å –∫ –æ—á–∏—â–µ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
        """
        from pathlib import Path
        
        input_path = Path(file_path)
        
        if not input_path.exists():
            raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
        
        # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
        try:
            with open(input_path, 'r', encoding='utf-8') as f:
                text = f.read()
        except UnicodeDecodeError:
            # –ü—Ä–æ–±—É–µ–º –¥—Ä—É–≥–∏–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏
            for encoding in ['windows-1251', 'cp1251', 'iso-8859-1']:
                try:
                    with open(input_path, 'r', encoding=encoding) as f:
                        text = f.read()
                    break
                except:
                    continue
            else:
                raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª {file_path}")
        
        # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç
        cleaned_text = self.clean_text(text, aggressive=aggressive)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        if output_path:
            output_path_obj = Path(output_path)
        else:
            output_path_obj = input_path
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º
        output_path_obj.parent.mkdir(parents=True, exist_ok=True)
        with open(output_path_obj, 'w', encoding='utf-8') as f:
            f.write(cleaned_text)
        
        logger.info(f"‚úÖ –§–∞–π–ª –æ—á–∏—â–µ–Ω: {output_path_obj}")
        
        return str(output_path_obj)
    
    def clean_directory(self, directory: str, pattern: str = "*.txt", aggressive: bool = True) -> List[str]:
        """
        –û—á–∏—â–∞–µ—Ç –≤—Å–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        
        Args:
            directory: –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
            pattern: –®–∞–±–ª–æ–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ñ–∞–π–ª–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é *.txt)
            aggressive: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—É—é –æ—á–∏—Å—Ç–∫—É
        
        Returns:
            –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ –æ—á–∏—â–µ–Ω–Ω—ã–º —Ñ–∞–π–ª–∞–º
        """
        from pathlib import Path
        
        dir_path = Path(directory)
        if not dir_path.exists():
            raise FileNotFoundError(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {directory}")
        
        cleaned_files = []
        files = list(dir_path.glob(pattern))
        
        logger.info(f"üßπ –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ—á–∏—Å—Ç–∫–∏: {len(files)}")
        
        for file_path in files:
            try:
                cleaned_path = self.clean_file(str(file_path), aggressive=aggressive)
                cleaned_files.append(cleaned_path)
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ {file_path.name}: {e}")
        
        logger.info(f"‚úÖ –û—á–∏—â–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(cleaned_files)}/{len(files)}")
        
        return cleaned_files


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
legal_text_cleaner = LegalTextCleaner()


def clean_legal_text(text: str, aggressive: bool = True) -> str:
    """
    –£–¥–æ–±–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –æ—á–∏—Å—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞
    
    Args:
        text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
        aggressive: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—É—é –æ—á–∏—Å—Ç–∫—É
    
    Returns:
        –û—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
    """
    return legal_text_cleaner.clean_text(text, aggressive=aggressive)


def clean_legal_file(file_path: str, output_path: Optional[str] = None, aggressive: bool = True) -> str:
    """
    –£–¥–æ–±–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ —Ñ–∞–π–ª–∞
    
    Args:
        file_path: –ü—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É
        output_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (–µ—Å–ª–∏ None, –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç –∏—Å—Ö–æ–¥–Ω—ã–π)
        aggressive: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—É—é –æ—á–∏—Å—Ç–∫—É
    
    Returns:
        –ü—É—Ç—å –∫ –æ—á–∏—â–µ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
    """
    return legal_text_cleaner.clean_file(file_path, output_path, aggressive)


def clean_legal_directory(directory: str, pattern: str = "*.txt", aggressive: bool = True) -> List[str]:
    """
    –£–¥–æ–±–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    
    Args:
        directory: –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        pattern: –®–∞–±–ª–æ–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ñ–∞–π–ª–æ–≤
        aggressive: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—É—é –æ—á–∏—Å—Ç–∫—É
    
    Returns:
        –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ –æ—á–∏—â–µ–Ω–Ω—ã–º —Ñ–∞–π–ª–∞–º
    """
    return legal_text_cleaner.clean_directory(directory, pattern, aggressive)

