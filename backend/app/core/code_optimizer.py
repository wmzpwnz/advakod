"""
–°–µ—Ä–≤–∏—Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∫–æ–¥–∞ –∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
"""
import ast
import logging
import os
from typing import Dict, List, Any, Optional, Set
from pathlib import Path
import re


class CodeOptimizer:
    """–°–µ—Ä–≤–∏—Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∫–æ–¥–∞"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.duplicated_code = {}
        self.unused_imports = set()
        self.long_functions = []
        self.complex_functions = []
        self.todo_comments = []
    
    def analyze_codebase(self, root_path: str) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–¥–æ–≤—É—é –±–∞–∑—É –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        try:
            analysis_results = {
                "duplicated_code": self._find_duplicated_code(root_path),
                "unused_imports": self._find_unused_imports(root_path),
                "long_functions": self._find_long_functions(root_path),
                "complex_functions": self._find_complex_functions(root_path),
                "todo_comments": self._find_todo_comments(root_path),
                "missing_type_hints": self._find_missing_type_hints(root_path),
                "error_handling": self._analyze_error_handling(root_path)
            }
            
            self.logger.info("‚úÖ Code analysis completed successfully")
            return analysis_results
            
        except Exception as e:
            self.logger.error(f"‚ùå Code analysis failed: {e}")
            return {"error": str(e)}
    
    def _find_duplicated_code(self, root_path: str) -> Dict[str, List[str]]:
        """–ù–∞—Ö–æ–¥–∏—Ç –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–¥"""
        duplicated = {}
        file_contents = {}
        
        try:
            # –°–æ–±–∏—Ä–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –≤—Å–µ—Ö Python —Ñ–∞–π–ª–æ–≤
            for py_file in Path(root_path).rglob("*.py"):
                if "venv" in str(py_file) or "__pycache__" in str(py_file):
                    continue
                
                try:
                    with open(py_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                        file_contents[str(py_file)] = content
                except Exception:
                    continue
            
            # –ò—â–µ–º –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –±–ª–æ–∫–∏ –∫–æ–¥–∞
            for file1, content1 in file_contents.items():
                for file2, content2 in file_contents.items():
                    if file1 >= file2:  # –ò–∑–±–µ–≥–∞–µ–º –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è
                        continue
                    
                    # –ò—â–µ–º –æ–±—â–∏–µ —Å—Ç—Ä–æ–∫–∏ –¥–ª–∏–Ω–Ω–µ–µ 5 —Å–∏–º–≤–æ–ª–æ–≤
                    lines1 = content1.split('\n')
                    lines2 = content2.split('\n')
                    
                    common_lines = set(lines1) & set(lines2)
                    common_lines = {line.strip() for line in common_lines if len(line.strip()) > 5}
                    
                    if len(common_lines) > 3:  # –ï—Å–ª–∏ –±–æ–ª—å—à–µ 3 –æ–±—â–∏—Ö —Å—Ç—Ä–æ–∫
                        key = f"{file1} <-> {file2}"
                        duplicated[key] = list(common_lines)[:10]  # –ü–µ—Ä–≤—ã–µ 10 –æ–±—â–∏—Ö —Å—Ç—Ä–æ–∫
            
            return duplicated
            
        except Exception as e:
            self.logger.error(f"Failed to find duplicated code: {e}")
            return {}
    
    def _find_unused_imports(self, root_path: str) -> Dict[str, List[str]]:
        """–ù–∞—Ö–æ–¥–∏—Ç –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –∏–º–ø–æ—Ä—Ç—ã"""
        unused = {}
        
        try:
            for py_file in Path(root_path).rglob("*.py"):
                if "venv" in str(py_file) or "__pycache__" in str(py_file):
                    continue
                
                try:
                    with open(py_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    tree = ast.parse(content)
                    imports = []
                    used_names = set()
                    
                    # –°–æ–±–∏—Ä–∞–µ–º –∏–º–ø–æ—Ä—Ç—ã –∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –∏–º–µ–Ω–∞
                    for node in ast.walk(tree):
                        if isinstance(node, ast.Import):
                            for alias in node.names:
                                imports.append(alias.name)
                        elif isinstance(node, ast.ImportFrom):
                            if node.module:
                                for alias in node.names:
                                    imports.append(alias.name)
                        elif isinstance(node, ast.Name):
                            used_names.add(node.id)
                        elif isinstance(node, ast.Attribute):
                            used_names.add(node.attr)
                    
                    # –ù–∞—Ö–æ–¥–∏–º –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –∏–º–ø–æ—Ä—Ç—ã
                    unused_imports = [imp for imp in imports if imp not in used_names]
                    if unused_imports:
                        unused[str(py_file)] = unused_imports
                
                except Exception:
                    continue
            
            return unused
            
        except Exception as e:
            self.logger.error(f"Failed to find unused imports: {e}")
            return {}
    
    def _find_long_functions(self, root_path: str) -> List[Dict[str, Any]]:
        """–ù–∞—Ö–æ–¥–∏—Ç –¥–ª–∏–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏"""
        long_functions = []
        
        try:
            for py_file in Path(root_path).rglob("*.py"):
                if "venv" in str(py_file) or "__pycache__" in str(py_file):
                    continue
                
                try:
                    with open(py_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    tree = ast.parse(content)
                    
                    for node in ast.walk(tree):
                        if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –≤ —Ñ—É–Ω–∫—Ü–∏–∏
                            func_lines = content.split('\n')[node.lineno-1:node.end_lineno]
                            func_lines = [line for line in func_lines if line.strip() and not line.strip().startswith('#')]
                            
                            if len(func_lines) > 50:  # –§—É–Ω–∫—Ü–∏–∏ –¥–ª–∏–Ω–Ω–µ–µ 50 —Å—Ç—Ä–æ–∫
                                long_functions.append({
                                    "file": str(py_file),
                                    "function": node.name,
                                    "lines": len(func_lines),
                                    "line_number": node.lineno
                                })
                
                except Exception:
                    continue
            
            return long_functions
            
        except Exception as e:
            self.logger.error(f"Failed to find long functions: {e}")
            return []
    
    def _find_complex_functions(self, root_path: str) -> List[Dict[str, Any]]:
        """–ù–∞—Ö–æ–¥–∏—Ç —Å–ª–æ–∂–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ (–≤—ã—Å–æ–∫–∞—è —Ü–∏–∫–ª–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å)"""
        complex_functions = []
        
        try:
            for py_file in Path(root_path).rglob("*.py"):
                if "venv" in str(py_file) or "__pycache__" in str(py_file):
                    continue
                
                try:
                    with open(py_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    tree = ast.parse(content)
                    
                    for node in ast.walk(tree):
                        if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                            complexity = self._calculate_complexity(node)
                            
                            if complexity > 10:  # –°–ª–æ–∂–Ω–æ—Å—Ç—å –±–æ–ª—å—à–µ 10
                                complex_functions.append({
                                    "file": str(py_file),
                                    "function": node.name,
                                    "complexity": complexity,
                                    "line_number": node.lineno
                                })
                
                except Exception:
                    continue
            
            return complex_functions
            
        except Exception as e:
            self.logger.error(f"Failed to find complex functions: {e}")
            return []
    
    def _calculate_complexity(self, node: ast.AST) -> int:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Ü–∏–∫–ª–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é —Å–ª–æ–∂–Ω–æ—Å—Ç—å"""
        complexity = 1  # –ë–∞–∑–æ–≤–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å
        
        for child in ast.walk(node):
            if isinstance(child, (ast.If, ast.While, ast.For, ast.AsyncFor, ast.ExceptHandler)):
                complexity += 1
            elif isinstance(child, ast.BoolOp):
                complexity += len(child.values) - 1
        
        return complexity
    
    def _find_todo_comments(self, root_path: str) -> List[Dict[str, Any]]:
        """–ù–∞—Ö–æ–¥–∏—Ç TODO –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏"""
        todos = []
        
        try:
            for py_file in Path(root_path).rglob("*.py"):
                if "venv" in str(py_file) or "__pycache__" in str(py_file):
                    continue
                
                try:
                    with open(py_file, 'r', encoding='utf-8') as f:
                        lines = f.readlines()
                    
                    for i, line in enumerate(lines, 1):
                        if re.search(r'#\s*(TODO|FIXME|HACK|XXX|BUG)', line, re.IGNORECASE):
                            todos.append({
                                "file": str(py_file),
                                "line_number": i,
                                "content": line.strip(),
                                "type": re.search(r'(TODO|FIXME|HACK|XXX|BUG)', line, re.IGNORECASE).group(1).upper()
                            })
                
                except Exception:
                    continue
            
            return todos
            
        except Exception as e:
            self.logger.error(f"Failed to find TODO comments: {e}")
            return []
    
    def _find_missing_type_hints(self, root_path: str) -> List[Dict[str, Any]]:
        """–ù–∞—Ö–æ–¥–∏—Ç —Ñ—É–Ω–∫—Ü–∏–∏ –±–µ–∑ type hints"""
        missing_hints = []
        
        try:
            for py_file in Path(root_path).rglob("*.py"):
                if "venv" in str(py_file) or "__pycache__" in str(py_file):
                    continue
                
                try:
                    with open(py_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    tree = ast.parse(content)
                    
                    for node in ast.walk(tree):
                        if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ type hints
                            has_return_annotation = node.returns is not None
                            has_args_annotations = all(arg.annotation is not None for arg in node.args.args)
                            
                            if not has_return_annotation or not has_args_annotations:
                                missing_hints.append({
                                    "file": str(py_file),
                                    "function": node.name,
                                    "line_number": node.lineno,
                                    "missing_return": not has_return_annotation,
                                    "missing_args": not has_args_annotations
                                })
                
                except Exception:
                    continue
            
            return missing_hints
            
        except Exception as e:
            self.logger.error(f"Failed to find missing type hints: {e}")
            return []
    
    def _analyze_error_handling(self, root_path: str) -> List[Dict[str, Any]]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—à–∏–±–æ–∫"""
        error_analysis = []
        
        try:
            for py_file in Path(root_path).rglob("*.py"):
                if "venv" in str(py_file) or "__pycache__" in str(py_file):
                    continue
                
                try:
                    with open(py_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    tree = ast.parse(content)
                    
                    for node in ast.walk(tree):
                        if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                            # –ò—â–µ–º try-except –±–ª–æ–∫–∏
                            has_try_except = any(isinstance(child, ast.Try) for child in ast.walk(node))
                            
                            # –ò—â–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ –±–µ–∑ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫
                            if not has_try_except and len(list(ast.walk(node))) > 10:  # –§—É–Ω–∫—Ü–∏–∏ —Å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–π —Å–ª–æ–∂–Ω–æ—Å—Ç—å—é
                                error_analysis.append({
                                    "file": str(py_file),
                                    "function": node.name,
                                    "line_number": node.lineno,
                                    "has_error_handling": has_try_except
                                })
                
                except Exception:
                    continue
            
            return error_analysis
            
        except Exception as e:
            self.logger.error(f"Failed to analyze error handling: {e}")
            return []
    
    def generate_optimization_report(self, analysis_results: Dict[str, Any]) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        report = []
        report.append("# –û—Ç—á–µ—Ç –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∫–æ–¥–∞\n")
        
        # –î—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–¥
        if analysis_results.get("duplicated_code"):
            report.append("## üîÑ –î—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–¥")
            report.append(f"–ù–∞–π–¥–µ–Ω–æ {len(analysis_results['duplicated_code'])} –ø–∞—Ä —Ñ–∞–π–ª–æ–≤ —Å –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –∫–æ–¥–æ–º:\n")
            for files, lines in analysis_results["duplicated_code"].items():
                report.append(f"- {files}")
                report.append(f"  –û–±—â–∏–µ —Å—Ç—Ä–æ–∫–∏: {len(lines)}")
            report.append("")
        
        # –ù–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –∏–º–ø–æ—Ä—Ç—ã
        if analysis_results.get("unused_imports"):
            report.append("## üì¶ –ù–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –∏–º–ø–æ—Ä—Ç—ã")
            report.append(f"–ù–∞–π–¥–µ–Ω–æ {len(analysis_results['unused_imports'])} —Ñ–∞–π–ª–æ–≤ —Å –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–º–∏ –∏–º–ø–æ—Ä—Ç–∞–º–∏:\n")
            for file, imports in analysis_results["unused_imports"].items():
                report.append(f"- {file}: {', '.join(imports)}")
            report.append("")
        
        # –î–ª–∏–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
        if analysis_results.get("long_functions"):
            report.append("## üìè –î–ª–∏–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏")
            report.append(f"–ù–∞–π–¥–µ–Ω–æ {len(analysis_results['long_functions'])} —Ñ—É–Ω–∫—Ü–∏–π –¥–ª–∏–Ω–Ω–µ–µ 50 —Å—Ç—Ä–æ–∫:\n")
            for func in analysis_results["long_functions"]:
                report.append(f"- {func['file']}:{func['line_number']} {func['function']} ({func['lines']} —Å—Ç—Ä–æ–∫)")
            report.append("")
        
        # –°–ª–æ–∂–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
        if analysis_results.get("complex_functions"):
            report.append("## üß© –°–ª–æ–∂–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏")
            report.append(f"–ù–∞–π–¥–µ–Ω–æ {len(analysis_results['complex_functions'])} —Ñ—É–Ω–∫—Ü–∏–π —Å –≤—ã—Å–æ–∫–æ–π —Å–ª–æ–∂–Ω–æ—Å—Ç—å—é:\n")
            for func in analysis_results["complex_functions"]:
                report.append(f"- {func['file']}:{func['line_number']} {func['function']} (—Å–ª–æ–∂–Ω–æ—Å—Ç—å: {func['complexity']})")
            report.append("")
        
        # TODO –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
        if analysis_results.get("todo_comments"):
            report.append("## üìù TODO –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏")
            report.append(f"–ù–∞–π–¥–µ–Ω–æ {len(analysis_results['todo_comments'])} TODO –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤:\n")
            for todo in analysis_results["todo_comments"][:20]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 20
                report.append(f"- {todo['file']}:{todo['line_number']} [{todo['type']}] {todo['content']}")
            if len(analysis_results["todo_comments"]) > 20:
                report.append(f"... –∏ –µ—â–µ {len(analysis_results['todo_comments']) - 20}")
            report.append("")
        
        # –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ type hints
        if analysis_results.get("missing_type_hints"):
            report.append("## üè∑Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ type hints")
            report.append(f"–ù–∞–π–¥–µ–Ω–æ {len(analysis_results['missing_type_hints'])} —Ñ—É–Ω–∫—Ü–∏–π –±–µ–∑ type hints:\n")
            for func in analysis_results["missing_type_hints"][:10]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10
                missing = []
                if func["missing_return"]:
                    missing.append("return type")
                if func["missing_args"]:
                    missing.append("args types")
                report.append(f"- {func['file']}:{func['line_number']} {func['function']} (–æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç: {', '.join(missing)})")
            report.append("")
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫
        if analysis_results.get("error_handling"):
            no_error_handling = [f for f in analysis_results["error_handling"] if not f["has_error_handling"]]
            if no_error_handling:
                report.append("## ‚ö†Ô∏è –§—É–Ω–∫—Ü–∏–∏ –±–µ–∑ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫")
                report.append(f"–ù–∞–π–¥–µ–Ω–æ {len(no_error_handling)} —Ñ—É–Ω–∫—Ü–∏–π –±–µ–∑ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫:\n")
                for func in no_error_handling[:10]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10
                    report.append(f"- {func['file']}:{func['line_number']} {func['function']}")
                report.append("")
        
        return "\n".join(report)


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞ –∫–æ–¥–∞
code_optimizer = CodeOptimizer()
