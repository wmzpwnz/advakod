"""
API –¥–ª—è –∞–¥–º–∏–Ω –ø–∞–Ω–µ–ª–∏
–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏, –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏, –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–π –∏ —Å–∏—Å—Ç–µ–º–æ–π
"""

import logging
from fastapi import APIRouter, Depends, HTTPException, UploadFile, File, Form, Query, Request
from fastapi.responses import StreamingResponse
from sqlalchemy.orm import Session
from sqlalchemy import func
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
import json
import io
import os
import tempfile

from ..core.database import get_db
from ..models.user import User
from ..models.chat import ChatSession, ChatMessage
from ..models.audit_log import AuditLog, ActionType, SeverityLevel
from ..schemas.user import User as UserSchema, UserCreate
from ..schemas.admin import (
    UserUpdate, AdminDashboard, DocumentList, DocumentSearchResponse,
    AuditLogsResponse, UserAnalytics, FileUploadResponse
)
from ..services.auth_service import auth_service
from ..services.document_service import document_service
from ..services.vector_store_service import vector_store_service
from ..services.embeddings_service import embeddings_service
from ..services.rag_service import rag_service
from ..services.smart_document_processor import smart_document_processor
from ..services.audit_service import get_audit_service
from ..services.ai_document_validator import ai_document_validator
from ..services.document_versioning import document_versioning_service
from ..core.admin_security import get_secure_admin, require_admin_action_validation
from ..core.cache import cache_service

logger = logging.getLogger(__name__)

router = APIRouter()

def get_current_admin(current_user: User = Depends(auth_service.get_current_active_user)):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞"""
    if not current_user.is_admin:
        raise HTTPException(status_code=403, detail="Admin access required")
    return current_user

# ==================== –£–ü–†–ê–í–õ–ï–ù–ò–ï –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø–ú–ò ====================

@router.get("/users", response_model=List[UserSchema])
async def get_users(
    skip: int = Query(0, ge=0),
    limit: int = Query(100, ge=1, le=1000),
    search: Optional[str] = None,
    is_active: Optional[bool] = None,
    is_premium: Optional[bool] = None,
    is_admin: Optional[bool] = None,
    current_admin: User = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π"""
    try:
        query = db.query(User)
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è
        if search:
            query = query.filter(
                (User.username.contains(search)) |
                (User.email.contains(search)) |
                (User.full_name.contains(search))
            )
        
        if is_active is not None:
            query = query.filter(User.is_active == is_active)
        
        if is_premium is not None:
            query = query.filter(User.is_premium == is_premium)
            
        if is_admin is not None:
            query = query.filter(User.is_admin == is_admin)
        
        users = query.offset(skip).limit(limit).all()
        return users
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/users/{user_id}", response_model=UserSchema)
async def get_user(
    user_id: int,
    current_admin: User = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """–ü–æ–ª—É—á–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø–æ ID"""
    try:
        user = db.query(User).filter(User.id == user_id).first()
        if not user:
            raise HTTPException(status_code=404, detail="User not found")
        return user
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.put("/users/{user_id}", response_model=UserSchema)
async def update_user(
    user_id: int,
    user_update: UserUpdate,
    current_admin: User = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """–û–±–Ω–æ–≤–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    try:
        user = db.query(User).filter(User.id == user_id).first()
        if not user:
            raise HTTPException(status_code=404, detail="User not found")
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø–æ–ª—è
        update_data = user_update.dict(exclude_unset=True)
        for field, value in update_data.items():
            setattr(user, field, value)
        
        user.updated_at = datetime.utcnow()
        db.commit()
        db.refresh(user)
        
        # –õ–æ–≥–∏—Ä—É–µ–º –¥–µ–π—Å—Ç–≤–∏–µ
        audit_service = get_audit_service(db)
        audit_service.log_action(
            user_id=current_admin.id,
            action=ActionType.ADMIN_ACTION,
            resource="user",
            resource_id=str(user_id),
            description=f"Updated user {user.username}",
            details={"updated_fields": list(update_data.keys())}
        )
        
        return user
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.delete("/users/{user_id}")
@require_admin_action_validation("delete_user", "user")
async def delete_user(
    user_id: int,
    request: Request,
    current_admin: User = Depends(get_secure_admin),
    db: Session = Depends(get_db)
):
    """–£–¥–∞–ª–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–º—è–≥–∫–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ)"""
    try:
        user = db.query(User).filter(User.id == user_id).first()
        if not user:
            raise HTTPException(status_code=404, detail="User not found")
        
        # –ú—è–≥–∫–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ - –¥–µ–∞–∫—Ç–∏–≤–∏—Ä—É–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user.is_active = False
        user.updated_at = datetime.utcnow()
        db.commit()
        
        # –õ–æ–≥–∏—Ä—É–µ–º –¥–µ–π—Å—Ç–≤–∏–µ
        audit_service = get_audit_service(db)
        audit_service.log_action(
            user_id=current_admin.id,
            action=ActionType.ADMIN_ACTION,
            resource="user",
            resource_id=str(user_id),
            description=f"Deactivated user {user.username}",
            severity=SeverityLevel.HIGH
        )
        
        return {"message": "User deactivated successfully"}
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/users/{user_id}/toggle-admin")
async def toggle_admin_status(
    user_id: int,
    request: Request,
    current_admin: User = Depends(get_secure_admin),
    db: Session = Depends(get_db)
):
    """–ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞"""
    try:
        user = db.query(User).filter(User.id == user_id).first()
        if not user:
            raise HTTPException(status_code=404, detail="User not found")
        
        # –ù–µ–ª—å–∑—è —É–±—Ä–∞—Ç—å –ø—Ä–∞–≤–∞ –∞–¥–º–∏–Ω–∞ —É —Å–∞–º–æ–≥–æ —Å–µ–±—è
        if user_id == current_admin.id:
            raise HTTPException(status_code=400, detail="Cannot change your own admin status")
        
        user.is_admin = not user.is_admin
        user.updated_at = datetime.utcnow()
        db.commit()
        
        # –õ–æ–≥–∏—Ä—É–µ–º –¥–µ–π—Å—Ç–≤–∏–µ
        audit_service = get_audit_service(db)
        audit_service.log_action(
            user_id=current_admin.id,
            action=ActionType.ADMIN_ACTION,
            resource="user",
            resource_id=str(user_id),
            description=f"Toggled admin status for {user.username} to {user.is_admin}",
            severity=SeverityLevel.HIGH
        )
        
        return {
            "message": f"Admin status {'granted' if user.is_admin else 'revoked'}",
            "is_admin": user.is_admin
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞ –∞–¥–º–∏–Ω–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ==================== –ê–ù–ê–õ–ò–¢–ò–ö–ê –ò –°–¢–ê–¢–ò–°–¢–ò–ö–ê ====================

@router.get("/dashboard", response_model=AdminDashboard)
async def get_admin_dashboard(
    current_admin: User = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """–ü–æ–ª—É—á–∏—Ç—å –¥–∞—à–±–æ—Ä–¥ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞"""
    try:
        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        total_users = db.query(User).count()
        active_users = db.query(User).filter(User.is_active == True).count()
        premium_users = db.query(User).filter(User.is_premium == True).count()
        admin_users = db.query(User).filter(User.is_admin == True).count()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π
        thirty_days_ago = datetime.utcnow() - timedelta(days=30)
        new_users_30d = db.query(User).filter(User.created_at >= thirty_days_ago).count()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —á–∞—Ç–æ–≤
        total_sessions = db.query(ChatSession).count()
        total_messages = db.query(ChatMessage).count()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ RAG —Å–∏—Å—Ç–µ–º—ã
        rag_status = rag_service.get_status()
        vector_store_status = vector_store_service.get_status()
        
        return {
            "users": {
                "total": total_users,
                "active": active_users,
                "premium": premium_users,
                "admins": admin_users,
                "new_last_30d": new_users_30d
            },
            "chats": {
                "total_sessions": total_sessions,
                "total_messages": total_messages
            },
            "system": {
                "rag_status": rag_status,
                "vector_store_status": vector_store_status,
                "timestamp": datetime.utcnow().isoformat()
            }
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞—à–±–æ—Ä–¥–∞: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/analytics/users")
async def get_user_analytics(
    days: int = Query(30, ge=1, le=365),
    current_admin: User = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """–ü–æ–ª—É—á–∏—Ç—å –∞–Ω–∞–ª–∏—Ç–∏–∫—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"""
    try:
        end_date = datetime.utcnow()
        start_date = end_date - timedelta(days=days)
        
        # –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –¥–Ω—è–º
        daily_registrations = db.query(
            func.date(User.created_at).label('date'),
            func.count(User.id).label('count')
        ).filter(
            User.created_at >= start_date
        ).group_by(
            func.date(User.created_at)
        ).all()
        
        # –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ —Ç–∏–ø–∞–º –ø–æ–¥–ø–∏—Å–∫–∏
        subscription_stats = db.query(
            User.subscription_type,
            func.count(User.id).label('count')
        ).group_by(User.subscription_type).all()
        
        return {
            "period": {
                "start": start_date.isoformat(),
                "end": end_date.isoformat(),
                "days": days
            },
            "daily_registrations": [
                {"date": str(reg.date), "count": reg.count}
                for reg in daily_registrations
            ],
            "subscription_distribution": [
                {"type": stat.subscription_type, "count": stat.count}
                for stat in subscription_stats
            ]
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ==================== –£–ü–†–ê–í–õ–ï–ù–ò–ï –î–û–ö–£–ú–ï–ù–¢–ê–ú–ò ====================

@router.get("/documents")
async def get_documents(
    skip: int = Query(0, ge=0),
    limit: int = Query(100, ge=1, le=1000),
    current_admin: User = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ RAG —Å–∏—Å—Ç–µ–º–µ"""
    try:
        if not vector_store_service.is_ready():
            return {"documents": [], "total": 0, "message": "Vector store not ready"}
        
        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
        collection = vector_store_service.collection
        total_docs = collection.count()
        
        # –ü–æ–ª—É—á–∞–µ–º –í–°–ï –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
        results = collection.get(
            limit=total_docs,  # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
            include=['metadatas', 'documents']
        )
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —á–∞–Ω–∫–∏ –ø–æ document_id –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        documents_by_id = {}
        for i, (doc, meta) in enumerate(zip(results['documents'], results['metadatas'])):
            doc_id = meta.get('document_id', results['ids'][i])
            
            if doc_id not in documents_by_id:
                # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç
                documents_by_id[doc_id] = {
                    "id": doc_id,
                    "content": doc,
                    "metadata": meta,
                    "length": len(doc),
                    "chunks_count": 1,
                    "total_length": len(doc)
                }
            else:
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –¥–æ–∫—É–º–µ–Ω—Ç
                existing = documents_by_id[doc_id]
                existing["chunks_count"] += 1
                existing["total_length"] += len(doc)
                # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–∞ –±–æ–ª–µ–µ –¥–ª–∏–Ω–Ω—ã–π —á–∞–Ω–∫
                if len(doc) > len(existing["content"]):
                    existing["content"] = doc
                    existing["length"] = len(doc)
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å–ø–∏—Å–æ–∫ –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è
        documents = list(documents_by_id.values())
        documents.sort(key=lambda x: x['metadata'].get('added_at', ''), reverse=True)
        
        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ source_url –¥–ª—è URL –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        seen_urls = set()
        unique_documents = []
        for doc in documents:
            if doc['metadata'].get('source_type') == 'url':
                source_url = doc['metadata'].get('source_url', '')
                if source_url not in seen_urls:
                    seen_urls.add(source_url)
                    unique_documents.append(doc)
            else:
                unique_documents.append(doc)
        
        documents = unique_documents
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–∞–≥–∏–Ω–∞—Ü–∏—é
        total_unique_docs = len(documents)
        documents = documents[skip:skip + limit]
        
        return {
            "documents": documents,
            "total": total_unique_docs,
            "skip": skip,
            "limit": limit
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/documents/upload")
async def upload_document(
    file: UploadFile = File(...),
    description: Optional[str] = Form(None),
    current_admin: User = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç –≤ RAG —Å–∏—Å—Ç–µ–º—É"""
    try:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª –≤—Ä–µ–º–µ–Ω–Ω–æ
        
        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
        safe_filename = os.path.basename(file.filename) if file.filename else "unknown"
        safe_filename = "".join(c for c in safe_filename if c.isalnum() or c in ".-_")[:50]
        
        with tempfile.NamedTemporaryFile(delete=False, suffix=f"_{safe_filename}") as tmp_file:
            content = await file.read()
            tmp_file.write(content)
            tmp_file_path = tmp_file.name
        
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ñ–∞–π–ª–∞ –∏ —á–∏—Ç–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
            file_extension = os.path.splitext(file.filename)[1].lower() if file.filename else ''
            
            if file_extension == '.docx':
                # –î–ª—è DOCX —Ñ–∞–π–ª–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
                import docx
                try:
                    doc = docx.Document(tmp_file_path)
                    content = '\n'.join([paragraph.text for paragraph in doc.paragraphs])
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è DOCX —Ñ–∞–π–ª–∞: {e}")
                    # Fallback: —á–∏—Ç–∞–µ–º –∫–∞–∫ –±–∏–Ω–∞—Ä–Ω—ã–π —Ñ–∞–π–ª
                    with open(tmp_file_path, 'rb') as f:
                        content = f.read().decode('utf-8', errors='ignore')
            elif file_extension == '.pdf':
                # –î–ª—è PDF —Ñ–∞–π–ª–æ–≤
                try:
                    import PyPDF2
                    with open(tmp_file_path, 'rb') as f:
                        reader = PyPDF2.PdfReader(f)
                        content = '\n'.join([page.extract_text() for page in reader.pages])
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è PDF —Ñ–∞–π–ª–∞: {e}")
                    content = "–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑ PDF"
            else:
                # –î–ª—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤
                with open(tmp_file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—É—é –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—É—é —Å–∏—Å—Ç–µ–º—É –æ–±—Ä–∞–±–æ—Ç–∫–∏
            result = await smart_document_processor.process_document(
                file_path=file.filename,
                content=content
            )
            
            if result.get('success'):
                # –õ–æ–≥–∏—Ä—É–µ–º –¥–µ–π—Å—Ç–≤–∏–µ
                audit_service = get_audit_service(db)
                audit_service.log_action(
                    user_id=current_admin.id,
                    action=ActionType.ADMIN_ACTION,
                    resource="document",
                    resource_id=file.filename,
                    description=f"Uploaded document with smart processing: {file.filename}",
                    details={
                        "chunks_created": result.get('chunks_count', 0),
                        "articles_found": result.get('articles_count', 0),
                        "document_type": result.get('metadata', {}).get('document_type', 'unknown'),
                        "structure_score": result.get('metadata', {}).get('structure_score', 0)
                    }
                )
                
                return {
                    "success": True,
                    "message": "Document uploaded and analyzed successfully",
                    "details": result,
                    "chunks_created": result.get('chunks_count', 0),
                    "articles_found": result.get('articles_count', 0),
                    "sections_found": result.get('sections_count', 0),
                    "document_type": result.get('metadata', {}).get('document_type', 'unknown'),
                    "structure_score": result.get('metadata', {}).get('structure_score', 0),
                    "processing_time": result.get('processing_time', 0),
                    "filename": file.filename
                }
            else:
                return {
                    "success": False,
                    "message": "Failed to process document with smart analysis",
                    "error": result.get('error', 'Unknown error')
                }
                
        finally:
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            os.unlink(tmp_file_path)
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/documents/upload-url")
async def upload_document_from_url(
    request: dict,
    current_admin: User = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç –ø–æ URL"""
    try:
        url = request.get('url')
        if not url:
            raise HTTPException(status_code=400, detail="URL –Ω–µ —É–∫–∞–∑–∞–Ω")
            
        logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –ø–æ URL: {url}")
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è URL
        if not url.startswith(('http://', 'https://')):
            raise HTTPException(status_code=400, detail="–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π URL")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç –ø–æ URL
        result = await document_service.process_url(url)
        
        if result.get('success'):
            # –õ–æ–≥–∏—Ä—É–µ–º –¥–µ–π—Å—Ç–≤–∏–µ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞
            audit_service = get_audit_service(db)
            audit_service.log_action(
                user_id=current_admin.id,
                action=ActionType.ADMIN_ACTION,
                resource="document",
                resource_id=result.get('document_id', 'unknown'),
                description=f"Uploaded document from URL: {url}",
                details={"chunks_added": result.get('chunks_added', 0)}
            )
            
            return {
                "success": True,
                "message": "Document uploaded successfully from URL",
                "details": result,
                "chunks_added": result.get('chunks_added', 0),
                "document_type": result.get('document_type', 'unknown'),
                "validation_confidence": result.get('validation_confidence', 0),
                "legal_score": result.get('legal_score', 0),
                "text_length": result.get('text_length', 0),
                "file_hash": result.get('file_hash', ''),
                "document_id": result.get('document_id', ''),
                "source_url": url
            }
        else:
            return {
                "success": False,
                "message": "Failed to upload document from URL",
                "error": result.get('error')
            }
            
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –ø–æ URL: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/validation/status")
async def get_validation_status(
    current_admin: User = Depends(get_current_admin)
):
    """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    try:
        status = document_service.get_status()
        return {
            "success": True,
            "validation_method": status.get("validation_method", "unknown"),
            "available_methods": ["hybrid", "ai", "rules"],
            "hybrid_stats": status.get("hybrid_stats", {}),
            "ai_validator_stats": ai_document_validator.get_validation_stats()
        }
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/validation/method")
async def set_validation_method(
    method: str = Query(..., description="–ú–µ—Ç–æ–¥ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: hybrid, ai, rules, none"),
    current_admin: User = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """–ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å –º–µ—Ç–æ–¥ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    try:
        document_service.set_validation_method(method)
        
        # –õ–æ–≥–∏—Ä—É–µ–º –¥–µ–π—Å—Ç–≤–∏–µ
        audit_service = get_audit_service(db)
        audit_service.log_action(
            user_id=current_admin.id,
            action=ActionType.ADMIN_ACTION,
            resource="validation_method",
            resource_id="system",
            description=f"Changed validation method to: {method}",
            details={"validation_method": method}
        )
        
        method_names = {
            "hybrid": "–ì–∏–±—Ä–∏–¥–Ω—ã–π (–ø—Ä–∞–≤–∏–ª–∞ + AI)",
            "ai": "AI (Vistral-24B)",
            "rules": "–ü—Ä–∞–≤–∏–ª–∞ (–±—ã—Å—Ç—Ä—ã–π)"
        }
        
        return {
            "success": True,
            "message": f"–ú–µ—Ç–æ–¥ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏–∑–º–µ–Ω–µ–Ω –Ω–∞: {method_names.get(method, method)}",
            "validation_method": method
        }
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è –º–µ—Ç–æ–¥–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/validation/clear-cache")
async def clear_validation_cache(
    current_admin: User = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """–û—á–∏—Å—Ç–∏—Ç—å –∫—ç—à –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
    try:
        from ..services.hybrid_document_validator import hybrid_document_validator
        hybrid_document_validator.clear_cache()
        
        # –õ–æ–≥–∏—Ä—É–µ–º –¥–µ–π—Å—Ç–≤–∏–µ
        audit_service = get_audit_service(db)
        audit_service.log_action(
            user_id=current_admin.id,
            action=ActionType.ADMIN_ACTION,
            resource="validation_cache",
            resource_id="system",
            description="Cleared validation cache",
            details={}
        )
        
        return {
            "success": True,
            "message": "–ö—ç—à –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –æ—á–∏—â–µ–Ω"
        }
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –∫—ç—à–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/documents/versions")
async def get_document_versions(
    document_id: Optional[str] = Query(None, description="ID –¥–æ–∫—É–º–µ–Ω—Ç–∞ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤–µ—Ä—Å–∏–π"),
    current_admin: User = Depends(get_current_admin)
):
    """–ü–æ–ª—É—á–∏—Ç—å –≤–µ—Ä—Å–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    try:
        if document_id:
            # –ü–æ–ª—É—á–∏—Ç—å –≤–µ—Ä—Å–∏–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            versions = document_versioning_service.get_all_versions(document_id)
            current_version = document_versioning_service.get_current_version(document_id)
            
            return {
                "success": True,
                "document_id": document_id,
                "current_version": current_version.__dict__ if current_version else None,
                "all_versions": [v.__dict__ for v in versions]
            }
        else:
            # –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            stats = document_versioning_service.get_version_statistics()
            return {
                "success": True,
                "statistics": stats
            }
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –≤–µ—Ä—Å–∏–π –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/documents/current-versions")
async def get_current_versions(
    current_admin: User = Depends(get_current_admin)
):
    """–ü–æ–ª—É—á–∏—Ç—å —Ç–æ–ª—å–∫–æ —Ç–µ–∫—É—â–∏–µ –≤–µ—Ä—Å–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    try:
        # –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å –∏—Ö —Ç–µ–∫—É—â–∏–º–∏ –≤–µ—Ä—Å–∏—è–º–∏
        all_documents = {}
        for document_id in document_versioning_service.versions.keys():
            current_version = document_versioning_service.get_current_version(document_id)
            if current_version:
                all_documents[document_id] = current_version.__dict__
        
        return {
            "success": True,
            "current_versions": all_documents
        }
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–µ–∫—É—â–∏—Ö –≤–µ—Ä—Å–∏–π: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/documents/{document_id}/archive")
async def archive_document(
    document_id: str,
    current_admin: User = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """–ê—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç (–ø–æ–º–µ—Ç–∏—Ç—å –∫–∞–∫ —É—Å—Ç–∞—Ä–µ–≤—à–∏–π)"""
    try:
        # –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –≤–µ—Ä—Å–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        versions = document_versioning_service.get_all_versions(document_id)
        if not versions:
            raise HTTPException(status_code=404, detail="–î–æ–∫—É–º–µ–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        # –ü–æ–º–µ—Ç–∏—Ç—å –≤—Å–µ –≤–µ—Ä—Å–∏–∏ –∫–∞–∫ –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ
        for version in versions:
            version.status = "archived"
        
        # –õ–æ–≥–∏—Ä—É–µ–º –¥–µ–π—Å—Ç–≤–∏–µ
        audit_service = get_audit_service(db)
        audit_service.log_action(
            user_id=current_admin.id,
            action=ActionType.ADMIN_ACTION,
            resource="document",
            resource_id=document_id,
            description=f"Archived document {document_id}",
            details={"versions_archived": len(versions)}
        )
        
        return {
            "success": True,
            "message": f"–î–æ–∫—É–º–µ–Ω—Ç {document_id} –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω",
            "archived_versions": len(versions)
        }
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.delete("/documents/{document_id}")
async def delete_document(
    document_id: str,
    current_admin: User = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """–£–¥–∞–ª–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç –∏–∑ RAG —Å–∏—Å—Ç–µ–º—ã (—Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ —Å simple_expert_rag)"""
    try:
        if not vector_store_service.is_ready():
            raise HTTPException(status_code=503, detail="Vector store not ready")
        
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º simple_expert_rag
        from ..services.simple_expert_rag import simple_expert_rag
        
        # 1. –£–¥–∞–ª—è–µ–º –∏–∑ ChromaDB
        collection = vector_store_service.collection
        all_results = collection.get(include=['metadatas'])
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º —á–∞–Ω–∫–∏ –ø–æ document_id –∏–ª–∏ –ø–æ chunk_id
        matching_ids = []
        for i, metadata in enumerate(all_results['metadatas']):
            if metadata and (metadata.get('document_id') == document_id or all_results['ids'][i] == document_id):
                matching_ids.append(all_results['ids'][i])
        
        chromadb_chunks_deleted = 0
        if matching_ids:
            # –£–¥–∞–ª—è–µ–º –≤—Å–µ —á–∞–Ω–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏–∑ ChromaDB
            collection.delete(ids=matching_ids)
            chromadb_chunks_deleted = len(matching_ids)
            logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ –∏–∑ ChromaDB: {chromadb_chunks_deleted} —á–∞–Ω–∫–æ–≤")
        
        # 2. –£–¥–∞–ª—è–µ–º –∏–∑ simple_expert_rag
        # –ü—Ä–æ–±—É–µ–º —É–¥–∞–ª–∏—Ç—å –ø–æ document_id –∏ –ø–æ –≤—Å–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–º –∏–º–µ–Ω–∞–º —Ñ–∞–π–ª–æ–≤
        simple_rag_result = await simple_expert_rag.delete_document(document_id)
        simple_rag_chunks_deleted = simple_rag_result.get('chunks_deleted', 0)
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω –ø–æ document_id, –ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ø–æ –∏–º–µ–Ω–∞–º —Ñ–∞–π–ª–æ–≤ –≤ ChromaDB
        if simple_rag_chunks_deleted == 0 and matching_ids:
            # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
            for chunk_id in matching_ids:
                try:
                    chunk_results = collection.get(ids=[chunk_id], include=['metadatas'])
                    if chunk_results['metadatas'] and len(chunk_results['metadatas']) > 0:
                        chunk_metadata = chunk_results['metadatas'][0]
                        if chunk_metadata and 'filename' in chunk_metadata:
                            filename = chunk_metadata['filename']
                            # –ü—Ä–æ–±—É–µ–º —É–¥–∞–ª–∏—Ç—å –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
                            filename_result = await simple_expert_rag.delete_document(filename)
                            if filename_result.get('success', False):
                                simple_rag_chunks_deleted += filename_result.get('chunks_deleted', 0)
                                simple_rag_result = filename_result
                                break
                except Exception as e:
                    logger.warning(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–ª—è {chunk_id}: {e}")
                    continue
        
        if not simple_rag_result.get('success', False):
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –∏–∑ simple_expert_rag: {simple_rag_result.get('error', 'Unknown error')}")
        
        # 3. –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª –ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç –Ω–∞–π–¥–µ–Ω —Ö–æ—Ç—è –±—ã –≤ –æ–¥–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ
        if chromadb_chunks_deleted == 0 and simple_rag_chunks_deleted == 0:
            logger.warning(f"‚ö†Ô∏è –î–æ–∫—É–º–µ–Ω—Ç {document_id} –Ω–µ –Ω–∞–π–¥–µ–Ω –Ω–∏ –≤ ChromaDB, –Ω–∏ –≤ simple_expert_rag")
            raise HTTPException(
                status_code=404, 
                detail=f"–î–æ–∫—É–º–µ–Ω—Ç —Å ID '{document_id}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Å–∏—Å—Ç–µ–º–µ. –í–æ–∑–º–æ–∂–Ω–æ, –æ–Ω —É–∂–µ –±—ã–ª —É–¥–∞–ª–µ–Ω –∏–ª–∏ –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–ª."
            )
        
        # 4. –õ–æ–≥–∏—Ä—É–µ–º –¥–µ–π—Å—Ç–≤–∏–µ
        audit_service = get_audit_service(db)
        audit_service.log_action(
            user_id=current_admin.id,
            action=ActionType.ADMIN_ACTION,
            resource="document",
            resource_id=document_id,
            description=f"Deleted document from RAG systems (ChromaDB: {chromadb_chunks_deleted}, Simple RAG: {simple_rag_chunks_deleted} chunks)",
            severity=SeverityLevel.MEDIUM,
            details={
                "chromadb_chunks_deleted": chromadb_chunks_deleted,
                "simple_rag_chunks_deleted": simple_rag_chunks_deleted,
                "simple_rag_success": simple_rag_result.get('success', False)
            }
        )
        
        return {
            "message": "Document deleted successfully from all RAG systems",
            "chromadb_chunks_deleted": chromadb_chunks_deleted,
            "simple_rag_chunks_deleted": simple_rag_chunks_deleted,
            "total_chunks_deleted": chromadb_chunks_deleted + simple_rag_chunks_deleted,
            "simple_rag_status": simple_rag_result.get('status', 'unknown')
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ {document_id}: {e}")
        logger.error(f"–¢–∏–ø –æ—à–∏–±–∫–∏: {type(e)}")
        logger.error(f"–î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏: {e.__dict__ if hasattr(e, '__dict__') else '–ù–µ—Ç –¥–µ—Ç–∞–ª–µ–π'}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è: {str(e)}")

@router.post("/documents/clear-all")
async def clear_all_documents(
    current_admin: User = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """–£–¥–∞–ª–∏—Ç—å –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ RAG —Å–∏—Å—Ç–µ–º—ã (—Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ —Å simple_expert_rag)"""
    try:
        if not vector_store_service.is_ready():
            raise HTTPException(status_code=503, detail="Vector store not ready")
        
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º simple_expert_rag
        from ..services.simple_expert_rag import simple_expert_rag
        
        # 1. –û—á–∏—â–∞–µ–º ChromaDB
        collection = vector_store_service.collection
        all_results = collection.get(include=['metadatas'])
        
        chromadb_chunks_deleted = len(all_results['ids'])
        if chromadb_chunks_deleted > 0:
            # –£–¥–∞–ª—è–µ–º –≤—Å–µ —á–∞–Ω–∫–∏ –∏–∑ ChromaDB
            collection.delete(ids=all_results['ids'])
            logger.info(f"üóëÔ∏è –û—á–∏—â–µ–Ω–æ ChromaDB: {chromadb_chunks_deleted} —á–∞–Ω–∫–æ–≤")
        
        # 2. –û—á–∏—â–∞–µ–º simple_expert_rag
        simple_rag_result = await simple_expert_rag.clear_all_documents()
        simple_rag_documents_deleted = simple_rag_result.get('documents_deleted', 0)
        simple_rag_chunks_deleted = simple_rag_result.get('chunks_deleted', 0)
        
        if not simple_rag_result.get('success', False):
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ simple_expert_rag: {simple_rag_result.get('error', 'Unknown error')}")
        
        # 3. –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª–∏ –ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç—ã —Ö–æ—Ç—è –±—ã –≤ –æ–¥–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ
        if chromadb_chunks_deleted == 0 and simple_rag_chunks_deleted == 0:
            return {
                "message": "No documents to delete in any system",
                "chromadb_chunks_deleted": 0,
                "simple_rag_documents_deleted": 0,
                "simple_rag_chunks_deleted": 0,
                "total_chunks_deleted": 0
            }
        
        # 4. –õ–æ–≥–∏—Ä—É–µ–º –¥–µ–π—Å—Ç–≤–∏–µ
        audit_service = get_audit_service(db)
        audit_service.log_action(
            user_id=current_admin.id,
            action=ActionType.ADMIN_ACTION,
            resource="documents",
            resource_id="all",
            description=f"Cleared all documents from RAG systems (ChromaDB: {chromadb_chunks_deleted}, Simple RAG: {simple_rag_documents_deleted} docs, {simple_rag_chunks_deleted} chunks)",
            severity=SeverityLevel.HIGH,
            details={
                "chromadb_chunks_deleted": chromadb_chunks_deleted,
                "simple_rag_documents_deleted": simple_rag_documents_deleted,
                "simple_rag_chunks_deleted": simple_rag_chunks_deleted,
                "simple_rag_success": simple_rag_result.get('success', False)
            }
        )
        
        return {
            "message": "All documents deleted successfully from all RAG systems",
            "chromadb_chunks_deleted": chromadb_chunks_deleted,
            "simple_rag_documents_deleted": simple_rag_documents_deleted,
            "simple_rag_chunks_deleted": simple_rag_chunks_deleted,
            "total_chunks_deleted": chromadb_chunks_deleted + simple_rag_chunks_deleted,
            "simple_rag_status": simple_rag_result.get('status', 'unknown')
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏: {str(e)}")

@router.get("/documents/search")
async def search_documents(
    query: str = Query(..., min_length=1),
    limit: int = Query(10, ge=1, le=100),
    current_admin: User = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """–ü–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ RAG —Å–∏—Å—Ç–µ–º–µ"""
    try:
        if not vector_store_service.is_ready():
            raise HTTPException(status_code=503, detail="Vector store not ready")
        
        collection = vector_store_service.collection
        results = collection.query(
            query_texts=[query],
            n_results=limit,
            include=['documents', 'metadatas', 'distances']
        )
        
        documents = []
        for i, (doc, meta, distance) in enumerate(zip(
            results['documents'][0],
            results['metadatas'][0],
            results['distances'][0]
        )):
            documents.append({
                "id": results['ids'][0][i],
                "content": doc,
                "metadata": meta,
                "similarity": 1 - distance,
                "distance": distance
            })
        
        return {
            "query": query,
            "documents": documents,
            "total_found": len(documents)
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ==================== –õ–û–ì–ò –ò –ê–£–î–ò–¢ ====================

@router.get("/logs/audit")
async def get_audit_logs(
    skip: int = Query(0, ge=0),
    limit: int = Query(100, ge=1, le=1000),
    action: Optional[ActionType] = None,
    severity: Optional[SeverityLevel] = None,
    user_id: Optional[int] = None,
    days: int = Query(30, ge=1, le=365),
    current_admin: User = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """–ü–æ–ª—É—á–∏—Ç—å –ª–æ–≥–∏ –∞—É–¥–∏—Ç–∞"""
    try:
        query = db.query(AuditLog)
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        start_date = datetime.utcnow() - timedelta(days=days)
        query = query.filter(AuditLog.created_at >= start_date)
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã
        if action:
            query = query.filter(AuditLog.action == action)
        if severity:
            query = query.filter(AuditLog.severity == severity)
        if user_id:
            query = query.filter(AuditLog.user_id == user_id)
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–Ω–æ–≤—ã–µ —Å–Ω–∞—á–∞–ª–∞)
        query = query.order_by(AuditLog.created_at.desc())
        
        logs = query.offset(skip).limit(limit).all()
        
        return {
            "logs": [
                {
                    "id": log.id,
                    "user_id": log.user_id,
                    "action": log.action,
                    "resource": log.resource,
                    "resource_id": log.resource_id,
                    "description": log.description,
                    "severity": log.severity,
                    "ip_address": log.ip_address,
                    "created_at": log.created_at.isoformat(),
                    "details": log.details
                }
                for log in logs
            ],
            "total": query.count(),
            "skip": skip,
            "limit": limit
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ª–æ–≥–æ–≤ –∞—É–¥–∏—Ç–∞: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/logs/export")
async def export_audit_logs(
    format: str = Query("json", pattern="^(json|csv)$"),
    days: int = Query(30, ge=1, le=365),
    current_admin: User = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """–≠–∫—Å–ø–æ—Ä—Ç –ª–æ–≥–æ–≤ –∞—É–¥–∏—Ç–∞"""
    try:
        start_date = datetime.utcnow() - timedelta(days=days)
        logs = db.query(AuditLog).filter(
            AuditLog.created_at >= start_date
        ).order_by(AuditLog.created_at.desc()).all()
        
        if format == "json":
            data = [
                {
                    "id": log.id,
                    "user_id": log.user_id,
                    "action": log.action,
                    "resource": log.resource,
                    "resource_id": log.resource_id,
                    "description": log.description,
                    "severity": log.severity,
                    "ip_address": log.ip_address,
                    "created_at": log.created_at.isoformat(),
                    "details": log.details
                }
                for log in logs
            ]
            
            return StreamingResponse(
                io.StringIO(json.dumps(data, indent=2, ensure_ascii=False)),
                media_type="application/json",
                headers={"Content-Disposition": f"attachment; filename=audit_logs_{datetime.now().strftime('%Y%m%d')}.json"}
            )
        
        elif format == "csv":
            import csv
            
            output = io.StringIO()
            writer = csv.writer(output)
            
            # –ó–∞–≥–æ–ª–æ–≤–∫–∏
            writer.writerow([
                "ID", "User ID", "Action", "Resource", "Resource ID",
                "Description", "Severity", "IP Address", "Created At", "Details"
            ])
            
            # –î–∞–Ω–Ω—ã–µ
            for log in logs:
                writer.writerow([
                    log.id, log.user_id, log.action, log.resource, log.resource_id,
                    log.description, log.severity, log.ip_address,
                    log.created_at.isoformat(), json.dumps(log.details) if log.details else ""
                ])
            
            return StreamingResponse(
                io.BytesIO(output.getvalue().encode('utf-8')),
                media_type="text/csv",
                headers={"Content-Disposition": f"attachment; filename=audit_logs_{datetime.now().strftime('%Y%m%d')}.csv"}
            )
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –ª–æ–≥–æ–≤: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ==================== –°–ò–°–¢–ï–ú–ê ====================

@router.get("/system/status")
async def get_system_status(
    current_admin: User = Depends(get_current_admin)
):
    """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã"""
    try:
        return {
            "rag_system": rag_service.get_status(),
            "vector_store": vector_store_service.get_status(),
            "embeddings": embeddings_service.get_status(),
            "timestamp": datetime.utcnow().isoformat()
        }
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞ —Å–∏—Å—Ç–µ–º—ã: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/system/rag/reinitialize")
async def reinitialize_rag_system(
    current_admin: User = Depends(get_current_admin)
):
    """–ü–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å RAG —Å–∏—Å—Ç–µ–º—É"""
    try:
        # –ü–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        vector_store_service.initialize()
        embeddings_service.load_model()
        
        # –õ–æ–≥–∏—Ä—É–µ–º –¥–µ–π—Å—Ç–≤–∏–µ
        audit_service = get_audit_service(db)
        audit_service.log_action(
            user_id=current_admin.id,
            action=ActionType.ADMIN_ACTION,
            resource="system",
            resource_id="rag",
            description="Reinitialized RAG system",
            severity=SeverityLevel.HIGH
        )
        
        return {"message": "RAG system reinitialized successfully"}
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ RAG —Å–∏—Å—Ç–µ–º—ã: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/documents/reprocess")
async def reprocess_documents(
    current_admin: User = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """–ü–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å –Ω–æ–≤—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
    try:
        if not vector_store_service.is_ready():
            raise HTTPException(status_code=400, detail="Vector store not ready")
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
        collection = vector_store_service.collection
        total_docs = collection.count()
        
        if total_docs == 0:
            return {"message": "No documents to reprocess", "processed": 0}
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        results = collection.get(
            limit=total_docs,
            include=['metadatas', 'documents']
        )
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ document_id
        documents_by_id = {}
        for i, (doc, meta) in enumerate(zip(results['documents'], results['metadatas'])):
            doc_id = meta.get('document_id', results['ids'][i])
            if doc_id not in documents_by_id:
                documents_by_id[doc_id] = {
                    "id": doc_id,
                    "metadata": meta,
                    "content": doc
                }
        
        processed_count = 0
        errors = []
        
        # –ü–µ—Ä–µ–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –¥–æ–∫—É–º–µ–Ω—Ç
        for doc_id, doc_data in documents_by_id.items():
            try:
                # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –ø–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∫–∏
                import tempfile
                with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.txt') as tmp_file:
                    tmp_file.write(doc_data['content'])
                    tmp_file_path = tmp_file.name
                
                try:
                    # –ü–µ—Ä–µ–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å –Ω–æ–≤—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
                    result = await document_service.process_file(tmp_file_path, doc_data['metadata'])
                    if result.get('success'):
                        processed_count += 1
                    else:
                        errors.append(f"Document {doc_id}: {result.get('error', 'Unknown error')}")
                finally:
                    # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                    if os.path.exists(tmp_file_path):
                        os.unlink(tmp_file_path)
                        
            except Exception as e:
                errors.append(f"Document {doc_id}: {str(e)}")
        
        # –õ–æ–≥–∏—Ä—É–µ–º –¥–µ–π—Å—Ç–≤–∏–µ
        audit_service = get_audit_service(db)
        audit_service.log_action(
            user_id=current_admin.id,
            action=ActionType.ADMIN_ACTION,
            resource="documents",
            resource_id="reprocess",
            description=f"Reprocessed {processed_count} documents",
            severity=SeverityLevel.MEDIUM
        )
        
        return {
            "message": f"Reprocessed {processed_count} documents",
            "processed": processed_count,
            "total": len(documents_by_id),
            "errors": errors
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ==================== –£–ü–†–ê–í–õ–ï–ù–ò–ï –ö–≠–®–ï–ú ====================

@router.get("/cache/status")
async def get_cache_status(
    current_admin: User = Depends(get_current_admin)
):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –∫—ç—à–∞"""
    try:
        health_status = await cache_service.health_check()
        stats = await cache_service.get_stats()
        
        return {
            "status": "success",
            "cache_health": health_status,
            "cache_stats": stats,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Error getting cache status: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/cache/reconnect")
async def reconnect_cache(
    current_admin: User = Depends(get_current_admin)
):
    """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Redis"""
    try:
        success = await cache_service.reconnect()
        
        if success:
            return {
                "status": "success",
                "message": "Redis reconnection successful",
                "timestamp": datetime.now().isoformat()
            }
        else:
            return {
                "status": "warning",
                "message": "Redis reconnection failed, using in-memory cache",
                "timestamp": datetime.now().isoformat()
            }
    except Exception as e:
        logger.error(f"Error reconnecting cache: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/cache/clear")
@require_admin_action_validation("clear_cache", "system")
async def clear_cache(
    pattern: Optional[str] = Query(None, description="–ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä: user_profile:*)"),
    current_admin: User = Depends(get_current_admin),
    request: Request = None
):
    """–û—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞ –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É –∏–ª–∏ –ø–æ–ª–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞"""
    try:
        if pattern:
            cleared_count = await cache_service.clear_pattern(pattern)
            message = f"Cleared {cleared_count} keys matching pattern '{pattern}'"
        else:
            # –ü–æ–ª–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞
            await cache_service.in_memory_cache.clear()
            if cache_service.redis_client and cache_service._initialized:
                await cache_service.redis_client.flushdb()
            message = "All cache cleared"
        
        # –õ–æ–≥–∏—Ä—É–µ–º –¥–µ–π—Å—Ç–≤–∏–µ
        audit_service = get_audit_service()
        audit_service.log_action(
            user_id=current_admin.id,
            action=ActionType.SYSTEM_MAINTENANCE,
            resource="cache",
            resource_id=None,
            description=f"Cache cleared by admin: {message}",
            severity=SeverityLevel.MEDIUM
        )
        
        return {
            "status": "success",
            "message": message,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Error clearing cache: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/cache/keys")
async def get_cache_keys(
    pattern: str = Query("*", description="–ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–ª—é—á–µ–π"),
    limit: int = Query(100, ge=1, le=1000, description="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª—é—á–µ–π"),
    current_admin: User = Depends(get_current_admin)
):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –∫–ª—é—á–µ–π –∫—ç—à–∞"""
    try:
        keys = []
        
        if cache_service.redis_client and cache_service._initialized:
            try:
                redis_keys = await cache_service.redis_client.keys(pattern)
                keys.extend(redis_keys[:limit])
            except Exception as e:
                logger.warning(f"Error getting Redis keys: {e}")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–ª—é—á–∏ –∏–∑ in-memory –∫—ç—à–∞
        in_memory_keys = list(cache_service.in_memory_cache._cache.keys())
        if pattern != "*":
            # –ü—Ä–æ—Å—Ç–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É –¥–ª—è in-memory –∫—ç—à–∞
            import fnmatch
            in_memory_keys = [k for k in in_memory_keys if fnmatch.fnmatch(k, pattern)]
        
        keys.extend(in_memory_keys[:limit - len(keys)])
        
        return {
            "status": "success",
            "keys": keys[:limit],
            "total_found": len(keys),
            "pattern": pattern,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Error getting cache keys: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/cache/key/{key}")
async def get_cache_value(
    key: str,
    current_admin: User = Depends(get_current_admin)
):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ –∫–ª—é—á—É –∏–∑ –∫—ç—à–∞"""
    try:
        value = await cache_service.get(key)
        
        return {
            "status": "success",
            "key": key,
            "value": value,
            "exists": value is not None,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Error getting cache value for key '{key}': {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.delete("/cache/key/{key}")
async def delete_cache_key(
    key: str,
    current_admin: User = Depends(get_current_admin)
):
    """–£–¥–∞–ª–µ–Ω–∏–µ –∫–ª—é—á–∞ –∏–∑ –∫—ç—à–∞"""
    try:
        success = await cache_service.delete(key)
        
        return {
            "status": "success",
            "key": key,
            "deleted": success,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Error deleting cache key '{key}': {e}")
        raise HTTPException(status_code=500, detail=str(e))