"""
API –¥–ª—è –∞–¥–º–∏–Ω –ø–∞–Ω–µ–ª–∏
–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º–∏, –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏, –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–π –∏ —Å–∏—Å—Ç–µ–º–æ–π
"""

import logging
from fastapi import APIRouter, Depends, HTTPException, UploadFile, File, Form, Query, Request
from fastapi.responses import StreamingResponse
from sqlalchemy.orm import Session
from sqlalchemy import func
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
import json
import io
import os
import tempfile

from ..core.database import get_db
from ..models.user import User
from ..models.chat import ChatSession, ChatMessage
from ..models.audit_log import AuditLog, ActionType, SeverityLevel
from ..schemas.user import User as UserSchema, UserCreate
from ..schemas.admin import (
    UserUpdate, AdminDashboard, DocumentList, DocumentSearchResponse,
    AuditLogsResponse, UserAnalytics, FileUploadResponse
)
from ..services.auth_service import auth_service
from ..services.document_service import document_service
from ..services.vector_store_service import vector_store_service
from ..services.embeddings_service import embeddings_service
from ..services.rag_service import rag_service
from ..services.smart_document_processor import smart_document_processor
from ..services.audit_service import get_audit_service
from ..services.ai_document_validator import ai_document_validator
from ..services.document_versioning import document_versioning_service
from ..core.admin_security import get_secure_admin, require_admin_action_validation

logger = logging.getLogger(__name__)

router = APIRouter()

def get_current_admin(current_user: User = Depends(auth_service.get_current_active_user)):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞"""
    if not current_user.is_admin:
        raise HTTPException(status_code=403, detail="Admin access required")
    return current_user

# ==================== –£–ü–†–ê–í–õ–ï–ù–ò–ï –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø–ú–ò ====================

@router.get("/users", response_model=List[UserSchema])
async def get_users(
    skip: int = Query(0, ge=0),
    limit: int = Query(100, ge=1, le=1000),
    search: Optional[str] = None,
    is_active: Optional[bool] = None,
    is_premium: Optional[bool] = None,
    is_admin: Optional[bool] = None,
    current_admin: User = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π"""
    try:
        query = db.query(User)
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è
        if search:
            query = query.filter(
                (User.username.contains(search)) |
                (User.email.contains(search)) |
                (User.full_name.contains(search))
            )
        
        if is_active is not None:
            query = query.filter(User.is_active == is_active)
        
        if is_premium is not None:
            query = query.filter(User.is_premium == is_premium)
            
        if is_admin is not None:
            query = query.filter(User.is_admin == is_admin)
        
        users = query.offset(skip).limit(limit).all()
        return users
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/users/{user_id}", response_model=UserSchema)
async def get_user(
    user_id: int,
    current_admin: User = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """–ü–æ–ª—É—á–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø–æ ID"""
    try:
        user = db.query(User).filter(User.id == user_id).first()
        if not user:
            raise HTTPException(status_code=404, detail="User not found")
        return user
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.put("/users/{user_id}", response_model=UserSchema)
async def update_user(
    user_id: int,
    user_update: UserUpdate,
    current_admin: User = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """–û–±–Ω–æ–≤–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    try:
        user = db.query(User).filter(User.id == user_id).first()
        if not user:
            raise HTTPException(status_code=404, detail="User not found")
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø–æ–ª—è
        update_data = user_update.dict(exclude_unset=True)
        for field, value in update_data.items():
            setattr(user, field, value)
        
        user.updated_at = datetime.utcnow()
        db.commit()
        db.refresh(user)
        
        # –õ–æ–≥–∏—Ä—É–µ–º –¥–µ–π—Å—Ç–≤–∏–µ
        audit_service = get_audit_service(db)
        audit_service.log_action(
            user_id=current_admin.id,
            action=ActionType.ADMIN_ACTION,
            resource="user",
            resource_id=str(user_id),
            description=f"Updated user {user.username}",
            details={"updated_fields": list(update_data.keys())}
        )
        
        return user
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.delete("/users/{user_id}")
@require_admin_action_validation("delete_user", "user")
async def delete_user(
    user_id: int,
    request: Request,
    current_admin: User = Depends(get_secure_admin),
    db: Session = Depends(get_db)
):
    """–£–¥–∞–ª–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–º—è–≥–∫–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ)"""
    try:
        user = db.query(User).filter(User.id == user_id).first()
        if not user:
            raise HTTPException(status_code=404, detail="User not found")
        
        # –ú—è–≥–∫–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ - –¥–µ–∞–∫—Ç–∏–≤–∏—Ä—É–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user.is_active = False
        user.updated_at = datetime.utcnow()
        db.commit()
        
        # –õ–æ–≥–∏—Ä—É–µ–º –¥–µ–π—Å—Ç–≤–∏–µ
        audit_service = get_audit_service(db)
        audit_service.log_action(
            user_id=current_admin.id,
            action=ActionType.ADMIN_ACTION,
            resource="user",
            resource_id=str(user_id),
            description=f"Deactivated user {user.username}",
            severity=SeverityLevel.HIGH
        )
        
        return {"message": "User deactivated successfully"}
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/users/{user_id}/toggle-admin")
@require_admin_action_validation("toggle_admin_status", "user")
async def toggle_admin_status(
    user_id: int,
    request: Request,
    current_admin: User = Depends(get_secure_admin),
    db: Session = Depends(get_db)
):
    """–ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞"""
    try:
        user = db.query(User).filter(User.id == user_id).first()
        if not user:
            raise HTTPException(status_code=404, detail="User not found")
        
        # –ù–µ–ª—å–∑—è —É–±—Ä–∞—Ç—å –ø—Ä–∞–≤–∞ –∞–¥–º–∏–Ω–∞ —É —Å–∞–º–æ–≥–æ —Å–µ–±—è
        if user_id == current_admin.id:
            raise HTTPException(status_code=400, detail="Cannot change your own admin status")
        
        user.is_admin = not user.is_admin
        user.updated_at = datetime.utcnow()
        db.commit()
        
        # –õ–æ–≥–∏—Ä—É–µ–º –¥–µ–π—Å—Ç–≤–∏–µ
        audit_service = get_audit_service(db)
        audit_service.log_action(
            user_id=current_admin.id,
            action=ActionType.ADMIN_ACTION,
            resource="user",
            resource_id=str(user_id),
            description=f"Toggled admin status for {user.username} to {user.is_admin}",
            severity=SeverityLevel.HIGH
        )
        
        return {
            "message": f"Admin status {'granted' if user.is_admin else 'revoked'}",
            "is_admin": user.is_admin
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞ –∞–¥–º–∏–Ω–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ==================== –ê–ù–ê–õ–ò–¢–ò–ö–ê –ò –°–¢–ê–¢–ò–°–¢–ò–ö–ê ====================

@router.get("/dashboard", response_model=AdminDashboard)
async def get_admin_dashboard(
    current_admin: User = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """–ü–æ–ª—É—á–∏—Ç—å –¥–∞—à–±–æ—Ä–¥ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞"""
    try:
        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        total_users = db.query(User).count()
        active_users = db.query(User).filter(User.is_active == True).count()
        premium_users = db.query(User).filter(User.is_premium == True).count()
        admin_users = db.query(User).filter(User.is_admin == True).count()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π
        thirty_days_ago = datetime.utcnow() - timedelta(days=30)
        new_users_30d = db.query(User).filter(User.created_at >= thirty_days_ago).count()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —á–∞—Ç–æ–≤
        total_sessions = db.query(ChatSession).count()
        total_messages = db.query(ChatMessage).count()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ RAG —Å–∏—Å—Ç–µ–º—ã
        rag_status = rag_service.get_status()
        vector_store_status = vector_store_service.get_status()
        
        return {
            "users": {
                "total": total_users,
                "active": active_users,
                "premium": premium_users,
                "admins": admin_users,
                "new_last_30d": new_users_30d
            },
            "chats": {
                "total_sessions": total_sessions,
                "total_messages": total_messages
            },
            "system": {
                "rag_status": rag_status,
                "vector_store_status": vector_store_status,
                "timestamp": datetime.utcnow().isoformat()
            }
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞—à–±–æ—Ä–¥–∞: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/analytics/users")
async def get_user_analytics(
    days: int = Query(30, ge=1, le=365),
    current_admin: User = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """–ü–æ–ª—É—á–∏—Ç—å –∞–Ω–∞–ª–∏—Ç–∏–∫—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"""
    try:
        end_date = datetime.utcnow()
        start_date = end_date - timedelta(days=days)
        
        # –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –¥–Ω—è–º
        daily_registrations = db.query(
            func.date(User.created_at).label('date'),
            func.count(User.id).label('count')
        ).filter(
            User.created_at >= start_date
        ).group_by(
            func.date(User.created_at)
        ).all()
        
        # –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ —Ç–∏–ø–∞–º –ø–æ–¥–ø–∏—Å–∫–∏
        subscription_stats = db.query(
            User.subscription_type,
            func.count(User.id).label('count')
        ).group_by(User.subscription_type).all()
        
        return {
            "period": {
                "start": start_date.isoformat(),
                "end": end_date.isoformat(),
                "days": days
            },
            "daily_registrations": [
                {"date": str(reg.date), "count": reg.count}
                for reg in daily_registrations
            ],
            "subscription_distribution": [
                {"type": stat.subscription_type, "count": stat.count}
                for stat in subscription_stats
            ]
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ==================== –£–ü–†–ê–í–õ–ï–ù–ò–ï –î–û–ö–£–ú–ï–ù–¢–ê–ú–ò ====================

@router.get("/documents")
async def get_documents(
    skip: int = Query(0, ge=0),
    limit: int = Query(100, ge=1, le=1000),
    document_type: Optional[str] = Query(None, description="–§–∏–ª—å—Ç—Ä –ø–æ —Ç–∏–ø—É –¥–æ–∫—É–º–µ–Ω—Ç–∞ (codex, federal_law, supreme_court_resolution, resolution, decree, order, other)"),
    current_admin: User = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ RAG —Å–∏—Å—Ç–µ–º–µ"""
    try:
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è, –µ—Å–ª–∏ –Ω–µ –≥–æ—Ç–æ–≤–∞
        if not vector_store_service.is_ready():
            logger.warning("Vector store not ready, attempting initialization...")
            try:
                vector_store_service.initialize()
                if not vector_store_service.is_ready():
                    logger.error("Failed to initialize vector store service")
                    return {"documents": [], "total": 0, "message": "Vector store not ready"}
            except Exception as init_error:
                logger.error(f"Error initializing vector store: {init_error}")
                return {"documents": [], "total": 0, "message": f"Vector store initialization failed: {str(init_error)}"}
        
        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
        collection = vector_store_service.collection
        if collection is None:
            logger.error("Collection is None after initialization")
            return {"documents": [], "total": 0, "message": "Collection not found"}
        
        try:
            total_docs = collection.count()
        except Exception as count_error:
            logger.error(f"Error getting collection count: {count_error}")
            return {"documents": [], "total": 0, "message": f"Error accessing collection: {str(count_error)}"}
        
        # –ï—Å–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–µ—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫
        if total_docs == 0:
            return {
                "documents": [],
                "total": 0,
                "skip": skip,
                "limit": limit
            }
        
        # –ü–æ–ª—É—á–∞–µ–º –í–°–ï –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
        try:
            results = collection.get(
                limit=total_docs,  # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
                include=['metadatas', 'documents']
            )
        except Exception as get_error:
            logger.error(f"Error getting documents from collection: {get_error}")
            return {"documents": [], "total": 0, "message": f"Error retrieving documents: {str(get_error)}"}
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if not results or 'documents' not in results or 'metadatas' not in results:
            logger.warning("Invalid results structure from collection")
            return {"documents": [], "total": 0, "message": "Invalid collection data structure"}
        
        if not results['documents'] or len(results['documents']) == 0:
            return {
                "documents": [],
                "total": 0,
                "skip": skip,
                "limit": limit
            }
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —á–∞–Ω–∫–∏ –ø–æ document_id –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        documents_by_id = {}
        try:
            ids = results.get('ids', [])
            documents_list = results.get('documents', [])
            metadatas_list = results.get('metadatas', [])
            
            for i in range(len(documents_list)):
                doc = documents_list[i] if i < len(documents_list) else ""
                meta = metadatas_list[i] if i < len(metadatas_list) else {}
                doc_id = meta.get('document_id', ids[i] if i < len(ids) else str(i))
                
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–ª—É—à–∫–∏ –∏ –æ—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
                # (–¥–æ–∫—É–º–µ–Ω—Ç—ã —Ä–∞–∑–º–µ—Ä–æ–º < 1000 –±–∞–π—Ç —Å—á–∏—Ç–∞—é—Ç—Å—è –∑–∞–≥–ª—É—à–∫–∞–º–∏)
                doc_size = len(doc) if doc else 0
                if doc_size < 1000:  # –§–∏–ª—å—Ç—Ä—É–µ–º –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –º–µ–Ω—å—à–µ 1 KB
                    continue
                
                if doc_id not in documents_by_id:
                    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç
                    doc_size = len(doc) if doc else 0
                    documents_by_id[doc_id] = {
                        "id": doc_id,
                        "content": doc,
                        "metadata": meta,
                        "length": doc_size,  # –ë—É–¥–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–æ –Ω–∞ total_length –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ —á–∞–Ω–∫–æ–≤
                        "chunks_count": 1,
                        "total_length": doc_size
                    }
                else:
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –¥–æ–∫—É–º–µ–Ω—Ç
                    existing = documents_by_id[doc_id]
                    existing["chunks_count"] += 1
                    existing["total_length"] += len(doc) if doc else 0
                    # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–∞ –±–æ–ª–µ–µ –¥–ª–∏–Ω–Ω—ã–π —á–∞–Ω–∫
                    if doc and len(doc) > len(existing.get("content", "")):
                        existing["content"] = doc
                    # –í—Å–µ–≥–¥–∞ –æ–±–Ω–æ–≤–ª—è–µ–º length –Ω–∞ total_length –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –æ–±—â–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞
                    existing["length"] = existing["total_length"]
        except Exception as grouping_error:
            logger.error(f"Error grouping documents: {grouping_error}")
            return {"documents": [], "total": 0, "message": f"Error processing documents: {str(grouping_error)}"}
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å–ø–∏—Å–æ–∫ –∏ –æ–±–Ω–æ–≤–ª—è–µ–º length –¥–ª—è –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        documents = list(documents_by_id.values())
        for doc in documents:
            # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ length = total_length –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ UI
            doc["length"] = doc.get("total_length", doc.get("length", 0))
            # –î–æ–±–∞–≤–ª—è–µ–º file_name –Ω–∞ –≤–µ—Ä—Ö–Ω–∏–π —É—Ä–æ–≤–µ–Ω—å –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞ —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–∞
            meta = doc.get("metadata", {})
            if "file_name" not in doc:
                doc["file_name"] = meta.get("file_name") or meta.get("filename", "–ë–µ–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞")
            # –î–æ–±–∞–≤–ª—è–µ–º document_type –Ω–∞ –≤–µ—Ä—Ö–Ω–∏–π —É—Ä–æ–≤–µ–Ω—å
            if "document_type" not in doc:
                doc["document_type"] = meta.get("document_type", "other")
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ –æ–±—â–µ–º—É —Ä–∞–∑–º–µ—Ä—É (—Å—É–º–º–∞ –≤—Å–µ—Ö —á–∞–Ω–∫–æ–≤)
        # –î–æ–∫—É–º–µ–Ω—Ç—ã —Å –æ–±—â–∏–º —Ä–∞–∑–º–µ—Ä–æ–º < 5 KB —Å—á–∏—Ç–∞—é—Ç—Å—è –∑–∞–≥–ª—É—à–∫–∞–º–∏
        documents = [doc for doc in documents if doc.get('total_length', 0) >= 5120]
        
        documents.sort(key=lambda x: x['metadata'].get('added_at', ''), reverse=True)
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ —Ç–∏–ø—É –¥–æ–∫—É–º–µ–Ω—Ç–∞, –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω
        if document_type:
            documents = [doc for doc in documents if doc['metadata'].get('document_type') == document_type]
        
        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ source_url –¥–ª—è URL –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        seen_urls = set()
        unique_documents = []
        for doc in documents:
            if doc['metadata'].get('source_type') == 'url':
                source_url = doc['metadata'].get('source_url', '')
                if source_url and source_url not in seen_urls:
                    seen_urls.add(source_url)
                    unique_documents.append(doc)
            else:
                unique_documents.append(doc)
        
        documents = unique_documents
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–∞–≥–∏–Ω–∞—Ü–∏—é
        total_unique_docs = len(documents)
        documents = documents[skip:skip + limit]
        
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        logger.info(f"API /documents: –≤–æ–∑–≤—Ä–∞—â–∞–µ–º {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ {total_unique_docs} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö")
        if len(documents) > 0:
            first_doc = documents[0]
            file_name = first_doc.get('file_name') or first_doc.get('metadata', {}).get('file_name', 'unknown')
            logger.info(f"–ü–µ—Ä–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç: {file_name}")
        else:
            logger.warning(f"API /documents: –¥–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –ø–æ—Å–ª–µ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏. documents_by_id —Å–æ–¥–µ—Ä–∂–∏—Ç {len(documents_by_id)} –∑–∞–ø–∏—Å–µ–π")
        
        # –£–ª—É—á—à–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –æ—Ç–≤–µ—Ç–∞ –¥–ª—è —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–∞
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–∏–ø–∞—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
        documents_by_type = {}
        for doc in documents:
            doc_type = doc['metadata'].get('document_type', 'other')
            if doc_type not in documents_by_type:
                documents_by_type[doc_type] = []
            documents_by_type[doc_type].append(doc)
        
        return {
            "documents": documents,
            "total": total_unique_docs,
            "skip": skip,
            "limit": limit,
            "document_type": document_type,  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—Ä–∏–º–µ–Ω–µ–Ω–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä
            "documents_by_type": documents_by_type,  # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ —Ç–∏–ø–∞–º –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
            "available_types": list(documents_by_type.keys())  # –î–æ—Å—Ç—É–ø–Ω—ã–µ —Ç–∏–ø—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Error retrieving documents: {str(e)}")

# –ú–∞–ø–ø–∏–Ω–≥ —Ç–∏–ø–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–∞ —Ä—É—Å—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è
DOCUMENT_TYPE_NAMES = {
    "codex": "–ö–æ–¥–µ–∫—Å—ã",
    "federal_law": "–§–µ–¥–µ—Ä–∞–ª—å–Ω—ã–µ –∑–∞–∫–æ–Ω—ã",
    "supreme_court_resolution": "–ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –í–µ—Ä—Ö–æ–≤–Ω–æ–≥–æ –°—É–¥–∞",
    "resolution": "–ü–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è",
    "decree": "–£–∫–∞–∑—ã",
    "order": "–ü—Ä–∏–∫–∞–∑—ã",
    "other": "–î—Ä—É–≥–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã"
}

@router.get("/documents/types")
async def get_document_types(
    current_admin: User = Depends(get_current_admin)
):
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ç–∏–ø–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å —Ä—É—Å—Å–∫–∏–º–∏ –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏"""
    return {
        "types": [
            {
                "id": doc_type,
                "name": DOCUMENT_TYPE_NAMES.get(doc_type, doc_type),
                "icon": get_document_type_icon(doc_type)
            }
            for doc_type in DOCUMENT_TYPE_NAMES.keys()
        ]
    }

def get_document_type_icon(doc_type: str) -> str:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–∫–æ–Ω–∫—É –¥–ª—è —Ç–∏–ø–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
    icons = {
        "codex": "üìö",
        "federal_law": "üìú",
        "supreme_court_resolution": "‚öñÔ∏è",
        "resolution": "üìã",
        "decree": "üìù",
        "order": "üìÑ",
        "other": "üìë"
    }
    return icons.get(doc_type, "üìÑ")

@router.get("/documents/stats")
async def get_documents_stats(
    current_admin: User = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ç–∏–ø–∞–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    try:
        if not vector_store_service.is_ready():
            vector_store_service.initialize()
            if not vector_store_service.is_ready():
                return {"stats": {}, "message": "Vector store not ready"}
        
        collection = vector_store_service.collection
        if collection is None:
            return {"stats": {}, "message": "Collection not found"}
        
        try:
            total_docs = collection.count()
            if total_docs == 0:
                return {"stats": {}, "total": 0}
            
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
            results = collection.get(
                limit=total_docs,
                include=['metadatas']
            )
            
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –ø–æ —Ç–∏–ø–∞–º
            stats = {}
            documents_by_type = {}
            
            metadatas_list = results.get('metadatas', [])
            for meta in metadatas_list:
                doc_type = meta.get('document_type', 'other')
                doc_id = meta.get('document_id', 'unknown')
                
                if doc_type not in stats:
                    stats[doc_type] = 0
                    documents_by_type[doc_type] = set()
                
                # –°—á–∏—Ç–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ document_id
                if doc_id not in documents_by_type[doc_type]:
                    documents_by_type[doc_type].add(doc_id)
                    stats[doc_type] += 1
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å–ø–∏—Å–æ–∫ –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞ —Å —Ä—É—Å—Å–∫–∏–º–∏ –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏
            stats_list = [
                {
                    "type": doc_type,
                    "count": count,
                    "name": DOCUMENT_TYPE_NAMES.get(doc_type, doc_type),
                    "icon": get_document_type_icon(doc_type)
                }
                for doc_type, count in sorted(stats.items())
            ]
            
            return {
                "stats": stats,
                "stats_list": stats_list,
                "total": total_docs,
                "total_unique_documents": sum(stats.values()),
                "type_names": DOCUMENT_TYPE_NAMES  # –ú–∞–ø–ø–∏–Ω–≥ –¥–ª—è —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–∞
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
            return {"stats": {}, "message": f"Error: {str(e)}"}
            
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/documents/by-type/{document_type}")
async def get_documents_by_type(
    document_type: str,
    skip: int = Query(0, ge=0),
    limit: int = Query(100, ge=1, le=1000),
    current_admin: User = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """–ü–æ–ª—É—á–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ —Ç–∏–ø–∞ —Å –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–æ–π"""
    try:
        if not vector_store_service.is_ready():
            vector_store_service.initialize()
            if not vector_store_service.is_ready():
                return {"documents": [], "total": 0, "message": "Vector store not ready"}
        
        collection = vector_store_service.collection
        if collection is None:
            return {"documents": [], "total": 0, "message": "Collection not found"}
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –Ω—É–∂–Ω–æ–≥–æ —Ç–∏–ø–∞
        total_docs = collection.count()
        if total_docs == 0:
            return {"documents": [], "total": 0, "skip": skip, "limit": limit}
        
        results = collection.get(limit=total_docs, include=['metadatas', 'documents'])
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ document_id
        documents_by_id = {}
        ids = results.get('ids', [])
        documents_list = results.get('documents', [])
        metadatas_list = results.get('metadatas', [])
        
        for i in range(len(documents_list)):
            doc = documents_list[i] if i < len(documents_list) else ""
            meta = metadatas_list[i] if i < len(metadatas_list) else {}
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ —Ç–∏–ø—É
            if meta.get('document_type') != document_type:
                continue
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –º–∞–ª–µ–Ω—å–∫–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã (< 1000 –±–∞–π—Ç)
            doc_size = len(doc) if doc else 0
            if doc_size < 1000:
                continue
            
            doc_id = meta.get('document_id', ids[i] if i < len(ids) else str(i))
            
            if doc_id not in documents_by_id:
                documents_by_id[doc_id] = {
                    "id": doc_id,
                    "content": doc,
                    "metadata": meta,
                    "length": len(doc) if doc else 0,
                    "chunks_count": 1,
                    "total_length": len(doc) if doc else 0,
                    "file_name": meta.get('file_name', meta.get('filename', 'unknown')),
                    "document_type": meta.get('document_type', 'other')
                }
            else:
                existing = documents_by_id[doc_id]
                existing["chunks_count"] += 1
                existing["total_length"] += len(doc) if doc else 0
                if doc and len(doc) > len(existing.get("content", "")):
                    existing["content"] = doc
                    existing["length"] = len(doc)
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å–ø–∏—Å–æ–∫ –∏ —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –æ–±—â–µ–º—É —Ä–∞–∑–º–µ—Ä—É
        documents = list(documents_by_id.values())
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ –æ–±—â–µ–º—É —Ä–∞–∑–º–µ—Ä—É (—Å—É–º–º–∞ –≤—Å–µ—Ö —á–∞–Ω–∫–æ–≤)
        # –î–æ–∫—É–º–µ–Ω—Ç—ã —Å –æ–±—â–∏–º —Ä–∞–∑–º–µ—Ä–æ–º < 5 KB —Å—á–∏—Ç–∞—é—Ç—Å—è –∑–∞–≥–ª—É—à–∫–∞–º–∏
        documents = [doc for doc in documents if doc.get('total_length', 0) >= 5120]
        
        # –î–æ–±–∞–≤–ª—è–µ–º file_name –∏ document_type –Ω–∞ –≤–µ—Ä—Ö–Ω–∏–π —É—Ä–æ–≤–µ–Ω—å –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞ —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–∞
        for doc in documents:
            meta = doc.get("metadata", {})
            if "file_name" not in doc:
                doc["file_name"] = meta.get("file_name") or meta.get("filename", "–ë–µ–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞")
            if "document_type" not in doc:
                doc["document_type"] = meta.get("document_type", "other")
        
        documents.sort(key=lambda x: x['metadata'].get('added_at', ''), reverse=True)
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–∞–≥–∏–Ω–∞—Ü–∏—é
        total_unique_docs = len(documents)
        documents = documents[skip:skip + limit]
        
        return {
            "documents": documents,
            "total": total_unique_docs,
            "skip": skip,
            "limit": limit,
            "document_type": document_type
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø–æ —Ç–∏–ø—É: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Error retrieving documents: {str(e)}")

@router.get("/documents/{document_id}/structure")
async def get_document_structure(
    document_id: str,
    current_admin: User = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–æ–∫—É–º–µ–Ω—Ç–∞ (—Ä–∞–∑–¥–µ–ª—ã, —Å—Ç–∞—Ç—å–∏ –¥–ª—è –∫–æ–¥–µ–∫—Å–æ–≤)"""
    try:
        if not vector_store_service.is_ready():
            vector_store_service.initialize()
            if not vector_store_service.is_ready():
                return {"structure": [], "message": "Vector store not ready"}
        
        collection = vector_store_service.collection
        if collection is None:
            return {"structure": [], "message": "Collection not found"}
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —á–∞–Ω–∫–∏ —ç—Ç–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        total_docs = collection.count()
        results = collection.get(limit=total_docs, include=['metadatas', 'documents', 'ids'])
        
        metadatas = results.get('metadatas', [])
        documents = results.get('documents', [])
        ids = results.get('ids', [])
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ document_id
        document_chunks = []
        for i, (meta, doc, chunk_id) in enumerate(zip(metadatas, documents, ids)):
            if meta.get('document_id') == document_id:
                document_chunks.append({
                    'chunk_id': chunk_id,
                    'content': doc,
                    'metadata': meta,
                    'chunk_index': meta.get('chunk_index', i),
                    'part': meta.get('part', ''),
                    'article': meta.get('article', ''),
                    'item': meta.get('item', ''),
                })
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ chunk_index
        document_chunks.sort(key=lambda x: x['chunk_index'])
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ä–∞–∑–¥–µ–ª–∞–º/—Å—Ç–∞—Ç—å—è–º –¥–ª—è –∫–æ–¥–µ–∫—Å–æ–≤
        structure = []
        current_section = None
        current_article = None
        
        for chunk in document_chunks:
            meta = chunk['metadata']
            part = meta.get('part', '')
            article = meta.get('article', '')
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å part - —ç—Ç–æ —Ä–∞–∑–¥–µ–ª
            if part and part != current_section:
                current_section = part
                structure.append({
                    'type': 'section',
                    'name': part,
                    'chunks': []
                })
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å article - —ç—Ç–æ —Å—Ç–∞—Ç—å—è
            if article:
                # –ò—â–µ–º —Ä–∞–∑–¥–µ–ª –¥–ª—è —ç—Ç–æ–π —Å—Ç–∞—Ç—å–∏
                section = None
                for s in structure:
                    if s['type'] == 'section' and s['name'] == part:
                        section = s
                        break
                
                if not section and part:
                    section = {'type': 'section', 'name': part, 'chunks': []}
                    structure.append(section)
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç—å—é
                article_name = f"–°—Ç–∞—Ç—å—è {article}" if article else "–ë–µ–∑ –Ω–æ–º–µ—Ä–∞"
                if not section or article_name not in [a['name'] for a in section.get('articles', [])]:
                    if section:
                        if 'articles' not in section:
                            section['articles'] = []
                        section['articles'].append({
                            'name': article_name,
                            'article': article,
                            'chunks': []
                        })
            
            # –î–æ–±–∞–≤–ª—è–µ–º —á–∞–Ω–∫ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä—É
            if structure:
                if article and structure[-1].get('articles'):
                    structure[-1]['articles'][-1]['chunks'].append(chunk)
                else:
                    if 'chunks' not in structure[-1]:
                        structure[-1]['chunks'] = []
                    structure[-1]['chunks'].append(chunk)
            else:
                structure.append({
                    'type': 'content',
                    'chunks': [chunk]
                })
        
        return {
            "document_id": document_id,
            "structure": structure,
            "total_chunks": len(document_chunks)
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Error retrieving document structure: {str(e)}")

@router.post("/documents/upload")
async def upload_document(
    file: UploadFile = File(...),
    description: Optional[str] = Form(None),
    current_admin: User = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç –≤ RAG —Å–∏—Å—Ç–µ–º—É"""
    try:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª –≤—Ä–µ–º–µ–Ω–Ω–æ
        
        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
        safe_filename = os.path.basename(file.filename) if file.filename else "unknown"
        safe_filename = "".join(c for c in safe_filename if c.isalnum() or c in ".-_")[:50]
        
        with tempfile.NamedTemporaryFile(delete=False, suffix=f"_{safe_filename}") as tmp_file:
            content = await file.read()
            tmp_file.write(content)
            tmp_file_path = tmp_file.name
        
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ñ–∞–π–ª–∞ –∏ —á–∏—Ç–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
            file_extension = os.path.splitext(file.filename)[1].lower() if file.filename else ''
            
            if file_extension == '.docx':
                # –î–ª—è DOCX —Ñ–∞–π–ª–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
                import docx
                try:
                    doc = docx.Document(tmp_file_path)
                    content = '\n'.join([paragraph.text for paragraph in doc.paragraphs])
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è DOCX —Ñ–∞–π–ª–∞: {e}")
                    # Fallback: —á–∏—Ç–∞–µ–º –∫–∞–∫ –±–∏–Ω–∞—Ä–Ω—ã–π —Ñ–∞–π–ª
                    with open(tmp_file_path, 'rb') as f:
                        content = f.read().decode('utf-8', errors='ignore')
            elif file_extension == '.pdf':
                # –î–ª—è PDF —Ñ–∞–π–ª–æ–≤
                try:
                    import PyPDF2
                    with open(tmp_file_path, 'rb') as f:
                        reader = PyPDF2.PdfReader(f)
                        content = '\n'.join([page.extract_text() for page in reader.pages])
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è PDF —Ñ–∞–π–ª–∞: {e}")
                    content = "–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑ PDF"
            else:
                # –î–ª—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤
                with open(tmp_file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—É—é –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—É—é —Å–∏—Å—Ç–µ–º—É –æ–±—Ä–∞–±–æ—Ç–∫–∏
            result = await smart_document_processor.process_document(
                file_path=file.filename,
                content=content
            )
            
            if result.get('success'):
                # –õ–æ–≥–∏—Ä—É–µ–º –¥–µ–π—Å—Ç–≤–∏–µ
                audit_service = get_audit_service(db)
                audit_service.log_action(
                    user_id=current_admin.id,
                    action=ActionType.ADMIN_ACTION,
                    resource="document",
                    resource_id=file.filename,
                    description=f"Uploaded document with smart processing: {file.filename}",
                    details={
                        "chunks_created": result.get('chunks_count', 0),
                        "articles_found": result.get('articles_count', 0),
                        "document_type": result.get('metadata', {}).get('document_type', 'unknown'),
                        "structure_score": result.get('metadata', {}).get('structure_score', 0)
                    }
                )
                
                return {
                    "success": True,
                    "message": "Document uploaded and analyzed successfully",
                    "details": result,
                    "chunks_created": result.get('chunks_count', 0),
                    "articles_found": result.get('articles_count', 0),
                    "sections_found": result.get('sections_count', 0),
                    "document_type": result.get('metadata', {}).get('document_type', 'unknown'),
                    "structure_score": result.get('metadata', {}).get('structure_score', 0),
                    "processing_time": result.get('processing_time', 0),
                    "filename": file.filename
                }
            else:
                return {
                    "success": False,
                    "message": "Failed to process document with smart analysis",
                    "error": result.get('error', 'Unknown error')
                }
                
        finally:
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            os.unlink(tmp_file_path)
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/documents/upload-url")
async def upload_document_from_url(
    request: dict,
    current_admin: User = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç –ø–æ URL"""
    try:
        url = request.get('url')
        if not url:
            raise HTTPException(status_code=400, detail="URL –Ω–µ —É–∫–∞–∑–∞–Ω")
            
        logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –ø–æ URL: {url}")
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è URL
        if not url.startswith(('http://', 'https://')):
            raise HTTPException(status_code=400, detail="–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π URL")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç –ø–æ URL
        result = await document_service.process_url(url)
        
        if result.get('success'):
            # –õ–æ–≥–∏—Ä—É–µ–º –¥–µ–π—Å—Ç–≤–∏–µ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞
            audit_service = get_audit_service(db)
            audit_service.log_action(
                user_id=current_admin.id,
                action=ActionType.ADMIN_ACTION,
                resource="document",
                resource_id=result.get('document_id', 'unknown'),
                description=f"Uploaded document from URL: {url}",
                details={"chunks_added": result.get('chunks_added', 0)}
            )
            
            return {
                "success": True,
                "message": "Document uploaded successfully from URL",
                "details": result,
                "chunks_added": result.get('chunks_added', 0),
                "document_type": result.get('document_type', 'unknown'),
                "validation_confidence": result.get('validation_confidence', 0),
                "legal_score": result.get('legal_score', 0),
                "text_length": result.get('text_length', 0),
                "file_hash": result.get('file_hash', ''),
                "document_id": result.get('document_id', ''),
                "source_url": url
            }
        else:
            return {
                "success": False,
                "message": "Failed to upload document from URL",
                "error": result.get('error')
            }
            
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –ø–æ URL: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/validation/status")
async def get_validation_status(
    current_admin: User = Depends(get_current_admin)
):
    """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    try:
        status = document_service.get_status()
        return {
            "success": True,
            "validation_method": status.get("validation_method", "unknown"),
            "available_methods": ["hybrid", "ai", "rules"],
            "hybrid_stats": status.get("hybrid_stats", {}),
            "ai_validator_stats": ai_document_validator.get_validation_stats()
        }
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/validation/method")
async def set_validation_method(
    method: str = Query(..., description="–ú–µ—Ç–æ–¥ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: hybrid, ai, rules, none"),
    current_admin: User = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """–ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å –º–µ—Ç–æ–¥ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    try:
        document_service.set_validation_method(method)
        
        # –õ–æ–≥–∏—Ä—É–µ–º –¥–µ–π—Å—Ç–≤–∏–µ
        audit_service = get_audit_service(db)
        audit_service.log_action(
            user_id=current_admin.id,
            action=ActionType.ADMIN_ACTION,
            resource="validation_method",
            resource_id="system",
            description=f"Changed validation method to: {method}",
            details={"validation_method": method}
        )
        
        method_names = {
            "hybrid": "–ì–∏–±—Ä–∏–¥–Ω—ã–π (–ø—Ä–∞–≤–∏–ª–∞ + AI)",
            "ai": "AI (Vistral-24B)",
            "rules": "–ü—Ä–∞–≤–∏–ª–∞ (–±—ã—Å—Ç—Ä—ã–π)"
        }
        
        return {
            "success": True,
            "message": f"–ú–µ—Ç–æ–¥ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏–∑–º–µ–Ω–µ–Ω –Ω–∞: {method_names.get(method, method)}",
            "validation_method": method
        }
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è –º–µ—Ç–æ–¥–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/validation/clear-cache")
async def clear_validation_cache(
    current_admin: User = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """–û—á–∏—Å—Ç–∏—Ç—å –∫—ç—à –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
    try:
        from ..services.hybrid_document_validator import hybrid_document_validator
        hybrid_document_validator.clear_cache()
        
        # –õ–æ–≥–∏—Ä—É–µ–º –¥–µ–π—Å—Ç–≤–∏–µ
        audit_service = get_audit_service(db)
        audit_service.log_action(
            user_id=current_admin.id,
            action=ActionType.ADMIN_ACTION,
            resource="validation_cache",
            resource_id="system",
            description="Cleared validation cache",
            details={}
        )
        
        return {
            "success": True,
            "message": "–ö—ç—à –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –æ—á–∏—â–µ–Ω"
        }
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –∫—ç—à–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/documents/versions")
async def get_document_versions(
    document_id: Optional[str] = Query(None, description="ID –¥–æ–∫—É–º–µ–Ω—Ç–∞ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤–µ—Ä—Å–∏–π"),
    current_admin: User = Depends(get_current_admin)
):
    """–ü–æ–ª—É—á–∏—Ç—å –≤–µ—Ä—Å–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    try:
        if document_id:
            # –ü–æ–ª—É—á–∏—Ç—å –≤–µ—Ä—Å–∏–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            versions = document_versioning_service.get_all_versions(document_id)
            current_version = document_versioning_service.get_current_version(document_id)
            
            return {
                "success": True,
                "document_id": document_id,
                "current_version": current_version.__dict__ if current_version else None,
                "all_versions": [v.__dict__ for v in versions]
            }
        else:
            # –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            stats = document_versioning_service.get_version_statistics()
            return {
                "success": True,
                "statistics": stats
            }
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –≤–µ—Ä—Å–∏–π –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/documents/current-versions")
async def get_current_versions(
    current_admin: User = Depends(get_current_admin)
):
    """–ü–æ–ª—É—á–∏—Ç—å —Ç–æ–ª—å–∫–æ —Ç–µ–∫—É—â–∏–µ –≤–µ—Ä—Å–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    try:
        # –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å –∏—Ö —Ç–µ–∫—É—â–∏–º–∏ –≤–µ—Ä—Å–∏—è–º–∏
        all_documents = {}
        for document_id in document_versioning_service.versions.keys():
            current_version = document_versioning_service.get_current_version(document_id)
            if current_version:
                all_documents[document_id] = current_version.__dict__
        
        return {
            "success": True,
            "current_versions": all_documents
        }
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–µ–∫—É—â–∏—Ö –≤–µ—Ä—Å–∏–π: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/documents/{document_id}/archive")
async def archive_document(
    document_id: str,
    current_admin: User = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """–ê—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç (–ø–æ–º–µ—Ç–∏—Ç—å –∫–∞–∫ —É—Å—Ç–∞—Ä–µ–≤—à–∏–π)"""
    try:
        # –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –≤–µ—Ä—Å–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        versions = document_versioning_service.get_all_versions(document_id)
        if not versions:
            raise HTTPException(status_code=404, detail="–î–æ–∫—É–º–µ–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        # –ü–æ–º–µ—Ç–∏—Ç—å –≤—Å–µ –≤–µ—Ä—Å–∏–∏ –∫–∞–∫ –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ
        for version in versions:
            version.status = "archived"
        
        # –õ–æ–≥–∏—Ä—É–µ–º –¥–µ–π—Å—Ç–≤–∏–µ
        audit_service = get_audit_service(db)
        audit_service.log_action(
            user_id=current_admin.id,
            action=ActionType.ADMIN_ACTION,
            resource="document",
            resource_id=document_id,
            description=f"Archived document {document_id}",
            details={"versions_archived": len(versions)}
        )
        
        return {
            "success": True,
            "message": f"–î–æ–∫—É–º–µ–Ω—Ç {document_id} –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω",
            "archived_versions": len(versions)
        }
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.delete("/documents/{document_id}")
async def delete_document(
    document_id: str,
    current_admin: User = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """–£–¥–∞–ª–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç –∏–∑ RAG —Å–∏—Å—Ç–µ–º—ã (—Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ —Å simple_expert_rag)"""
    try:
        if not vector_store_service.is_ready():
            raise HTTPException(status_code=503, detail="Vector store not ready")
        
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º simple_expert_rag
        from ..services.simple_expert_rag import simple_expert_rag
        
        # 1. –£–¥–∞–ª—è–µ–º –∏–∑ ChromaDB
        collection = vector_store_service.collection
        all_results = collection.get(include=['metadatas'])
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º —á–∞–Ω–∫–∏ –ø–æ document_id –∏–ª–∏ –ø–æ chunk_id
        matching_ids = []
        for i, metadata in enumerate(all_results['metadatas']):
            if metadata and (metadata.get('document_id') == document_id or all_results['ids'][i] == document_id):
                matching_ids.append(all_results['ids'][i])
        
        chromadb_chunks_deleted = 0
        if matching_ids:
            # –£–¥–∞–ª—è–µ–º –≤—Å–µ —á–∞–Ω–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏–∑ ChromaDB
            collection.delete(ids=matching_ids)
            chromadb_chunks_deleted = len(matching_ids)
            logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ –∏–∑ ChromaDB: {chromadb_chunks_deleted} —á–∞–Ω–∫–æ–≤")
        
        # 2. –£–¥–∞–ª—è–µ–º –∏–∑ simple_expert_rag
        # –ü—Ä–æ–±—É–µ–º —É–¥–∞–ª–∏—Ç—å –ø–æ document_id –∏ –ø–æ –≤—Å–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–º –∏–º–µ–Ω–∞–º —Ñ–∞–π–ª–æ–≤
        simple_rag_result = await simple_expert_rag.delete_document(document_id)
        simple_rag_chunks_deleted = simple_rag_result.get('chunks_deleted', 0)
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω –ø–æ document_id, –ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ø–æ –∏–º–µ–Ω–∞–º —Ñ–∞–π–ª–æ–≤ –≤ ChromaDB
        if simple_rag_chunks_deleted == 0 and matching_ids:
            # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
            for chunk_id in matching_ids:
                try:
                    chunk_results = collection.get(ids=[chunk_id], include=['metadatas'])
                    if chunk_results['metadatas'] and len(chunk_results['metadatas']) > 0:
                        chunk_metadata = chunk_results['metadatas'][0]
                        if chunk_metadata and 'filename' in chunk_metadata:
                            filename = chunk_metadata['filename']
                            # –ü—Ä–æ–±—É–µ–º —É–¥–∞–ª–∏—Ç—å –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
                            filename_result = await simple_expert_rag.delete_document(filename)
                            if filename_result.get('success', False):
                                simple_rag_chunks_deleted += filename_result.get('chunks_deleted', 0)
                                simple_rag_result = filename_result
                                break
                except Exception as e:
                    logger.warning(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–ª—è {chunk_id}: {e}")
                    continue
        
        if not simple_rag_result.get('success', False):
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –∏–∑ simple_expert_rag: {simple_rag_result.get('error', 'Unknown error')}")
        
        # 3. –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª –ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç –Ω–∞–π–¥–µ–Ω —Ö–æ—Ç—è –±—ã –≤ –æ–¥–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ
        if chromadb_chunks_deleted == 0 and simple_rag_chunks_deleted == 0:
            logger.warning(f"‚ö†Ô∏è –î–æ–∫—É–º–µ–Ω—Ç {document_id} –Ω–µ –Ω–∞–π–¥–µ–Ω –Ω–∏ –≤ ChromaDB, –Ω–∏ –≤ simple_expert_rag")
            raise HTTPException(
                status_code=404, 
                detail=f"–î–æ–∫—É–º–µ–Ω—Ç —Å ID '{document_id}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Å–∏—Å—Ç–µ–º–µ. –í–æ–∑–º–æ–∂–Ω–æ, –æ–Ω —É–∂–µ –±—ã–ª —É–¥–∞–ª–µ–Ω –∏–ª–∏ –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–ª."
            )
        
        # 4. –õ–æ–≥–∏—Ä—É–µ–º –¥–µ–π—Å—Ç–≤–∏–µ
        audit_service = get_audit_service(db)
        audit_service.log_action(
            user_id=current_admin.id,
            action=ActionType.ADMIN_ACTION,
            resource="document",
            resource_id=document_id,
            description=f"Deleted document from RAG systems (ChromaDB: {chromadb_chunks_deleted}, Simple RAG: {simple_rag_chunks_deleted} chunks)",
            severity=SeverityLevel.MEDIUM,
            details={
                "chromadb_chunks_deleted": chromadb_chunks_deleted,
                "simple_rag_chunks_deleted": simple_rag_chunks_deleted,
                "simple_rag_success": simple_rag_result.get('success', False)
            }
        )
        
        return {
            "message": "Document deleted successfully from all RAG systems",
            "chromadb_chunks_deleted": chromadb_chunks_deleted,
            "simple_rag_chunks_deleted": simple_rag_chunks_deleted,
            "total_chunks_deleted": chromadb_chunks_deleted + simple_rag_chunks_deleted,
            "simple_rag_status": simple_rag_result.get('status', 'unknown')
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ {document_id}: {e}")
        logger.error(f"–¢–∏–ø –æ—à–∏–±–∫–∏: {type(e)}")
        logger.error(f"–î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏: {e.__dict__ if hasattr(e, '__dict__') else '–ù–µ—Ç –¥–µ—Ç–∞–ª–µ–π'}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è: {str(e)}")

@router.post("/documents/clear-all")
async def clear_all_documents(
    current_admin: User = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """–£–¥–∞–ª–∏—Ç—å –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ RAG —Å–∏—Å—Ç–µ–º—ã (—Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ —Å simple_expert_rag)"""
    try:
        if not vector_store_service.is_ready():
            raise HTTPException(status_code=503, detail="Vector store not ready")
        
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º simple_expert_rag
        from ..services.simple_expert_rag import simple_expert_rag
        
        # 1. –û—á–∏—â–∞–µ–º ChromaDB
        collection = vector_store_service.collection
        all_results = collection.get(include=['metadatas'])
        
        chromadb_chunks_deleted = len(all_results['ids'])
        if chromadb_chunks_deleted > 0:
            # –£–¥–∞–ª—è–µ–º –≤—Å–µ —á–∞–Ω–∫–∏ –∏–∑ ChromaDB
            collection.delete(ids=all_results['ids'])
            logger.info(f"üóëÔ∏è –û—á–∏—â–µ–Ω–æ ChromaDB: {chromadb_chunks_deleted} —á–∞–Ω–∫–æ–≤")
        
        # 2. –û—á–∏—â–∞–µ–º simple_expert_rag
        simple_rag_result = await simple_expert_rag.clear_all_documents()
        simple_rag_documents_deleted = simple_rag_result.get('documents_deleted', 0)
        simple_rag_chunks_deleted = simple_rag_result.get('chunks_deleted', 0)
        
        if not simple_rag_result.get('success', False):
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ simple_expert_rag: {simple_rag_result.get('error', 'Unknown error')}")
        
        # 3. –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª–∏ –ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç—ã —Ö–æ—Ç—è –±—ã –≤ –æ–¥–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ
        if chromadb_chunks_deleted == 0 and simple_rag_chunks_deleted == 0:
            return {
                "message": "No documents to delete in any system",
                "chromadb_chunks_deleted": 0,
                "simple_rag_documents_deleted": 0,
                "simple_rag_chunks_deleted": 0,
                "total_chunks_deleted": 0
            }
        
        # 4. –õ–æ–≥–∏—Ä—É–µ–º –¥–µ–π—Å—Ç–≤–∏–µ
        audit_service = get_audit_service(db)
        audit_service.log_action(
            user_id=current_admin.id,
            action=ActionType.ADMIN_ACTION,
            resource="documents",
            resource_id="all",
            description=f"Cleared all documents from RAG systems (ChromaDB: {chromadb_chunks_deleted}, Simple RAG: {simple_rag_documents_deleted} docs, {simple_rag_chunks_deleted} chunks)",
            severity=SeverityLevel.HIGH,
            details={
                "chromadb_chunks_deleted": chromadb_chunks_deleted,
                "simple_rag_documents_deleted": simple_rag_documents_deleted,
                "simple_rag_chunks_deleted": simple_rag_chunks_deleted,
                "simple_rag_success": simple_rag_result.get('success', False)
            }
        )
        
        return {
            "message": "All documents deleted successfully from all RAG systems",
            "chromadb_chunks_deleted": chromadb_chunks_deleted,
            "simple_rag_documents_deleted": simple_rag_documents_deleted,
            "simple_rag_chunks_deleted": simple_rag_chunks_deleted,
            "total_chunks_deleted": chromadb_chunks_deleted + simple_rag_chunks_deleted,
            "simple_rag_status": simple_rag_result.get('status', 'unknown')
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏: {str(e)}")

@router.get("/documents/search")
async def search_documents(
    query: str = Query(..., min_length=1),
    limit: int = Query(10, ge=1, le=100),
    current_admin: User = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """–ü–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ RAG —Å–∏—Å—Ç–µ–º–µ"""
    try:
        if not vector_store_service.is_ready():
            raise HTTPException(status_code=503, detail="Vector store not ready")
        
        collection = vector_store_service.collection
        results = collection.query(
            query_texts=[query],
            n_results=limit,
            include=['documents', 'metadatas', 'distances']
        )
        
        documents = []
        for i, (doc, meta, distance) in enumerate(zip(
            results['documents'][0],
            results['metadatas'][0],
            results['distances'][0]
        )):
            documents.append({
                "id": results['ids'][0][i],
                "content": doc,
                "metadata": meta,
                "similarity": 1 - distance,
                "distance": distance
            })
        
        return {
            "query": query,
            "documents": documents,
            "total_found": len(documents)
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ==================== –õ–û–ì–ò –ò –ê–£–î–ò–¢ ====================

@router.get("/logs/audit")
async def get_audit_logs(
    skip: int = Query(0, ge=0),
    limit: int = Query(100, ge=1, le=1000),
    action: Optional[ActionType] = None,
    severity: Optional[SeverityLevel] = None,
    user_id: Optional[int] = None,
    days: int = Query(30, ge=1, le=365),
    current_admin: User = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """–ü–æ–ª—É—á–∏—Ç—å –ª–æ–≥–∏ –∞—É–¥–∏—Ç–∞"""
    try:
        query = db.query(AuditLog)
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        start_date = datetime.utcnow() - timedelta(days=days)
        query = query.filter(AuditLog.created_at >= start_date)
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã
        if action:
            query = query.filter(AuditLog.action == action)
        if severity:
            query = query.filter(AuditLog.severity == severity)
        if user_id:
            query = query.filter(AuditLog.user_id == user_id)
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–Ω–æ–≤—ã–µ —Å–Ω–∞—á–∞–ª–∞)
        query = query.order_by(AuditLog.created_at.desc())
        
        logs = query.offset(skip).limit(limit).all()
        
        return {
            "logs": [
                {
                    "id": log.id,
                    "user_id": log.user_id,
                    "action": log.action,
                    "resource": log.resource,
                    "resource_id": log.resource_id,
                    "description": log.description,
                    "severity": log.severity,
                    "ip_address": log.ip_address,
                    "created_at": log.created_at.isoformat(),
                    "details": log.details
                }
                for log in logs
            ],
            "total": query.count(),
            "skip": skip,
            "limit": limit
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ª–æ–≥–æ–≤ –∞—É–¥–∏—Ç–∞: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/logs/export")
async def export_audit_logs(
    format: str = Query("json", pattern="^(json|csv)$"),
    days: int = Query(30, ge=1, le=365),
    current_admin: User = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """–≠–∫—Å–ø–æ—Ä—Ç –ª–æ–≥–æ–≤ –∞—É–¥–∏—Ç–∞"""
    try:
        start_date = datetime.utcnow() - timedelta(days=days)
        logs = db.query(AuditLog).filter(
            AuditLog.created_at >= start_date
        ).order_by(AuditLog.created_at.desc()).all()
        
        if format == "json":
            data = [
                {
                    "id": log.id,
                    "user_id": log.user_id,
                    "action": log.action,
                    "resource": log.resource,
                    "resource_id": log.resource_id,
                    "description": log.description,
                    "severity": log.severity,
                    "ip_address": log.ip_address,
                    "created_at": log.created_at.isoformat(),
                    "details": log.details
                }
                for log in logs
            ]
            
            return StreamingResponse(
                io.StringIO(json.dumps(data, indent=2, ensure_ascii=False)),
                media_type="application/json",
                headers={"Content-Disposition": f"attachment; filename=audit_logs_{datetime.now().strftime('%Y%m%d')}.json"}
            )
        
        elif format == "csv":
            import csv
            
            output = io.StringIO()
            writer = csv.writer(output)
            
            # –ó–∞–≥–æ–ª–æ–≤–∫–∏
            writer.writerow([
                "ID", "User ID", "Action", "Resource", "Resource ID",
                "Description", "Severity", "IP Address", "Created At", "Details"
            ])
            
            # –î–∞–Ω–Ω—ã–µ
            for log in logs:
                writer.writerow([
                    log.id, log.user_id, log.action, log.resource, log.resource_id,
                    log.description, log.severity, log.ip_address,
                    log.created_at.isoformat(), json.dumps(log.details) if log.details else ""
                ])
            
            return StreamingResponse(
                io.BytesIO(output.getvalue().encode('utf-8')),
                media_type="text/csv",
                headers={"Content-Disposition": f"attachment; filename=audit_logs_{datetime.now().strftime('%Y%m%d')}.csv"}
            )
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –ª–æ–≥–æ–≤: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ==================== –°–ò–°–¢–ï–ú–ê ====================

@router.get("/system/status")
async def get_system_status(
    current_admin: User = Depends(get_current_admin)
):
    """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã"""
    try:
        return {
            "rag_system": rag_service.get_status(),
            "vector_store": vector_store_service.get_status(),
            "embeddings": embeddings_service.get_status(),
            "timestamp": datetime.utcnow().isoformat()
        }
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞ —Å–∏—Å—Ç–µ–º—ã: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/system/rag/reinitialize")
async def reinitialize_rag_system(
    current_admin: User = Depends(get_current_admin)
):
    """–ü–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å RAG —Å–∏—Å—Ç–µ–º—É"""
    try:
        # –ü–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        vector_store_service.initialize()
        embeddings_service.load_model()
        
        # –õ–æ–≥–∏—Ä—É–µ–º –¥–µ–π—Å—Ç–≤–∏–µ
        audit_service = get_audit_service(db)
        audit_service.log_action(
            user_id=current_admin.id,
            action=ActionType.ADMIN_ACTION,
            resource="system",
            resource_id="rag",
            description="Reinitialized RAG system",
            severity=SeverityLevel.HIGH
        )
        
        return {"message": "RAG system reinitialized successfully"}
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ RAG —Å–∏—Å—Ç–µ–º—ã: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/documents/reprocess")
async def reprocess_documents(
    current_admin: User = Depends(get_current_admin),
    db: Session = Depends(get_db)
):
    """–ü–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å –Ω–æ–≤—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
    try:
        if not vector_store_service.is_ready():
            raise HTTPException(status_code=400, detail="Vector store not ready")
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
        collection = vector_store_service.collection
        total_docs = collection.count()
        
        if total_docs == 0:
            return {"message": "No documents to reprocess", "processed": 0}
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        results = collection.get(
            limit=total_docs,
            include=['metadatas', 'documents']
        )
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ document_id
        documents_by_id = {}
        for i, (doc, meta) in enumerate(zip(results['documents'], results['metadatas'])):
            doc_id = meta.get('document_id', results['ids'][i])
            if doc_id not in documents_by_id:
                documents_by_id[doc_id] = {
                    "id": doc_id,
                    "metadata": meta,
                    "content": doc
                }
        
        processed_count = 0
        errors = []
        
        # –ü–µ—Ä–µ–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –¥–æ–∫—É–º–µ–Ω—Ç
        for doc_id, doc_data in documents_by_id.items():
            try:
                # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –ø–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∫–∏
                import tempfile
                with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.txt') as tmp_file:
                    tmp_file.write(doc_data['content'])
                    tmp_file_path = tmp_file.name
                
                try:
                    # –ü–µ—Ä–µ–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å –Ω–æ–≤—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
                    result = await document_service.process_file(tmp_file_path, doc_data['metadata'])
                    if result.get('success'):
                        processed_count += 1
                    else:
                        errors.append(f"Document {doc_id}: {result.get('error', 'Unknown error')}")
                finally:
                    # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                    if os.path.exists(tmp_file_path):
                        os.unlink(tmp_file_path)
                        
            except Exception as e:
                errors.append(f"Document {doc_id}: {str(e)}")
        
        # –õ–æ–≥–∏—Ä—É–µ–º –¥–µ–π—Å—Ç–≤–∏–µ
        audit_service = get_audit_service(db)
        audit_service.log_action(
            user_id=current_admin.id,
            action=ActionType.ADMIN_ACTION,
            resource="documents",
            resource_id="reprocess",
            description=f"Reprocessed {processed_count} documents",
            severity=SeverityLevel.MEDIUM
        )
        
        return {
            "message": f"Reprocessed {processed_count} documents",
            "processed": processed_count,
            "total": len(documents_by_id),
            "errors": errors
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {e}")
        raise HTTPException(status_code=500, detail=str(e))
