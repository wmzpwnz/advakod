"""
API –¥–ª—è –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
"""

import asyncio
import logging
import time
from typing import Dict, Any, List
from fastapi import APIRouter, UploadFile, File, HTTPException, BackgroundTasks
from fastapi.responses import JSONResponse

from ..services.smart_document_processor import smart_document_processor
from ..services.vector_store_service import vector_store_service
from ..core.security import validate_file_type, validate_file_size

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/api/smart-upload", tags=["Smart Upload"])


@router.post("/upload-document")
async def upload_document_with_analysis(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(...)
) -> JSONResponse:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç —Å –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º
    """
    try:
        # –í–∞–ª–∏–¥–∞—Ü–∏—è —Ñ–∞–π–ª–∞
        if not validate_file_type(file.filename):
            raise HTTPException(
                status_code=400, 
                detail="–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è: .pdf, .docx, .txt"
            )
        
        if not validate_file_size(file.size):
            raise HTTPException(
                status_code=400,
                detail="–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π. –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: 50MB"
            )
        
        # –ß–∏—Ç–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞
        content = await file.read()
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Ç–µ–∫—Å—Ç (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
        text_content = content.decode('utf-8', errors='ignore')
        
        logger.info(f"üìÅ –ù–∞—á–∏–Ω–∞–µ–º –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É —Ñ–∞–π–ª–∞: {file.filename}")
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç
        result = await smart_document_processor.process_document(
            file_path=file.filename,
            content=text_content
        )
        
        if result["success"]:
            # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–¥–∞—á—É –≤ —Ñ–æ–Ω–æ–≤—ã–µ –∑–∞–¥–∞—á–∏ –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
            background_tasks.add_task(
                post_process_document,
                file.filename,
                result["metadata"]
            )
            
            return JSONResponse({
                "success": True,
                "message": "–î–æ–∫—É–º–µ–Ω—Ç —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω –∏ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω",
                "filename": file.filename,
                "processing_time": result["processing_time"],
                "chunks_created": result["chunks_count"],
                "articles_found": result["articles_count"],
                "sections_found": result["sections_count"],
                "document_type": result["metadata"]["document_type"],
                "structure_score": result["metadata"]["structure_score"]
            })
        else:
            raise HTTPException(
                status_code=500,
                detail=f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {result.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}"
            )
            
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/upload-multiple")
async def upload_multiple_documents(
    background_tasks: BackgroundTasks,
    files: List[UploadFile] = File(...)
) -> JSONResponse:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –∞–Ω–∞–ª–∏–∑–æ–º
    """
    results = []
    errors = []
    
    for file in files:
        try:
            # –í–∞–ª–∏–¥–∞—Ü–∏—è —Ñ–∞–π–ª–∞
            if not validate_file_type(file.filename):
                errors.append({
                    "filename": file.filename,
                    "error": "–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞"
                })
                continue
            
            if not validate_file_size(file.size):
                errors.append({
                    "filename": file.filename,
                    "error": "–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π"
                })
                continue
            
            # –ß–∏—Ç–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
            content = await file.read()
            text_content = content.decode('utf-8', errors='ignore')
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç
            result = await smart_document_processor.process_document(
                file_path=file.filename,
                content=text_content
            )
            
            if result["success"]:
                results.append({
                    "filename": file.filename,
                    "success": True,
                    "chunks_created": result["chunks_count"],
                    "articles_found": result["articles_count"],
                    "document_type": result["metadata"]["document_type"]
                })
                
                # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Ñ–æ–Ω–æ–≤—ã–µ –∑–∞–¥–∞—á–∏
                background_tasks.add_task(
                    post_process_document,
                    file.filename,
                    result["metadata"]
                )
            else:
                errors.append({
                    "filename": file.filename,
                    "error": result.get("error", "–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏")
                })
                
        except Exception as e:
            errors.append({
                "filename": file.filename,
                "error": str(e)
            })
    
    return JSONResponse({
        "success": len(results) > 0,
        "processed_files": len(results),
        "total_files": len(files),
        "results": results,
        "errors": errors
    })


@router.get("/analysis-status/{filename}")
async def get_analysis_status(filename: str) -> JSONResponse:
    """
    –ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç—É—Å –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    """
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç –≤ –±–∞–∑–µ
        collection = vector_store_service.collection
        results = collection.get(
            where={"filename": filename},
            include=["metadatas"]
        )
        
        if not results["ids"]:
            return JSONResponse({
                "found": False,
                "message": "–î–æ–∫—É–º–µ–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"
            })
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        metadatas = results["metadatas"]
        document_type = metadatas[0].get("document_type", "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
        structure_score = metadatas[0].get("structure_score", 0.0)
        total_chunks = metadatas[0].get("total_chunks", 0)
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ç–∏–ø—ã —á–∞–Ω–∫–æ–≤
        chunk_types = {}
        for meta in metadatas:
            chunk_type = meta.get("chunk_type", "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
            chunk_types[chunk_type] = chunk_types.get(chunk_type, 0) + 1
        
        return JSONResponse({
            "found": True,
            "filename": filename,
            "document_type": document_type,
            "structure_score": structure_score,
            "total_chunks": total_chunks,
            "chunk_types": chunk_types,
            "analysis_quality": "–≤—ã—Å–æ–∫–æ–µ" if structure_score > 0.7 else "—Å—Ä–µ–¥–Ω–µ–µ" if structure_score > 0.4 else "–Ω–∏–∑–∫–æ–µ"
        })
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/database-stats")
async def get_database_stats() -> JSONResponse:
    """
    –ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
    """
    try:
        collection = vector_store_service.collection
        count = collection.count()
        
        if count == 0:
            return JSONResponse({
                "total_chunks": 0,
                "documents": [],
                "message": "–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –ø—É—Å—Ç–∞"
            })
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        results = collection.get(include=["metadatas"])
        metadatas = results["metadatas"]
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º
        documents = {}
        for meta in metadatas:
            filename = meta.get("filename", "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
            if filename not in documents:
                documents[filename] = {
                    "filename": filename,
                    "document_type": meta.get("document_type", "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"),
                    "structure_score": meta.get("structure_score", 0.0),
                    "chunks_count": 0,
                    "chunk_types": {}
                }
            
            documents[filename]["chunks_count"] += 1
            chunk_type = meta.get("chunk_type", "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
            documents[filename]["chunk_types"][chunk_type] = documents[filename]["chunk_types"].get(chunk_type, 0) + 1
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        total_chunks = count
        document_count = len(documents)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞—á–µ—Å—Ç–≤–æ
        high_quality = sum(1 for doc in documents.values() if doc["structure_score"] > 0.7)
        medium_quality = sum(1 for doc in documents.values() if 0.4 <= doc["structure_score"] <= 0.7)
        low_quality = sum(1 for doc in documents.values() if doc["structure_score"] < 0.4)
        
        return JSONResponse({
            "total_chunks": total_chunks,
            "document_count": document_count,
            "documents": list(documents.values()),
            "quality_analysis": {
                "high_quality": high_quality,
                "medium_quality": medium_quality,
                "low_quality": low_quality
            }
        })
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.delete("/document/{filename}")
async def delete_document(filename: str) -> JSONResponse:
    """
    –£–¥–∞–ª—è–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
    """
    try:
        collection = vector_store_service.collection
        
        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —á–∞–Ω–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        results = collection.get(
            where={"filename": filename},
            include=["metadatas"]
        )
        
        if not results["ids"]:
            return JSONResponse({
                "success": False,
                "message": "–î–æ–∫—É–º–µ–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"
            })
        
        # –£–¥–∞–ª—è–µ–º –≤—Å–µ —á–∞–Ω–∫–∏
        collection.delete(ids=results["ids"])
        
        logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω –¥–æ–∫—É–º–µ–Ω—Ç: {filename} ({len(results['ids'])} —á–∞–Ω–∫–æ–≤)")
        
        return JSONResponse({
            "success": True,
            "message": f"–î–æ–∫—É–º–µ–Ω—Ç {filename} —É—Å–ø–µ—à–Ω–æ —É–¥–∞–ª–µ–Ω",
            "deleted_chunks": len(results["ids"])
        })
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")
        raise HTTPException(status_code=500, detail=str(e))


async def post_process_document(filename: str, metadata: Dict[str, Any]):
    """
    –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ
    """
    try:
        logger.info(f"üîÑ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {filename}")
        
        # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å:
        # - –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤
        # - –ê–Ω–∞–ª–∏–∑ —Å–≤—è–∑–µ–π –º–µ–∂–¥—É –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏
        # - –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        # - –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑—é–º–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        
        # –ü—Ä–∏–º–µ—Ä: —Å–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑—é–º–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        if metadata.get("document_type") == "—É–≥–æ–ª–æ–≤–Ω—ã–π_–∫–æ–¥–µ–∫—Å":
            logger.info(f"üìã –°–æ–∑–¥–∞–µ–º —Ä–µ–∑—é–º–µ –£–ö –†–§: {filename}")
            # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å —Å–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑—é–º–µ
        
        logger.info(f"‚úÖ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {filename}")
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")


@router.post("/reprocess-document/{filename}")
async def reprocess_document(filename: str) -> JSONResponse:
    """
    –ü–µ—Ä–µ–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –¥–æ–∫—É–º–µ–Ω—Ç
    """
    try:
        # –°–Ω–∞—á–∞–ª–∞ —É–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ
        collection = vector_store_service.collection
        results = collection.get(
            where={"filename": filename},
            include=["metadatas"]
        )
        
        if results["ids"]:
            collection.delete(ids=results["ids"])
            logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω—ã —Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è {filename}")
        
        # –ó–¥–µ—Å—å –Ω—É–∂–Ω–æ –±—ã–ª–æ –±—ã –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª –∑–∞–Ω–æ–≤–æ
        # –ù–æ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –ø—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —É—Å–ø–µ—Ö
        
        return JSONResponse({
            "success": True,
            "message": f"–î–æ–∫—É–º–µ–Ω—Ç {filename} –≥–æ—Ç–æ–≤ –∫ –ø–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∫–µ. –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –∑–∞–Ω–æ–≤–æ."
        })
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
        raise HTTPException(status_code=500, detail=str(e))
