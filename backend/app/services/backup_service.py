"""
–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–µ—Ä–≤–∏—Å –¥–ª—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
"""

import logging
import os
import shutil
import sqlite3
import subprocess
from datetime import datetime, timedelta
from typing import Dict, Any, Optional, List
import asyncio
from pathlib import Path
import json
import hashlib
import zipfile
import tempfile
from croniter import croniter
from sqlalchemy.orm import Session

from ..core.config import settings
from ..core.database import get_db
from ..models.backup import BackupRecord, BackupSchedule, RestoreRecord, BackupIntegrityCheck
from ..models.backup import BackupStatus, BackupType, RestoreStatus
from ..services.notification_service import notification_service

logger = logging.getLogger(__name__)


class EnhancedBackupService:
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–µ—Ä–≤–∏—Å –¥–ª—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è"""
    
    def __init__(self):
        self.backup_dir = os.getenv("BACKUP_DIR", os.path.join(os.getcwd(), "backend", "backups"))
        self.max_backups = int(os.getenv("MAX_BACKUPS", "7"))  # –•—Ä–∞–Ω–∏–º 7 –¥–Ω–µ–π
        self.backup_interval_hours = int(os.getenv("BACKUP_INTERVAL_HOURS", "6"))  # –ö–∞–∂–¥—ã–µ 6 —á–∞—Å–æ–≤
        self.compression_level = int(os.getenv("BACKUP_COMPRESSION_LEVEL", "6"))  # –£—Ä–æ–≤–µ–Ω—å —Å–∂–∞—Ç–∏—è
        self.encryption_key = os.getenv("BACKUP_ENCRYPTION_KEY")  # –ö–ª—é—á —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏—è
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        os.makedirs(self.backup_dir, exist_ok=True)
        os.makedirs(os.path.join(self.backup_dir, "temp"), exist_ok=True)
    
    async def create_backup_with_record(
        self, 
        name: str,
        components: List[str],
        description: Optional[str] = None,
        tags: Optional[List[str]] = None,
        created_by: Optional[int] = None,
        backup_type: BackupType = BackupType.MANUAL,
        compression_enabled: bool = True,
        encryption_enabled: bool = False,
        retention_days: int = 30
    ) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–µ—Ç —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é —Å –∑–∞–ø–∏—Å—å—é –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å –≤ –ë–î
        db = next(get_db())
        backup_record = BackupRecord(
            name=name,
            backup_type=backup_type,
            status=BackupStatus.PENDING,
            created_by=created_by,
            description=description,
            tags=tags,
            retention_days=retention_days,
            compression_enabled=compression_enabled,
            encryption_enabled=encryption_enabled
        )
        
        try:
            db.add(backup_record)
            db.commit()
            db.refresh(backup_record)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –Ω–∞ "–≤ –ø—Ä–æ—Ü–µ—Å—Å–µ"
            backup_record.status = BackupStatus.IN_PROGRESS
            backup_record.started_at = datetime.utcnow()
            db.commit()
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º —Ä–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ
            result = await self._perform_backup(backup_record.id, components, compression_enabled, encryption_enabled)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
            backup_record.status = BackupStatus.COMPLETED if result["success"] else BackupStatus.FAILED
            backup_record.completed_at = datetime.utcnow()
            backup_record.backup_path = result.get("backup_path")
            backup_record.total_size = result.get("total_size", 0)
            backup_record.components = result.get("components", {})
            backup_record.success = result["success"]
            backup_record.error_message = result.get("error")
            backup_record.warnings = result.get("warnings", [])
            backup_record.files_count = result.get("files_count", 0)
            
            if backup_record.started_at and backup_record.completed_at:
                backup_record.duration_seconds = (backup_record.completed_at - backup_record.started_at).total_seconds()
            
            db.commit()
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ
            await self._send_backup_notification(backup_record, result["success"])
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ –≤ —Ñ–æ–Ω–µ
            if result["success"]:
                asyncio.create_task(self._schedule_integrity_check(backup_record.id))
            
            return {
                "backup_id": backup_record.id,
                "success": result["success"],
                "backup_path": result.get("backup_path"),
                "total_size": result.get("total_size", 0),
                "duration_seconds": backup_record.duration_seconds,
                "error": result.get("error"),
                "warnings": result.get("warnings", [])
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏: {e}")
            backup_record.status = BackupStatus.FAILED
            backup_record.completed_at = datetime.utcnow()
            backup_record.error_message = str(e)
            backup_record.success = False
            db.commit()
            
            return {
                "backup_id": backup_record.id,
                "success": False,
                "error": str(e)
            }
        finally:
            db.close()
        
    async def create_backup(self) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–µ—Ç —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö"""
        try:
            # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è –±—ç–∫–∞–ø–æ–≤
            os.makedirs(self.backup_dir, exist_ok=True)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_name = f"advakod_backup_{timestamp}"
            backup_path = os.path.join(self.backup_dir, backup_name)
            
            os.makedirs(backup_path, exist_ok=True)
            
            result = {
                "timestamp": timestamp,
                "backup_path": backup_path,
                "databases": {},
                "success": True,
                "errors": []
            }
            
            # 1. –ë—ç–∫–∞–ø –æ—Å–Ω–æ–≤–Ω–æ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
            db_backup = await self._backup_main_database(backup_path)
            result["databases"]["main"] = db_backup
            
            # 2. –ë—ç–∫–∞–ø –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
            vector_backup = await self._backup_vector_database(backup_path)
            result["databases"]["vector"] = vector_backup
            
            # 3. –ë—ç–∫–∞–ø –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
            config_backup = await self._backup_config_files(backup_path)
            result["databases"]["config"] = config_backup
            
            # 4. –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤
            await self._cleanup_old_backups()
            
            # 5. –°–æ–∑–¥–∞–Ω–∏–µ –º–∞–Ω–∏—Ñ–µ—Å—Ç–∞
            await self._create_backup_manifest(backup_path, result)
            
            logger.info(f"‚úÖ –†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è —Å–æ–∑–¥–∞–Ω–∞: {backup_path}")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏: {e}")
            return {
                "success": False,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    async def _backup_main_database(self, backup_path: str) -> Dict[str, Any]:
        """–ë—ç–∫–∞–ø –æ—Å–Ω–æ–≤–Ω–æ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        try:
            if settings.DATABASE_URL.startswith("sqlite"):
                # SQLite –±—ç–∫–∞–ø
                source_db = settings.DATABASE_URL.replace("sqlite:///", "").replace("sqlite://", "")
                if source_db.startswith("./"):
                    source_db = os.path.join("backend", source_db[2:])
                
                if os.path.exists(source_db):
                    backup_db_path = os.path.join(backup_path, "main_database.db")
                    shutil.copy2(source_db, backup_db_path)
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å
                    conn = sqlite3.connect(backup_db_path)
                    conn.execute("PRAGMA integrity_check")
                    conn.close()
                    
                    file_size = os.path.getsize(backup_db_path)
                    return {
                        "status": "success",
                        "type": "sqlite",
                        "file_path": backup_db_path,
                        "file_size": file_size
                    }
                else:
                    return {"status": "error", "error": "Database file not found"}
                    
            else:
                # PostgreSQL –±—ç–∫–∞–ø
                backup_file = os.path.join(backup_path, "main_database.sql")
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º pg_dump –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è SQL –¥–∞–º–ø–∞
                cmd = [
                    "pg_dump",
                    "--no-password",
                    "--verbose",
                    "--clean",
                    "--no-acl",
                    "--no-owner",
                    "-f", backup_file,
                    settings.DATABASE_URL
                ]
                
                process = await asyncio.create_subprocess_exec(
                    *cmd,
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE
                )
                
                stdout, stderr = await process.communicate()
                
                if process.returncode == 0:
                    file_size = os.path.getsize(backup_file)
                    return {
                        "status": "success",
                        "type": "postgresql",
                        "file_path": backup_file,
                        "file_size": file_size
                    }
                else:
                    return {
                        "status": "error", 
                        "error": stderr.decode() if stderr else "Unknown pg_dump error"
                    }
                    
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –±—ç–∫–∞–ø–∞ –æ—Å–Ω–æ–≤–Ω–æ–π –ë–î: {e}")
            return {"status": "error", "error": str(e)}
    
    async def _backup_vector_database(self, backup_path: str) -> Dict[str, Any]:
        """–ë—ç–∫–∞–ø –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        try:
            # ChromaDB –±—ç–∫–∞–ø
            chroma_source = os.path.join("backend", "data", "chroma_db")
            if os.path.exists(chroma_source):
                chroma_backup = os.path.join(backup_path, "chroma_db")
                shutil.copytree(chroma_source, chroma_backup)
                
                # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä
                total_size = sum(
                    os.path.getsize(os.path.join(dirpath, filename))
                    for dirpath, dirnames, filenames in os.walk(chroma_backup)
                    for filename in filenames
                )
                
                return {
                    "status": "success",
                    "type": "chromadb",
                    "path": chroma_backup,
                    "size": total_size
                }
            else:
                return {"status": "skipped", "reason": "ChromaDB directory not found"}
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –±—ç–∫–∞–ø–∞ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ë–î: {e}")
            return {"status": "error", "error": str(e)}
    
    async def _backup_config_files(self, backup_path: str) -> Dict[str, Any]:
        """–ë—ç–∫–∞–ø –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        try:
            config_backup_path = os.path.join(backup_path, "config")
            os.makedirs(config_backup_path, exist_ok=True)
            
            # –§–∞–π–ª—ã –¥–ª—è –±—ç–∫–∞–ø–∞
            config_files = [
                "backend/app/core/config.py",
                "backend/alembic.ini",
                "backend/requirements.txt",
                ".env"  # –ï—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            ]
            
            backed_up = []
            for config_file in config_files:
                if os.path.exists(config_file):
                    filename = os.path.basename(config_file)
                    backup_file_path = os.path.join(config_backup_path, filename)
                    shutil.copy2(config_file, backup_file_path)
                    backed_up.append(filename)
            
            return {
                "status": "success",
                "files": backed_up,
                "path": config_backup_path
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –±—ç–∫–∞–ø–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
            return {"status": "error", "error": str(e)}
    
    async def _cleanup_old_backups(self):
        """–£–¥–∞–ª—è–µ—Ç —Å—Ç–∞—Ä—ã–µ —Ä–µ–∑–µ—Ä–≤–Ω—ã–µ –∫–æ–ø–∏–∏"""
        try:
            if not os.path.exists(self.backup_dir):
                return
            
            # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –±—ç–∫–∞–ø–æ–≤
            backups = []
            for item in os.listdir(self.backup_dir):
                item_path = os.path.join(self.backup_dir, item)
                if os.path.isdir(item_path) and item.startswith("advakod_backup_"):
                    try:
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞—Ç—É –∏–∑ –∏–º–µ–Ω–∏
                        date_str = item.replace("advakod_backup_", "")
                        backup_date = datetime.strptime(date_str, "%Y%m%d_%H%M%S")
                        backups.append((backup_date, item_path))
                    except ValueError:
                        continue
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ (–Ω–æ–≤—ã–µ –ø–µ—Ä–≤—ã–º–∏)
            backups.sort(key=lambda x: x[0], reverse=True)
            
            # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –±—ç–∫–∞–ø—ã
            if len(backups) > self.max_backups:
                for _, old_backup_path in backups[self.max_backups:]:
                    shutil.rmtree(old_backup_path)
                    logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π –±—ç–∫–∞–ø: {old_backup_path}")
                    
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —Å—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤: {e}")
    
    async def _create_backup_manifest(self, backup_path: str, backup_info: Dict[str, Any]):
        """–°–æ–∑–¥–∞–µ—Ç –º–∞–Ω–∏—Ñ–µ—Å—Ç —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏"""
        try:
            manifest_path = os.path.join(backup_path, "manifest.json")
            
            manifest = {
                "backup_info": backup_info,
                "created_at": datetime.now().isoformat(),
                "version": settings.VERSION,
                "project_name": settings.PROJECT_NAME,
                "environment": settings.ENVIRONMENT,
                "database_url": settings.DATABASE_URL.split("@")[-1] if "@" in settings.DATABASE_URL else "sqlite",  # –°–∫—Ä—ã–≤–∞–µ–º –ø–∞—Ä–æ–ª–∏
                "restore_instructions": {
                    "main_db": "–í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ main_database.db –∏–ª–∏ –∏–º–ø–æ—Ä—Ç–∏—Ä—É–π—Ç–µ main_database.sql",
                    "vector_db": "–°–∫–æ–ø–∏—Ä—É–π—Ç–µ –ø–∞–ø–∫—É chroma_db –≤ backend/data/",
                    "config": "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ config/"
                }
            }
            
            import json
            with open(manifest_path, 'w', encoding='utf-8') as f:
                json.dump(manifest, f, indent=2, ensure_ascii=False)
                
            logger.info(f"üìã –ú–∞–Ω–∏—Ñ–µ—Å—Ç —Å–æ–∑–¥–∞–Ω: {manifest_path}")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –º–∞–Ω–∏—Ñ–µ—Å—Ç–∞: {e}")
    
    async def restore_backup(self, backup_path: str) -> Dict[str, Any]:
        """–í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏"""
        try:
            if not os.path.exists(backup_path):
                return {"status": "error", "error": "Backup path not found"}
            
            # –ß–∏—Ç–∞–µ–º –º–∞–Ω–∏—Ñ–µ—Å—Ç
            manifest_path = os.path.join(backup_path, "manifest.json")
            if os.path.exists(manifest_path):
                import json
                with open(manifest_path, 'r', encoding='utf-8') as f:
                    manifest = json.load(f)
                logger.info(f"üìã –ú–∞–Ω–∏—Ñ–µ—Å—Ç –∑–∞–≥—Ä—É–∂–µ–Ω: {manifest['created_at']}")
            
            result = {"status": "success", "restored": []}
            
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –ë–î
            main_db_path = os.path.join(backup_path, "main_database.db")
            if os.path.exists(main_db_path):
                if settings.DATABASE_URL.startswith("sqlite"):
                    target_db = settings.DATABASE_URL.replace("sqlite:///", "").replace("sqlite://", "")
                    if target_db.startswith("./"):
                        target_db = os.path.join("backend", target_db[2:])
                    
                    shutil.copy2(main_db_path, target_db)
                    result["restored"].append("main_database")
            
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤–µ–∫—Ç–æ—Ä–Ω—É—é –ë–î
            vector_backup_path = os.path.join(backup_path, "chroma_db")
            if os.path.exists(vector_backup_path):
                target_vector_path = os.path.join("backend", "data", "chroma_db")
                if os.path.exists(target_vector_path):
                    shutil.rmtree(target_vector_path)
                shutil.copytree(vector_backup_path, target_vector_path)
                result["restored"].append("vector_database")
            
            logger.info(f"‚úÖ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {result['restored']}")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è: {e}")
            return {"status": "error", "error": str(e)}
    
    def get_backup_status(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã –±—ç–∫–∞–ø–æ–≤"""
        try:
            if not os.path.exists(self.backup_dir):
                return {
                    "status": "no_backups",
                    "backup_dir": self.backup_dir,
                    "backups_count": 0
                }
            
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –±—ç–∫–∞–ø—ã
            backups = []
            total_size = 0
            
            for item in os.listdir(self.backup_dir):
                item_path = os.path.join(self.backup_dir, item)
                if os.path.isdir(item_path) and item.startswith("advakod_backup_"):
                    try:
                        date_str = item.replace("advakod_backup_", "")
                        backup_date = datetime.strptime(date_str, "%Y%m%d_%H%M%S")
                        
                        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä
                        size = sum(
                            os.path.getsize(os.path.join(dirpath, filename))
                            for dirpath, dirnames, filenames in os.walk(item_path)
                            for filename in filenames
                        )
                        total_size += size
                        
                        backups.append({
                            "name": item,
                            "date": backup_date.isoformat(),
                            "size": size,
                            "age_days": (datetime.now() - backup_date).days
                        })
                    except ValueError:
                        continue
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ (–Ω–æ–≤—ã–µ –ø–µ—Ä–≤—ã–º–∏)
            backups.sort(key=lambda x: x["date"], reverse=True)
            
            return {
                "status": "active",
                "backup_dir": self.backup_dir,
                "backups_count": len(backups),
                "total_size": total_size,
                "latest_backup": backups[0] if backups else None,
                "backups": backups[:5],  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5
                "settings": {
                    "max_backups": self.max_backups,
                    "interval_hours": self.backup_interval_hours
                }
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞ –±—ç–∫–∞–ø–æ–≤: {e}")
            return {"status": "error", "error": str(e)}


    async def _perform_backup(
        self, 
        backup_id: int, 
        components: List[str], 
        compression_enabled: bool = True,
        encryption_enabled: bool = False
    ) -> Dict[str, Any]:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç —Ä–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_name = f"backup_{backup_id}_{timestamp}"
            backup_path = os.path.join(self.backup_dir, backup_name)
            
            os.makedirs(backup_path, exist_ok=True)
            
            result = {
                "backup_path": backup_path,
                "components": {},
                "success": True,
                "warnings": [],
                "files_count": 0,
                "total_size": 0
            }
            
            # –†–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
            for component in components:
                if component == "main_db":
                    comp_result = await self._backup_main_database(backup_path)
                elif component == "vector_db":
                    comp_result = await self._backup_vector_database(backup_path)
                elif component == "config":
                    comp_result = await self._backup_config_files(backup_path)
                elif component == "uploads":
                    comp_result = await self._backup_uploads(backup_path)
                elif component == "logs":
                    comp_result = await self._backup_logs(backup_path)
                else:
                    comp_result = {"status": "skipped", "reason": f"Unknown component: {component}"}
                
                result["components"][component] = comp_result
                
                if comp_result.get("status") == "error":
                    result["success"] = False
                elif comp_result.get("status") == "warning":
                    result["warnings"].append(f"{component}: {comp_result.get('warning', 'Unknown warning')}")
                
                # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –∏ —Ñ–∞–π–ª—ã
                if "file_size" in comp_result:
                    result["total_size"] += comp_result["file_size"]
                    result["files_count"] += 1
                elif "size" in comp_result:
                    result["total_size"] += comp_result["size"]
                    result["files_count"] += comp_result.get("files_count", 1)
            
            # –°–æ–∑–¥–∞–µ–º –º–∞–Ω–∏—Ñ–µ—Å—Ç
            await self._create_backup_manifest(backup_path, result)
            
            # –°–∂–∞—Ç–∏–µ –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ
            if compression_enabled and result["success"]:
                compressed_path = await self._compress_backup(backup_path)
                if compressed_path:
                    # –£–¥–∞–ª—è–µ–º –Ω–µ—Å–∂–∞—Ç—É—é –≤–µ—Ä—Å–∏—é
                    shutil.rmtree(backup_path)
                    result["backup_path"] = compressed_path
                    result["total_size"] = os.path.getsize(compressed_path)
            
            # –®–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ
            if encryption_enabled and result["success"] and self.encryption_key:
                encrypted_path = await self._encrypt_backup(result["backup_path"])
                if encrypted_path:
                    os.remove(result["backup_path"])
                    result["backup_path"] = encrypted_path
                    result["total_size"] = os.path.getsize(encrypted_path)
            
            # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤
            await self._cleanup_old_backups()
            
            logger.info(f"‚úÖ –†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è —Å–æ–∑–¥–∞–Ω–∞: {result['backup_path']}")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    async def _backup_uploads(self, backup_path: str) -> Dict[str, Any]:
        """–†–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        try:
            uploads_source = os.path.join("backend", "uploads")
            if os.path.exists(uploads_source):
                uploads_backup = os.path.join(backup_path, "uploads")
                shutil.copytree(uploads_source, uploads_backup)
                
                # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä
                total_size = sum(
                    os.path.getsize(os.path.join(dirpath, filename))
                    for dirpath, dirnames, filenames in os.walk(uploads_backup)
                    for filename in filenames
                )
                
                files_count = sum(
                    len(filenames)
                    for dirpath, dirnames, filenames in os.walk(uploads_backup)
                )
                
                return {
                    "status": "success",
                    "type": "uploads",
                    "path": uploads_backup,
                    "size": total_size,
                    "files_count": files_count
                }
            else:
                return {"status": "skipped", "reason": "Uploads directory not found"}
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –±—ç–∫–∞–ø–∞ –∑–∞–≥—Ä—É–∑–æ–∫: {e}")
            return {"status": "error", "error": str(e)}
    
    async def _backup_logs(self, backup_path: str) -> Dict[str, Any]:
        """–†–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –ª–æ–≥–æ–≤"""
        try:
            logs_backup_path = os.path.join(backup_path, "logs")
            os.makedirs(logs_backup_path, exist_ok=True)
            
            # –ü—É—Ç–∏ –∫ –ª–æ–≥–∞–º
            log_paths = [
                "backend/logs",
                "backend/backend.log",
                "frontend/frontend.log"
            ]
            
            backed_up = []
            total_size = 0
            
            for log_path in log_paths:
                if os.path.exists(log_path):
                    if os.path.isdir(log_path):
                        # –ö–æ–ø–∏—Ä—É–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
                        target_dir = os.path.join(logs_backup_path, os.path.basename(log_path))
                        shutil.copytree(log_path, target_dir)
                        
                        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä
                        dir_size = sum(
                            os.path.getsize(os.path.join(dirpath, filename))
                            for dirpath, dirnames, filenames in os.walk(target_dir)
                            for filename in filenames
                        )
                        total_size += dir_size
                    else:
                        # –ö–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª
                        filename = os.path.basename(log_path)
                        target_file = os.path.join(logs_backup_path, filename)
                        shutil.copy2(log_path, target_file)
                        total_size += os.path.getsize(target_file)
                    
                    backed_up.append(os.path.basename(log_path))
            
            return {
                "status": "success",
                "files": backed_up,
                "path": logs_backup_path,
                "size": total_size,
                "files_count": len(backed_up)
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –±—ç–∫–∞–ø–∞ –ª–æ–≥–æ–≤: {e}")
            return {"status": "error", "error": str(e)}
    
    async def _compress_backup(self, backup_path: str) -> Optional[str]:
        """–°–∂–∏–º–∞–µ—Ç —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é"""
        try:
            compressed_path = f"{backup_path}.zip"
            
            with zipfile.ZipFile(compressed_path, 'w', zipfile.ZIP_DEFLATED, compresslevel=self.compression_level) as zipf:
                for root, dirs, files in os.walk(backup_path):
                    for file in files:
                        file_path = os.path.join(root, file)
                        arcname = os.path.relpath(file_path, backup_path)
                        zipf.write(file_path, arcname)
            
            logger.info(f"üì¶ –†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è —Å–∂–∞—Ç–∞: {compressed_path}")
            return compressed_path
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–∂–∞—Ç–∏—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏: {e}")
            return None
    
    async def _encrypt_backup(self, backup_path: str) -> Optional[str]:
        """–®–∏—Ñ—Ä—É–µ—Ç —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é (–∑–∞–≥–ª—É—à–∫–∞ –¥–ª—è –±—É–¥—É—â–µ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏)"""
        try:
            # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º cryptography
            logger.info(f"üîê –®–∏—Ñ—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏: {backup_path}")
            return backup_path  # –ü–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π –ø—É—Ç—å
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —à–∏—Ñ—Ä–æ–≤–∞–Ω–∏—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏: {e}")
            return None
    
    async def _send_backup_notification(self, backup_record: BackupRecord, success: bool):
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è"""
        try:
            if success:
                message = f"‚úÖ –†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è '{backup_record.name}' —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω–∞"
                notification_type = "success"
            else:
                message = f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏ '{backup_record.name}': {backup_record.error_message}"
                notification_type = "error"
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ —á–µ—Ä–µ–∑ —Å–µ—Ä–≤–∏—Å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π
            # TODO: Implement system notification when notification service is ready
            logger.info(f"üì¢ {message}")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ —Ä–µ–∑–µ—Ä–≤–Ω–æ–º –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}")
    
    async def _schedule_integrity_check(self, backup_id: int):
        """–ü–ª–∞–Ω–∏—Ä—É–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫—É —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏"""
        try:
            # –ñ–¥–µ–º –Ω–µ–º–Ω–æ–≥–æ, —á—Ç–æ–±—ã —Ä–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è –±—ã–ª–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é –∑–∞–ø–∏—Å–∞–Ω–∞
            await asyncio.sleep(10)
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏
            await self.check_backup_integrity(backup_id)
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏: {e}")
    
    async def check_backup_integrity(self, backup_id: int) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏"""
        db = next(get_db())
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –∑–∞–ø–∏—Å—å –æ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏
            backup_record = db.query(BackupRecord).filter(BackupRecord.id == backup_id).first()
            if not backup_record:
                return {"success": False, "error": "Backup record not found"}
            
            if not backup_record.backup_path or not os.path.exists(backup_record.backup_path):
                return {"success": False, "error": "Backup file not found"}
            
            checks = []
            overall_passed = True
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞
            file_size_check = await self._check_file_size(backup_record)
            checks.append(file_size_check)
            if not file_size_check["passed"]:
                overall_passed = False
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∞—Ä—Ö–∏–≤–∞ (–µ—Å–ª–∏ —Å–∂–∞—Ç–æ)
            if backup_record.backup_path.endswith('.zip'):
                archive_check = await self._check_archive_integrity(backup_record)
                checks.append(archive_check)
                if not archive_check["passed"]:
                    overall_passed = False
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∞–Ω–∏—Ñ–µ—Å—Ç–∞
            manifest_check = await self._check_manifest(backup_record)
            checks.append(manifest_check)
            if not manifest_check["passed"]:
                overall_passed = False
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≤–µ—Ä–æ–∫
            for check in checks:
                integrity_check = BackupIntegrityCheck(
                    backup_record_id=backup_id,
                    status="passed" if check["passed"] else "failed",
                    check_type=check["check_type"],
                    passed=check["passed"],
                    error_message=check.get("error"),
                    warnings=check.get("warnings", []),
                    details=check.get("details", {}),
                    files_checked=check.get("files_checked"),
                    size_verified=check.get("size_verified"),
                    checksum_verified=check.get("checksum_verified", False),
                    check_duration_seconds=check.get("duration")
                )
                db.add(integrity_check)
            
            db.commit()
            
            return {
                "success": True,
                "overall_passed": overall_passed,
                "checks": checks
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏: {e}")
            return {"success": False, "error": str(e)}
        finally:
            db.close()
    
    async def _check_file_size(self, backup_record: BackupRecord) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏"""
        start_time = datetime.utcnow()
        
        try:
            actual_size = os.path.getsize(backup_record.backup_path)
            expected_size = backup_record.total_size
            
            # –î–æ–ø—É—Å–∫–∞–µ–º –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –≤ 5% –¥–ª—è —Å–∂–∞—Ç—ã—Ö –∞—Ä—Ö–∏–≤–æ–≤
            tolerance = 0.05 if backup_record.compression_enabled else 0.01
            size_diff = abs(actual_size - expected_size) / expected_size if expected_size > 0 else 0
            
            passed = size_diff <= tolerance
            
            return {
                "check_type": "file_size",
                "passed": passed,
                "size_verified": actual_size,
                "details": {
                    "expected_size": expected_size,
                    "actual_size": actual_size,
                    "size_difference": size_diff,
                    "tolerance": tolerance
                },
                "duration": (datetime.utcnow() - start_time).total_seconds()
            }
            
        except Exception as e:
            return {
                "check_type": "file_size",
                "passed": False,
                "error": str(e),
                "duration": (datetime.utcnow() - start_time).total_seconds()
            }
    
    async def _check_archive_integrity(self, backup_record: BackupRecord) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å –∞—Ä—Ö–∏–≤–∞"""
        start_time = datetime.utcnow()
        
        try:
            with zipfile.ZipFile(backup_record.backup_path, 'r') as zipf:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞—Ä—Ö–∏–≤ –Ω–∞ –æ—à–∏–±–∫–∏
                bad_files = zipf.testzip()
                
                if bad_files:
                    return {
                        "check_type": "archive_integrity",
                        "passed": False,
                        "error": f"Corrupted files in archive: {bad_files}",
                        "duration": (datetime.utcnow() - start_time).total_seconds()
                    }
                
                # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª—ã –≤ –∞—Ä—Ö–∏–≤–µ
                files_in_archive = len(zipf.namelist())
                
                return {
                    "check_type": "archive_integrity",
                    "passed": True,
                    "files_checked": files_in_archive,
                    "details": {
                        "files_in_archive": files_in_archive,
                        "archive_format": "zip"
                    },
                    "duration": (datetime.utcnow() - start_time).total_seconds()
                }
                
        except Exception as e:
            return {
                "check_type": "archive_integrity",
                "passed": False,
                "error": str(e),
                "duration": (datetime.utcnow() - start_time).total_seconds()
            }
    
    async def _check_manifest(self, backup_record: BackupRecord) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –º–∞–Ω–∏—Ñ–µ—Å—Ç —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏"""
        start_time = datetime.utcnow()
        
        try:
            manifest_path = None
            
            if backup_record.backup_path.endswith('.zip'):
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–∞–Ω–∏—Ñ–µ—Å—Ç –∏–∑ –∞—Ä—Ö–∏–≤–∞
                with zipfile.ZipFile(backup_record.backup_path, 'r') as zipf:
                    if 'manifest.json' in zipf.namelist():
                        manifest_content = zipf.read('manifest.json').decode('utf-8')
                        manifest = json.loads(manifest_content)
                    else:
                        return {
                            "check_type": "manifest",
                            "passed": False,
                            "error": "Manifest file not found in archive",
                            "duration": (datetime.utcnow() - start_time).total_seconds()
                        }
            else:
                # –ß–∏—Ç–∞–µ–º –º–∞–Ω–∏—Ñ–µ—Å—Ç –∏–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
                manifest_path = os.path.join(backup_record.backup_path, 'manifest.json')
                if os.path.exists(manifest_path):
                    with open(manifest_path, 'r', encoding='utf-8') as f:
                        manifest = json.load(f)
                else:
                    return {
                        "check_type": "manifest",
                        "passed": False,
                        "error": "Manifest file not found",
                        "duration": (datetime.utcnow() - start_time).total_seconds()
                    }
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –º–∞–Ω–∏—Ñ–µ—Å—Ç–∞
            required_fields = ['backup_info', 'created_at', 'version']
            missing_fields = [field for field in required_fields if field not in manifest]
            
            if missing_fields:
                return {
                    "check_type": "manifest",
                    "passed": False,
                    "error": f"Missing required fields in manifest: {missing_fields}",
                    "duration": (datetime.utcnow() - start_time).total_seconds()
                }
            
            return {
                "check_type": "manifest",
                "passed": True,
                "details": {
                    "manifest_version": manifest.get('version'),
                    "backup_created_at": manifest.get('created_at'),
                    "components": list(manifest.get('backup_info', {}).get('components', {}).keys())
                },
                "duration": (datetime.utcnow() - start_time).total_seconds()
            }
            
        except Exception as e:
            return {
                "check_type": "manifest",
                "passed": False,
                "error": str(e),
                "duration": (datetime.utcnow() - start_time).total_seconds()
            }

    # –ú–µ—Ç–æ–¥—ã –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ–º
    async def create_backup_schedule(
        self,
        name: str,
        cron_expression: str,
        components: List[str],
        created_by: int,
        **kwargs
    ) -> int:
        """–°–æ–∑–¥–∞–µ—Ç —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è"""
        db = next(get_db())
        
        try:
            # –í–∞–ª–∏–¥–∏—Ä—É–µ–º cron –≤—ã—Ä–∞–∂–µ–Ω–∏–µ
            try:
                croniter(cron_expression)
            except Exception:
                raise ValueError("Invalid cron expression")
            
            schedule = BackupSchedule(
                name=name,
                cron_expression=cron_expression,
                backup_components=components,
                created_by=created_by,
                **kwargs
            )
            
            # –í—ã—á–∏—Å–ª—è–µ–º —Å–ª–µ–¥—É—é—â–∏–π –∑–∞–ø—É—Å–∫
            cron = croniter(cron_expression, datetime.utcnow())
            schedule.next_run_at = cron.get_next(datetime)
            
            db.add(schedule)
            db.commit()
            db.refresh(schedule)
            
            logger.info(f"üìÖ –°–æ–∑–¥–∞–Ω–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è: {schedule.name}")
            return schedule.id
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è: {e}")
            db.rollback()
            raise
        finally:
            db.close()
    
    async def get_backup_schedules(self, enabled_only: bool = False) -> List[BackupSchedule]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–π —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è"""
        db = next(get_db())
        
        try:
            query = db.query(BackupSchedule)
            if enabled_only:
                query = query.filter(BackupSchedule.enabled == True)
            
            return query.all()
            
        finally:
            db.close()
    
    async def get_due_schedules(self) -> List[BackupSchedule]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω—ã"""
        db = next(get_db())
        
        try:
            now = datetime.utcnow()
            return db.query(BackupSchedule).filter(
                BackupSchedule.enabled == True,
                BackupSchedule.next_run_at <= now
            ).all()
            
        finally:
            db.close()
    
    async def restore_backup_with_record(
        self,
        restore_id: int,
        backup_path: str,
        components_to_restore: List[str],
        restore_options: dict = None
    ) -> Dict[str, Any]:
        """–í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏ —Å –∑–∞–ø–∏—Å—å—é –≤ –ë–î"""
        db = next(get_db())
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –∑–∞–ø–∏—Å—å –æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–∏
            restore_record = db.query(RestoreRecord).filter(RestoreRecord.id == restore_id).first()
            if not restore_record:
                return {"success": False, "error": "Restore record not found"}
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
            restore_record.status = RestoreStatus.IN_PROGRESS
            restore_record.started_at = datetime.utcnow()
            db.commit()
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ
            result = await self.restore_backup(backup_path)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
            restore_record.status = RestoreStatus.COMPLETED if result["status"] == "success" else RestoreStatus.FAILED
            restore_record.completed_at = datetime.utcnow()
            restore_record.success = result["status"] == "success"
            restore_record.error_message = result.get("error")
            restore_record.restored_components = result.get("restored", [])
            
            if restore_record.started_at and restore_record.completed_at:
                restore_record.duration_seconds = (restore_record.completed_at - restore_record.started_at).total_seconds()
            
            db.commit()
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ
            await self._send_restore_notification(restore_record, result["status"] == "success")
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è —Å –∑–∞–ø–∏—Å—å—é: {e}")
            restore_record.status = RestoreStatus.FAILED
            restore_record.completed_at = datetime.utcnow()
            restore_record.error_message = str(e)
            restore_record.success = False
            db.commit()
            
            return {"success": False, "error": str(e)}
        finally:
            db.close()
    
    async def _send_restore_notification(self, restore_record: RestoreRecord, success: bool):
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è"""
        try:
            if success:
                message = f"‚úÖ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ '{restore_record.name}' —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ"
                notification_type = "success"
            else:
                message = f"‚ùå –û—à–∏–±–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è '{restore_record.name}': {restore_record.error_message}"
                notification_type = "error"
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ —á–µ—Ä–µ–∑ —Å–µ—Ä–≤–∏—Å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π
            # TODO: Implement system notification when notification service is ready
            logger.info(f"üì¢ {message}")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–∏: {e}")
    
    async def get_backup_preview(self, backup_id: int) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∞–µ—Ç –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏"""
        db = next(get_db())
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –∑–∞–ø–∏—Å—å –æ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏
            backup_record = db.query(BackupRecord).filter(BackupRecord.id == backup_id).first()
            if not backup_record:
                raise ValueError("Backup record not found")
            
            if not backup_record.backup_path or not os.path.exists(backup_record.backup_path):
                raise ValueError("Backup file not found")
            
            preview = {
                "backup_id": backup_id,
                "manifest": {},
                "components": backup_record.components or {},
                "file_structure": {},
                "estimated_restore_time": None,
                "compatibility_check": {}
            }
            
            # –ß–∏—Ç–∞–µ–º –º–∞–Ω–∏—Ñ–µ—Å—Ç
            try:
                if backup_record.backup_path.endswith('.zip'):
                    # –ò–∑ –∞—Ä—Ö–∏–≤–∞
                    with zipfile.ZipFile(backup_record.backup_path, 'r') as zipf:
                        if 'manifest.json' in zipf.namelist():
                            manifest_content = zipf.read('manifest.json').decode('utf-8')
                            preview["manifest"] = json.loads(manifest_content)
                        
                        # –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ñ–∞–π–ª–æ–≤
                        preview["file_structure"] = {
                            "files": zipf.namelist(),
                            "total_files": len(zipf.namelist())
                        }
                else:
                    # –ò–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
                    manifest_path = os.path.join(backup_record.backup_path, 'manifest.json')
                    if os.path.exists(manifest_path):
                        with open(manifest_path, 'r', encoding='utf-8') as f:
                            preview["manifest"] = json.load(f)
                    
                    # –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ñ–∞–π–ª–æ–≤
                    files = []
                    for root, dirs, filenames in os.walk(backup_record.backup_path):
                        for filename in filenames:
                            rel_path = os.path.relpath(os.path.join(root, filename), backup_record.backup_path)
                            files.append(rel_path)
                    
                    preview["file_structure"] = {
                        "files": files,
                        "total_files": len(files)
                    }
            except Exception as e:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –º–∞–Ω–∏—Ñ–µ—Å—Ç: {e}")
            
            # –û—Ü–µ–Ω–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è (–ø—Ä–∏–º–µ—Ä–Ω–∞—è)
            if backup_record.total_size:
                # –ü—Ä–∏–º–µ—Ä–Ω–æ 50 –ú–ë/—Å–µ–∫ –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
                estimated_seconds = backup_record.total_size / (50 * 1024 * 1024)
                preview["estimated_restore_time"] = max(60, estimated_seconds)  # –ú–∏–Ω–∏–º—É–º 1 –º–∏–Ω—É—Ç–∞
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            preview["compatibility_check"] = {
                "version_compatible": True,  # TODO: —Ä–µ–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –≤–µ—Ä—Å–∏–π
                "database_compatible": True,  # TODO: –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –ë–î
                "storage_available": self._check_storage_space(backup_record.total_size or 0),
                "services_running": True  # TODO: –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–ø—É—â–µ–Ω–Ω—ã—Ö —Å–µ—Ä–≤–∏—Å–æ–≤
            }
            
            return preview
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞: {e}")
            raise
        finally:
            db.close()
    
    async def validate_restore(
        self, 
        backup_id: int, 
        components_to_restore: List[str], 
        restore_options: Dict[str, Any]
    ) -> Dict[str, Any]:
        """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è"""
        db = next(get_db())
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –∑–∞–ø–∏—Å—å –æ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏
            backup_record = db.query(BackupRecord).filter(BackupRecord.id == backup_id).first()
            if not backup_record:
                raise ValueError("Backup record not found")
            
            validation_errors = []
            validation_warnings = []
            components_status = {}
            file_integrity = {}
            size_verification = {}
            recommendations = []
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏
            if backup_record.status != BackupStatus.COMPLETED:
                validation_errors.append("–†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è –Ω–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∏–ª–∏ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∞")
            
            if not backup_record.success:
                validation_errors.append("–†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è —Å–æ–∑–¥–∞–Ω–∞ —Å –æ—à–∏–±–∫–∞–º–∏")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
            if not backup_record.backup_path or not os.path.exists(backup_record.backup_path):
                validation_errors.append("–§–∞–π–ª —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω")
            else:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
                actual_size = os.path.getsize(backup_record.backup_path)
                expected_size = backup_record.total_size or 0
                
                if expected_size > 0:
                    size_diff = abs(actual_size - expected_size) / expected_size
                    if size_diff > 0.1:  # –ë–æ–ª–µ–µ 10% –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è
                        validation_warnings.append(f"–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç –æ–∂–∏–¥–∞–µ–º–æ–≥–æ –Ω–∞ {size_diff*100:.1f}%")
                
                size_verification["expected"] = expected_size
                size_verification["actual"] = actual_size
                size_verification["valid"] = size_diff <= 0.1 if expected_size > 0 else True
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
            available_components = list((backup_record.components or {}).keys())
            for component in components_to_restore:
                if component not in available_components:
                    validation_errors.append(f"–ö–æ–º–ø–æ–Ω–µ–Ω—Ç '{component}' –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –≤ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏")
                    components_status[component] = "missing"
                else:
                    component_info = backup_record.components.get(component, {})
                    if component_info.get("status") == "success":
                        components_status[component] = "valid"
                    else:
                        validation_warnings.append(f"–ö–æ–º–ø–æ–Ω–µ–Ω—Ç '{component}' –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–≤—Ä–µ–∂–¥–µ–Ω")
                        components_status[component] = "warning"
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–µ—Å—Ç–æ –Ω–∞ –¥–∏—Å–∫–µ
            if backup_record.total_size:
                if not self._check_storage_space(backup_record.total_size):
                    validation_errors.append("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –º–µ—Å—Ç–∞ –Ω–∞ –¥–∏—Å–∫–µ –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–ø—Ü–∏–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
            if restore_options.get("overwrite_existing") and not restore_options.get("create_backup_before_restore"):
                validation_warnings.append("–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —Å–æ–∑–¥–∞—Ç—å —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é –ø–µ—Ä–µ–¥ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—å—é –¥–∞–Ω–Ω—ã—Ö")
                recommendations.append("–í–∫–ª—é—á–∏—Ç–µ –æ–ø—Ü–∏—é '–°–æ–∑–¥–∞—Ç—å —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é –ø–µ—Ä–µ–¥ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ–º'")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å –∞—Ä—Ö–∏–≤–∞ (–µ—Å–ª–∏ —ç—Ç–æ –∞—Ä—Ö–∏–≤)
            if backup_record.backup_path.endswith('.zip'):
                try:
                    with zipfile.ZipFile(backup_record.backup_path, 'r') as zipf:
                        bad_files = zipf.testzip()
                        if bad_files:
                            validation_errors.append(f"–ü–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –≤ –∞—Ä—Ö–∏–≤–µ: {bad_files}")
                            file_integrity["archive"] = False
                        else:
                            file_integrity["archive"] = True
                except Exception as e:
                    validation_errors.append(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∞—Ä—Ö–∏–≤–∞: {str(e)}")
                    file_integrity["archive"] = False
            
            # –û–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            if not restore_options.get("validate_before_restore"):
                recommendations.append("–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –≤–∫–ª—é—á–∏—Ç—å –≤–∞–ª–∏–¥–∞—Ü–∏—é –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–¥ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ–º")
            
            if not restore_options.get("stop_services_during_restore"):
                recommendations.append("–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Å–µ—Ä–≤–∏—Å—ã –≤–æ –≤—Ä–µ–º—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è")
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–±—â–∏–π —Å—Ç–∞—Ç—É—Å –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            is_valid = len(validation_errors) == 0
            
            return {
                "backup_id": backup_id,
                "is_valid": is_valid,
                "validation_errors": validation_errors,
                "validation_warnings": validation_warnings,
                "components_status": components_status,
                "file_integrity": file_integrity,
                "size_verification": size_verification,
                "recommendations": recommendations
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è: {e}")
            return {
                "backup_id": backup_id,
                "is_valid": False,
                "validation_errors": [f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {str(e)}"],
                "validation_warnings": [],
                "components_status": {},
                "file_integrity": {},
                "size_verification": {},
                "recommendations": []
            }
        finally:
            db.close()
    
    def _check_storage_space(self, required_bytes: int) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ–µ –º–µ—Å—Ç–æ –Ω–∞ –¥–∏—Å–∫–µ"""
        try:
            import shutil
            total, used, free = shutil.disk_usage("/")
            return free > required_bytes * 1.2  # 20% –∑–∞–ø–∞—Å
        except Exception:
            return True  # –ï—Å–ª–∏ –Ω–µ –º–æ–∂–µ–º –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, —Å—á–∏—Ç–∞–µ–º —á—Ç–æ –º–µ—Å—Ç–∞ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ

# –°–æ–∑–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
backup_service = EnhancedBackupService()


async def schedule_automatic_backups():
    """–ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –±—ç–∫–∞–ø–æ–≤"""
    while True:
        try:
            logger.info("üîÑ –ó–∞–ø—É—Å–∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è...")
            result = await backup_service.create_backup()
            
            if result["success"]:
                logger.info(f"‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –±—ç–∫–∞–ø –∑–∞–≤–µ—Ä—à–µ–Ω: {result['backup_path']}")
            else:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –±—ç–∫–∞–ø–∞: {result.get('error')}")
            
            # –ñ–¥–µ–º –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ –±—ç–∫–∞–ø–∞
            await asyncio.sleep(backup_service.backup_interval_hours * 3600)
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞ –±—ç–∫–∞–ø–æ–≤: {e}")
            await asyncio.sleep(3600)  # –ü–æ–≤—Ç–æ—Ä—è–µ–º —á–µ—Ä–µ–∑ —á–∞—Å –ø—Ä–∏ –æ—à–∏–±–∫–µ
