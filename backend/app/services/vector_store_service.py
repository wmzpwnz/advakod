"""
–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö (ChromaDB)
–•—Ä–∞–Ω–∏—Ç –∏ –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è RAG —Å–∏—Å—Ç–µ–º—ã
"""

import logging
import chromadb
from chromadb.config import Settings
import os
from typing import List, Dict, Any, Optional, Tuple, Union
import uuid
import json
from datetime import datetime, date
from ..core.date_utils import DateUtils

logger = logging.getLogger(__name__)

class VectorStoreService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö"""
    
    def __init__(self):
        self.client = None
        self.collection = None
        self.collection_name = os.getenv("CHROMA_COLLECTION_NAME", "legal_documents")
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å –æ—Ç –∫–æ—Ä–Ω—è –ø—Ä–æ–µ–∫—Ç–∞
        self.db_path = os.getenv("CHROMA_DB_PATH", os.path.join(os.getcwd(), "backend", "data", "chroma_db"))
        self.is_initialized = False
        # –ù–ï –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ - —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏
        
    def initialize(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ChromaDB"""
        try:
            # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
            os.makedirs(self.db_path, exist_ok=True)
            
            logger.info(f"üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º ChromaDB –≤ {self.db_path}")
            
            # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç ChromaDB
            self.client = chromadb.PersistentClient(
                path=self.db_path,
                settings=Settings(
                    anonymized_telemetry=False,
                    allow_reset=True
                )
            )
            
            # –ü–æ–ª—É—á–∞–µ–º –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é
            try:
                self.collection = self.client.get_collection(name=self.collection_name)
                logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∞—è –∫–æ–ª–ª–µ–∫—Ü–∏—è: {self.collection_name}")
            except Exception:
                self.collection = self.client.create_collection(
                    name=self.collection_name,
                    metadata={"description": "–ö–æ–ª–ª–µ–∫—Ü–∏—è —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è RAG"},
                    embedding_function=None  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å ChromaDB
                )
                logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω–∞ –Ω–æ–≤–∞—è –∫–æ–ª–ª–µ–∫—Ü–∏—è: {self.collection_name}")
            
            self.is_initialized = True
            logger.info("‚úÖ ChromaDB —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            try:
                count = self.collection.count()
                logger.info(f"üìä –í –∫–æ–ª–ª–µ–∫—Ü–∏–∏ {count} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {e}")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ ChromaDB: {e}")
            self.is_initialized = False
    
    def is_ready(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –≥–æ—Ç–æ–≤–∞ –ª–∏ –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∫ —Ä–∞–±–æ—Ç–µ"""
        return self.is_initialized and self.client is not None and self.collection is not None
    
    def get_status(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç—É—Å —Å–µ—Ä–≤–∏—Å–∞"""
        count = 0
        if self.is_ready():
            try:
                count = self.collection.count()
            except:
                count = 0
                
        return {
            "initialized": self.is_initialized,
            "db_path": self.db_path,
            "collection_name": self.collection_name,
            "documents_count": count
        }
    
    def _validate_embedding(self, embedding) -> list:
        """Validates embedding data before storing"""
        import numpy as np
        
        if embedding is None:
            raise ValueError("Embedding cannot be None")
            
        try:
            # Convert to numpy array for validation
            arr = np.asarray(embedding, dtype=float)
            
            # Check dimensions
            if arr.ndim != 1:
                raise ValueError(f"Embedding must be 1-dimensional, got {arr.ndim}D")
                
            # Check for invalid values
            if np.isnan(arr).any():
                raise ValueError("Embedding contains NaN values")
                
            if np.isinf(arr).any():
                raise ValueError("Embedding contains infinite values")
                
            # Check reasonable size (typical embeddings are 384-1536 dimensions)
            if len(arr) < 50 or len(arr) > 5000:
                raise ValueError(f"Embedding dimension {len(arr)} seems unreasonable")
                
            return arr.tolist()
            
        except (ValueError, TypeError) as e:
            logger.error(f"Embedding validation failed: {e}")
            raise ValueError(f"Invalid embedding data: {e}")
    
    def _validate_metadata(self, metadata: Dict[str, Any]) -> Dict[str, Any]:
        """Validates and sanitizes metadata"""
        if not isinstance(metadata, dict):
            raise ValueError("Metadata must be a dictionary")
            
        # Allowed metadata keys to prevent injection
        ALLOWED_KEYS = {
            "source", "article", "valid_from", "valid_to", "edition",
            "title", "filename", "content_length", "added_at", "part", "item"
        }
        
        sanitized = {}
        for key, value in metadata.items():
            if key in ALLOWED_KEYS:
                # Ensure values are safe types
                if isinstance(value, (str, int, float, bool, type(None))):
                    sanitized[key] = value
                else:
                    sanitized[key] = str(value)
                    
        return sanitized 
    def add_document(self, 
                    content: str, 
                    metadata: Dict[str, Any],
                    document_id: Optional[str] = None,
                    embedding: Optional[List[float]] = None) -> bool:
        """–î–æ–±–∞–≤–ª—è–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏
        if not self.is_ready():
            logger.info("üîÑ Vector store –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω, –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—é...")
            self.initialize()
        
        if not self.is_ready():
            logger.warning("VectorStore –Ω–µ –≥–æ—Ç–æ–≤")
            return False
            
        try:
            # Validate inputs
            if not content or not content.strip():
                raise ValueError("Document content cannot be empty")
                
            # Validate and sanitize metadata
            sanitized_metadata = self._validate_metadata(metadata)
            
            # Validate embedding if provided
            if embedding is not None:
                validated_embedding = self._validate_embedding(embedding)
            else:
                validated_embedding = None
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º ID –µ—Å–ª–∏ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω
            if not document_id:
                document_id = str(uuid.uuid4())
            
            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            sanitized_metadata.update({
                "added_at": datetime.now().isoformat(),
                "content_length": len(content)
            })
            
            # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é
            if validated_embedding:
                self.collection.add(
                    documents=[content],
                    metadatas=[sanitized_metadata],
                    ids=[document_id],
                    embeddings=[validated_embedding]
                )
            else:
                self.collection.add(
                    documents=[content],
                    metadatas=[sanitized_metadata],
                    ids=[document_id]
                )
            
            logger.info(f"‚úÖ –î–æ–∫—É–º–µ–Ω—Ç –¥–æ–±–∞–≤–ª–µ–Ω: {document_id} (–¥–ª–∏–Ω–∞: {len(content)} —Å–∏–º–≤–æ–ª–æ–≤)")
            return True
            
        except ValueError as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")
            return False
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")
            return False
    
    async def add_documents(self, 
                           documents: List[Dict[str, Any]]) -> int:
        """–î–æ–±–∞–≤–ª—è–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
        if not self.is_ready():
            logger.warning("VectorStore –Ω–µ –≥–æ—Ç–æ–≤")
            return 0
            
        added_count = 0
        for doc in documents:
            success = await self.add_document(
                content=doc.get("content", ""),
                metadata=doc.get("metadata", {}),
                document_id=doc.get("id")
            )
            if success:
                added_count += 1
                
        logger.info(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {added_count}/{len(documents)}")
        return added_count
    
    async def search_similar(self, 
                           query: str, 
                           limit: int = 5,
                           min_similarity: float = 0.5,
                           situation_date: Optional[Union[str, date, datetime]] = None) -> List[Dict[str, Any]]:
        """–ò—â–µ—Ç –ø–æ—Ö–æ–∂–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ –∑–∞–ø—Ä–æ—Å—É"""
        if not self.is_ready():
            logger.warning("VectorStore –Ω–µ –≥–æ—Ç–æ–≤")
            return []
            
        try:
            # Create date filter if situation_date is provided
            where_filter = None
            if situation_date:
                where_filter = DateUtils.create_date_filter(situation_date)
                logger.info(f"üìÖ –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä –ø–æ –¥–∞—Ç–µ: {situation_date} -> {where_filter}")
            
            logger.info(f"üîç –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫: '{query[:50]}...' (limit={limit}, min_similarity={min_similarity})")
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ —Å —É—á–µ—Ç–æ–º —Ñ–∏–ª—å—Ç—Ä–∞ –ø–æ –¥–∞—Ç–µ
            search_kwargs = {
                "query_texts": [query],
                "n_results": limit,
                "include": ['documents', 'metadatas', 'distances']
            }
            
            if where_filter:
                search_kwargs["where"] = where_filter
                
            results = self.collection.query(**search_kwargs)
            
            logger.info(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞: {len(results.get('documents', [[]])[0])} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–∞–π–¥–µ–Ω–æ")
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            documents = []
            if results['documents'] and len(results['documents']) > 0:
                docs = results['documents'][0]
                metadatas = results['metadatas'][0] if results['metadatas'] else []
                distances = results['distances'][0] if results['distances'] else []
                
                logger.info(f"üìã –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º {len(docs)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, {len(metadatas)} –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö, {len(distances)} —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π")
                
                for i, content in enumerate(docs):
                    # ChromaDB –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ (—á–µ–º –º–µ–Ω—å—à–µ, —Ç–µ–º –ª—É—á—à–µ)
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å—Ö–æ–¥—Å—Ç–≤–æ (—á–µ–º –±–æ–ª—å—à–µ, —Ç–µ–º –ª—É—á—à–µ)
                    distance = distances[i] if i < len(distances) else 1.0
                    similarity = 1.0 - distance  # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
                    
                    logger.info(f"üìÑ –î–æ–∫—É–º–µ–Ω—Ç {i+1}: similarity={similarity:.3f}, distance={distance:.3f}, content_length={len(content)}")
                    
                    if similarity >= min_similarity:
                        documents.append({
                            "content": content,
                            "metadata": metadatas[i] if i < len(metadatas) else {},
                            "similarity": similarity,
                            "distance": distance
                        })
                        logger.info(f"‚úÖ –î–æ–∫—É–º–µ–Ω—Ç {i+1} –ø—Ä–æ—à–µ–ª —Ñ–∏–ª—å—Ç—Ä –ø–æ —Å—Ö–æ–¥—Å—Ç–≤—É")
                    else:
                        logger.info(f"‚ùå –î–æ–∫—É–º–µ–Ω—Ç {i+1} –Ω–µ –ø—Ä–æ—à–µ–ª —Ñ–∏–ª—å—Ç—Ä –ø–æ —Å—Ö–æ–¥—Å—Ç–≤—É (similarity={similarity:.3f} < {min_similarity})")
            
            logger.info(f"üîç –ò—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏")
            return documents
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")
            return []
    
    async def get_document(self, document_id: str) -> Optional[Dict[str, Any]]:
        """–ü–æ–ª—É—á–∞–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –ø–æ ID"""
        if not self.is_ready():
            logger.warning("VectorStore –Ω–µ –≥–æ—Ç–æ–≤")
            return None
            
        try:
            results = self.collection.get(
                ids=[document_id],
                include=['documents', 'metadatas']
            )
            
            if results['documents'] and len(results['documents']) > 0:
                return {
                    "id": document_id,
                    "content": results['documents'][0],
                    "metadata": results['metadatas'][0] if results['metadatas'] else {}
                }
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ {document_id}: {e}")
            
        return None
    
    async def delete_document(self, document_id: str) -> bool:
        """–£–¥–∞–ª—è–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –ø–æ ID"""
        if not self.is_ready():
            logger.warning("VectorStore –Ω–µ –≥–æ—Ç–æ–≤")
            return False
            
        try:
            self.collection.delete(ids=[document_id])
            logger.info(f"üóëÔ∏è –î–æ–∫—É–º–µ–Ω—Ç —É–¥–∞–ª–µ–Ω: {document_id}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ {document_id}: {e}")
            return False
    
    async def clear_collection(self) -> bool:
        """–û—á–∏—â–∞–µ—Ç –≤—Å—é –∫–æ–ª–ª–µ–∫—Ü–∏—é"""
        if not self.is_ready():
            logger.warning("VectorStore –Ω–µ –≥–æ—Ç–æ–≤")
            return False
            
        try:
            # –£–¥–∞–ª—è–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é –∏ —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é
            self.client.delete_collection(name=self.collection_name)
            self.collection = self.client.create_collection(
                name=self.collection_name,
                metadata={"description": "–ö–æ–ª–ª–µ–∫—Ü–∏—è —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è RAG"}
            )
            logger.info("üóëÔ∏è –ö–æ–ª–ª–µ–∫—Ü–∏—è –æ—á–∏—â–µ–Ω–∞")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –∫–æ–ª–ª–µ–∫—Ü–∏–∏: {e}")
            return False

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–µ—Ä–≤–∏—Å–∞
vector_store_service = VectorStoreService()
