"""
–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö (ChromaDB)
–•—Ä–∞–Ω–∏—Ç –∏ –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è RAG —Å–∏—Å—Ç–µ–º—ã
"""

import logging
import chromadb
from chromadb.config import Settings
import os
from typing import List, Dict, Any, Optional, Tuple, Union
import uuid
import json
from datetime import datetime, date
from ..core.date_utils import DateUtils

logger = logging.getLogger(__name__)

class VectorStoreService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö"""
    
    def __init__(self):
        self.client = None
        self.collection = None
        self.collection_name = os.getenv("CHROMA_COLLECTION_NAME", "legal_documents")
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å –æ—Ç –∫–æ—Ä–Ω—è –ø—Ä–æ–µ–∫—Ç–∞
        self.db_path = os.getenv("CHROMA_DB_PATH", os.path.join(os.getcwd(), "data", "chroma_db"))
        self.is_initialized = False
        # –ù–ï –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ - —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏
        
    def _check_schema_compatibility(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å—Ö–µ–º—ã ChromaDB"""
        try:
            import sqlite3
            sqlite_path = os.path.join(self.db_path, "chroma.sqlite3")
            
            if not os.path.exists(sqlite_path):
                # –ù–æ–≤–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö - —Å—Ö–µ–º–∞ –±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
                logger.info("üìÅ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö ChromaDB –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç - –±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω–∞ –Ω–æ–≤–∞—è")
                return True
                
            with sqlite3.connect(sqlite_path) as conn:
                cursor = conn.cursor()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ç–∞–±–ª–∏—Ü—ã collections
                cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='collections'")
                if not cursor.fetchone():
                    logger.info("üìã –¢–∞–±–ª–∏—Ü–∞ collections –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç - –±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω–∞")
                    return True  # –¢–∞–±–ª–∏—Ü–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç - –±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω–∞
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–∫–∏ topic –≤ —Ç–∞–±–ª–∏—Ü–µ collections
                cursor.execute("PRAGMA table_info(collections)")
                columns = [row[1] for row in cursor.fetchall()]
                
                if 'topic' not in columns:
                    logger.warning("‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å—Ö–µ–º—ã ChromaDB: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–ª–æ–Ω–∫–∞ 'topic'")
                    return False
                
                logger.info("‚úÖ –°—Ö–µ–º–∞ ChromaDB —Å–æ–≤–º–µ—Å—Ç–∏–º–∞")
                return True
                
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ö–µ–º—É ChromaDB: {e}")
            return True  # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é
    
    def _migrate_schema_if_needed(self) -> bool:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –º–∏–≥—Ä–∞—Ü–∏—é —Å—Ö–µ–º—ã –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ"""
        try:
            if self._check_schema_compatibility():
                return True
                
            logger.info("üîÑ –í—ã–ø–æ–ª–Ω—è–µ–º –º–∏–≥—Ä–∞—Ü–∏—é —Å—Ö–µ–º—ã ChromaDB...")
            
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∏ –∑–∞–ø—É—Å–∫–∞–µ–º –º–∏–≥—Ä–∞—Ü–∏—é
            import subprocess
            import sys
            
            migration_script = os.path.join(
                os.path.dirname(os.path.dirname(os.path.dirname(__file__))),
                "scripts", "chromadb_migration.py"
            )
            
            if os.path.exists(migration_script):
                result = subprocess.run([
                    sys.executable, migration_script, 
                    "--db-path", self.db_path,
                    "--force"
                ], capture_output=True, text=True)
                
                if result.returncode == 0:
                    logger.info("‚úÖ –ú–∏–≥—Ä–∞—Ü–∏—è —Å—Ö–µ–º—ã ChromaDB –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
                    return True
                else:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –º–∏–≥—Ä–∞—Ü–∏–∏ —Å—Ö–µ–º—ã: {result.stderr}")
                    return False
            else:
                logger.error(f"‚ùå –°–∫—Ä–∏–ø—Ç –º–∏–≥—Ä–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {migration_script}")
                return False
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –º–∏–≥—Ä–∞—Ü–∏–∏ —Å—Ö–µ–º—ã: {e}")
            return False

    def initialize(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ChromaDB"""
        try:
            # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
            os.makedirs(self.db_path, exist_ok=True)
            
            logger.info(f"üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º ChromaDB –≤ {self.db_path}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –º–∏–≥—Ä–∏—Ä—É–µ–º —Å—Ö–µ–º—É –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
            if not self._migrate_schema_if_needed():
                logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –º–∏–≥—Ä–∞—Ü–∏—é —Å—Ö–µ–º—ã ChromaDB")
                self.is_initialized = False
                return
            
            # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç ChromaDB
            self.client = chromadb.PersistentClient(
                path=self.db_path,
                settings=Settings(
                    anonymized_telemetry=False,
                    allow_reset=True
                )
            )
            
            # –ü–æ–ª—É—á–∞–µ–º –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é
            try:
                self.collection = self.client.get_collection(name=self.collection_name)
                logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∞—è –∫–æ–ª–ª–µ–∫—Ü–∏—è: {self.collection_name}")
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ embedding function —É —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏
                # –ï—Å–ª–∏ –∫–æ–ª–ª–µ–∫—Ü–∏—è –±—ã–ª–∞ —Å–æ–∑–¥–∞–Ω–∞ –±–µ–∑ embedding function, ChromaDB —Ç—Ä–µ–±—É–µ—Ç embeddings –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏
            except Exception:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω—É—é embedding function ChromaDB
                try:
                    from chromadb.utils import embedding_functions
                    default_ef = embedding_functions.DefaultEmbeddingFunction()
                    logger.info("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º DefaultEmbeddingFunction –¥–ª—è –Ω–æ–≤–æ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏")
                except (ImportError, AttributeError) as e:
                    # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º None
                    default_ef = None
                    logger.warning(f"‚ö†Ô∏è DefaultEmbeddingFunction –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞ ({e}), –∫–æ–ª–ª–µ–∫—Ü–∏—è –±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω–∞ –±–µ–∑ embedding function")
                
                self.collection = self.client.create_collection(
                    name=self.collection_name,
                    metadata={"description": "–ö–æ–ª–ª–µ–∫—Ü–∏—è —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è RAG"},
                    embedding_function=default_ef
                )
                logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω–∞ –Ω–æ–≤–∞—è –∫–æ–ª–ª–µ–∫—Ü–∏—è: {self.collection_name}")
            
            self.is_initialized = True
            logger.info("‚úÖ ChromaDB —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            try:
                count = self.collection.count()
                logger.info(f"üìä –í –∫–æ–ª–ª–µ–∫—Ü–∏–∏ {count} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {e}")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ ChromaDB: {e}")
            logger.error(f"–í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:")
            logger.error(f"  1. –ù–µ—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –≤–µ—Ä—Å–∏–π ChromaDB")
            logger.error(f"  2. –ü–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö")
            logger.error(f"  3. –ü—Ä–æ–±–ª–µ–º—ã —Å –ø—Ä–∞–≤–∞–º–∏ –¥–æ—Å—Ç—É–ø–∞")
            logger.error(f"–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å –º–∏–≥—Ä–∞—Ü–∏—é: python scripts/chromadb_migration.py")
            self.is_initialized = False
    
    def is_ready(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –≥–æ—Ç–æ–≤–∞ –ª–∏ –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∫ —Ä–∞–±–æ—Ç–µ"""
        return self.is_initialized and self.client is not None and self.collection is not None
    
    def get_status(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç—É—Å —Å–µ—Ä–≤–∏—Å–∞"""
        count = 0
        if self.is_ready():
            try:
                count = self.collection.count()
            except:
                count = 0
                
        return {
            "initialized": self.is_initialized,
            "db_path": self.db_path,
            "collection_name": self.collection_name,
            "documents_count": count
        }
    
    def _validate_embedding(self, embedding) -> list:
        """Validates embedding data before storing"""
        import numpy as np
        
        if embedding is None:
            raise ValueError("Embedding cannot be None")
            
        try:
            # Convert to numpy array for validation
            arr = np.asarray(embedding, dtype=float)
            
            # Check dimensions
            if arr.ndim != 1:
                raise ValueError(f"Embedding must be 1-dimensional, got {arr.ndim}D")
                
            # Check for invalid values
            if np.isnan(arr).any():
                raise ValueError("Embedding contains NaN values")
                
            if np.isinf(arr).any():
                raise ValueError("Embedding contains infinite values")
                
            # Check reasonable size (typical embeddings are 384-1536 dimensions)
            if len(arr) < 50 or len(arr) > 5000:
                raise ValueError(f"Embedding dimension {len(arr)} seems unreasonable")
                
            return arr.tolist()
            
        except (ValueError, TypeError) as e:
            logger.error(f"Embedding validation failed: {e}")
            raise ValueError(f"Invalid embedding data: {e}")
    
    def _validate_metadata(self, metadata: Dict[str, Any]) -> Dict[str, Any]:
        """Validates and sanitizes metadata"""
        if not isinstance(metadata, dict):
            raise ValueError("Metadata must be a dictionary")
            
        # Allowed metadata keys to prevent injection
        ALLOWED_KEYS = {
            "source", "article", "valid_from", "valid_to", "edition",
            "title", "filename", "content_length", "added_at", "part", "item",
            # –ö–ª—é—á–∏ –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏ —á–∞–Ω–∫–æ–≤
            "document_id", "chunk_index", "chunk_length", "is_chunk",
            # –ö–ª—é—á–∏ –¥–ª—è –∫–æ–¥–µ–∫—Å–æ–≤
            "codex_name", "document_name", "document_type", "type",
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            "file_size", "size", "file_hash", "file_extension", "processed_at",
            "chunks_count", "total_length", "validation_confidence", "legal_score",
            "is_validated", "version", "status", "is_draft", "pages",
            "source_path", "language", "method_used", "upload_date"
        }
        
        sanitized = {}
        for key, value in metadata.items():
            if key in ALLOWED_KEYS:
                # Ensure values are safe types
                if isinstance(value, (str, int, float, bool, type(None))):
                    sanitized[key] = value
                else:
                    sanitized[key] = str(value)
                    
        return sanitized 
    def add_document(self, 
                    content: str, 
                    metadata: Dict[str, Any],
                    document_id: Optional[str] = None,
                    embedding: Optional[List[float]] = None) -> bool:
        """–î–æ–±–∞–≤–ª—è–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏
        if not self.is_ready():
            logger.info("üîÑ Vector store –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω, –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—é...")
            self.initialize()
        
        if not self.is_ready():
            logger.warning("VectorStore –Ω–µ –≥–æ—Ç–æ–≤")
            return False
            
        try:
            # Validate inputs
            if not content or not content.strip():
                raise ValueError("Document content cannot be empty")
                
            # Validate and sanitize metadata
            sanitized_metadata = self._validate_metadata(metadata)
            
            # Validate embedding if provided
            if embedding is not None:
                validated_embedding = self._validate_embedding(embedding)
            else:
                validated_embedding = None
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º ID –µ—Å–ª–∏ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω
            if not document_id:
                document_id = str(uuid.uuid4())
            
            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            sanitized_metadata.update({
                "added_at": datetime.now().isoformat(),
                "content_length": len(content)
            })
            
            # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é
            if validated_embedding:
                self.collection.add(
                    documents=[content],
                    metadatas=[sanitized_metadata],
                    ids=[document_id],
                    embeddings=[validated_embedding]
                )
            else:
                self.collection.add(
                    documents=[content],
                    metadatas=[sanitized_metadata],
                    ids=[document_id]
                )
            
            logger.info(f"‚úÖ –î–æ–∫—É–º–µ–Ω—Ç –¥–æ–±–∞–≤–ª–µ–Ω: {document_id} (–¥–ª–∏–Ω–∞: {len(content)} —Å–∏–º–≤–æ–ª–æ–≤)")
            return True
            
        except ValueError as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")
            return False
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")
            return False
    
    async def add_documents(self, 
                           documents: List[Dict[str, Any]]) -> int:
        """–î–æ–±–∞–≤–ª—è–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
        if not self.is_ready():
            logger.warning("VectorStore –Ω–µ –≥–æ—Ç–æ–≤")
            return 0
            
        added_count = 0
        for doc in documents:
            success = await self.add_document(
                content=doc.get("content", ""),
                metadata=doc.get("metadata", {}),
                document_id=doc.get("id")
            )
            if success:
                added_count += 1
                
        logger.info(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {added_count}/{len(documents)}")
        return added_count
    
    async def search_similar(self, 
                           query: str, 
                           limit: int = 5,
                           min_similarity: float = 0.5,
                           situation_date: Optional[Union[str, date, datetime]] = None) -> List[Dict[str, Any]]:
        """–ò—â–µ—Ç –ø–æ—Ö–æ–∂–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ –∑–∞–ø—Ä–æ—Å—É"""
        if not self.is_ready():
            logger.warning("VectorStore –Ω–µ –≥–æ—Ç–æ–≤")
            return []
            
        try:
            # Create date filter if situation_date is provided
            where_filter = None
            if situation_date:
                where_filter = DateUtils.create_date_filter(situation_date)
                logger.info(f"üìÖ –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä –ø–æ –¥–∞—Ç–µ: {situation_date} -> {where_filter}")
            
            logger.info(f"üîç –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫: '{query[:50]}...' (limit={limit}, min_similarity={min_similarity})")
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ —Å —É—á–µ—Ç–æ–º —Ñ–∏–ª—å—Ç—Ä–∞ –ø–æ –¥–∞—Ç–µ
            search_kwargs = {
                "query_texts": [query],
                "n_results": limit,
                "include": ['documents', 'metadatas', 'distances']
            }
            
            if where_filter:
                search_kwargs["where"] = where_filter
                
            results = self.collection.query(**search_kwargs)
            
            logger.info(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞: {len(results.get('documents', [[]])[0])} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–∞–π–¥–µ–Ω–æ")
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            documents = []
            if results['documents'] and len(results['documents']) > 0:
                docs = results['documents'][0]
                metadatas = results['metadatas'][0] if results['metadatas'] else []
                distances = results['distances'][0] if results['distances'] else []
                
                logger.info(f"üìã –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º {len(docs)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, {len(metadatas)} –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö, {len(distances)} —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π")
                
                for i, content in enumerate(docs):
                    # ChromaDB –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ (—á–µ–º –º–µ–Ω—å—à–µ, —Ç–µ–º –ª—É—á—à–µ)
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å—Ö–æ–¥—Å—Ç–≤–æ (—á–µ–º –±–æ–ª—å—à–µ, —Ç–µ–º –ª—É—á—à–µ)
                    distance = distances[i] if i < len(distances) else 1.0
                    # –î–ª—è –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è: similarity = 1 - distance
                    # –ù–æ ChromaDB –º–æ–∂–µ—Ç –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ç–∏–ø—ã —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
                    if distance <= 1.0:
                        similarity = 1.0 - distance
                    else:
                        # –î–ª—è –µ–≤–∫–ª–∏–¥–æ–≤–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥—Ä—É–≥—É—é —Ñ–æ—Ä–º—É–ª—É
                        similarity = 1.0 / (1.0 + distance)
                    
                    logger.info(f"üìÑ –î–æ–∫—É–º–µ–Ω—Ç {i+1}: similarity={similarity:.3f}, distance={distance:.3f}, content_length={len(content)}")
                    
                    if similarity >= min_similarity:
                        documents.append({
                            "content": content,
                            "metadata": metadatas[i] if i < len(metadatas) else {},
                            "similarity": similarity,
                            "distance": distance
                        })
                        logger.info(f"‚úÖ –î–æ–∫—É–º–µ–Ω—Ç {i+1} –ø—Ä–æ—à–µ–ª —Ñ–∏–ª—å—Ç—Ä –ø–æ —Å—Ö–æ–¥—Å—Ç–≤—É")
                    else:
                        logger.info(f"‚ùå –î–æ–∫—É–º–µ–Ω—Ç {i+1} –Ω–µ –ø—Ä–æ—à–µ–ª —Ñ–∏–ª—å—Ç—Ä –ø–æ —Å—Ö–æ–¥—Å—Ç–≤—É (similarity={similarity:.3f} < {min_similarity})")
            
            logger.info(f"üîç –ò—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏")
            return documents
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")
            return []
    
    async def get_document(self, document_id: str) -> Optional[Dict[str, Any]]:
        """–ü–æ–ª—É—á–∞–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –ø–æ ID"""
        if not self.is_ready():
            logger.warning("VectorStore –Ω–µ –≥–æ—Ç–æ–≤")
            return None
            
        try:
            results = self.collection.get(
                ids=[document_id],
                include=['documents', 'metadatas']
            )
            
            if results['documents'] and len(results['documents']) > 0:
                return {
                    "id": document_id,
                    "content": results['documents'][0],
                    "metadata": results['metadatas'][0] if results['metadatas'] else {}
                }
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ {document_id}: {e}")
            
        return None
    
    async def delete_document(self, document_id: str) -> bool:
        """–£–¥–∞–ª—è–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –ø–æ ID"""
        if not self.is_ready():
            logger.warning("VectorStore –Ω–µ –≥–æ—Ç–æ–≤")
            return False
            
        try:
            self.collection.delete(ids=[document_id])
            logger.info(f"üóëÔ∏è –î–æ–∫—É–º–µ–Ω—Ç —É–¥–∞–ª–µ–Ω: {document_id}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ {document_id}: {e}")
            return False
    
    async def clear_collection(self) -> bool:
        """–û—á–∏—â–∞–µ—Ç –≤—Å—é –∫–æ–ª–ª–µ–∫—Ü–∏—é"""
        if not self.is_ready():
            logger.warning("VectorStore –Ω–µ –≥–æ—Ç–æ–≤")
            return False
            
        try:
            # –£–¥–∞–ª—è–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é –∏ —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é
            self.client.delete_collection(name=self.collection_name)
            self.collection = self.client.create_collection(
                name=self.collection_name,
                metadata={"description": "–ö–æ–ª–ª–µ–∫—Ü–∏—è —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è RAG"}
            )
            logger.info("üóëÔ∏è –ö–æ–ª–ª–µ–∫—Ü–∏—è –æ—á–∏—â–µ–Ω–∞")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –∫–æ–ª–ª–µ–∫—Ü–∏–∏: {e}")
            return False

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–µ—Ä–≤–∏—Å–∞
vector_store_service = VectorStoreService()
