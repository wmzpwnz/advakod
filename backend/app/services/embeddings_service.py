"""
–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏ (–≤–µ–∫—Ç–æ—Ä–Ω—ã–º–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è–º–∏ —Ç–µ–∫—Å—Ç–∞)
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è RAG (Retrieval-Augmented Generation)
"""

import logging
import asyncio
from typing import List, Dict, Any, Optional
from sentence_transformers import SentenceTransformer
import numpy as np
import threading
import time

logger = logging.getLogger(__name__)

# Import enhanced embeddings service
from .enhanced_embeddings_service import enhanced_embeddings_service

# Re-export for backward compatibility
embeddings_service = enhanced_embeddings_service

# Keep original class for compatibility
class EmbeddingsService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
    
    def __init__(self):
        self.model = None
        self.model_name = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"  # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫
        self.is_loading = False
        self.load_error = None
        
    def _load_model_sync(self):
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ"""
        try:
            logger.info(f"üöÄ –ó–∞–≥—Ä—É–∂–∞–µ–º embeddings –º–æ–¥–µ–ª—å: {self.model_name}")
            start_time = time.time()
            
            # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å —Å —Ç–∞–π–º–∞—É—Ç–æ–º
            import requests
            requests.adapters.DEFAULT_RETRIES = 3
            
            self.model = SentenceTransformer(self.model_name)
            
            load_time = time.time() - start_time
            logger.info(f"‚úÖ Embeddings –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∑–∞ {load_time:.2f} —Å–µ–∫—É–Ω–¥")
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å
            test_text = "–¢–µ—Å—Ç embeddings –º–æ–¥–µ–ª–∏"
            test_embedding = self.model.encode(test_text)
            logger.info(f"‚úÖ –¢–µ—Å—Ç –ø—Ä–æ—à–µ–ª —É—Å–ø–µ—à–Ω–æ. –†–∞–∑–º–µ—Ä –≤–µ–∫—Ç–æ—Ä–∞: {len(test_embedding)}")
            
        except Exception as e:
            self.load_error = str(e)
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ embeddings –º–æ–¥–µ–ª–∏: {e}")
            logger.info("üîÑ –ü—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —É–ø—Ä–æ—â–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å...")
            
            try:
                # –ü—Ä–æ–±—É–µ–º –±–æ–ª–µ–µ –ø—Ä–æ—Å—Ç—É—é –º–æ–¥–µ–ª—å
                self.model_name = "sentence-transformers/all-MiniLM-L6-v2"
                self.model = SentenceTransformer(self.model_name)
                logger.info(f"‚úÖ –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {self.model_name}")
            except Exception as e2:
                logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–∂–µ —É–ø—Ä–æ—â–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å: {e2}")
        finally:
            self.is_loading = False
    
    def load_model(self):
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏"""
        if self.model is not None:
            logger.info("Embeddings –º–æ–¥–µ–ª—å —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            return
            
        if self.is_loading:
            logger.info("Embeddings –º–æ–¥–µ–ª—å —É–∂–µ –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è...")
            return
            
        self.is_loading = True
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ
        self._load_model_sync()
    
    def is_ready(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –≥–æ—Ç–æ–≤–∞ –ª–∏ –º–æ–¥–µ–ª—å –∫ —Ä–∞–±–æ—Ç–µ"""
        return self.model is not None and not self.is_loading
    
    def get_status(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç—É—Å —Å–µ—Ä–≤–∏—Å–∞"""
        return {
            "model_loaded": self.model is not None,
            "is_loading": self.is_loading,
            "load_error": self.load_error,
            "model_name": self.model_name
        }
    
    async def encode_text(self, text: str) -> Optional[List[float]]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"""
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏
        if not self.is_ready():
            logger.info("üîÑ Embeddings –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞, –∑–∞–≥—Ä—É–∂–∞–µ–º –ø–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—é...")
            self.load_model()
        
        if not self.is_ready():
            logger.warning("Embeddings –º–æ–¥–µ–ª—å –Ω–µ –≥–æ—Ç–æ–≤–∞")
            return None
            
        try:
            # –í—ã–ø–æ–ª–Ω—è–µ–º –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ, —á—Ç–æ–±—ã –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å event loop
            loop = asyncio.get_event_loop()
            embedding = await loop.run_in_executor(
                None, 
                self.model.encode, 
                text
            )
            return embedding.tolist()
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {e}")
            return None
    
    async def encode_texts(self, texts: List[str]) -> List[Optional[List[float]]]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è —Å–ø–∏—Å–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤"""
        if not self.is_ready():
            logger.warning("Embeddings –º–æ–¥–µ–ª—å –Ω–µ –≥–æ—Ç–æ–≤–∞")
            return [None] * len(texts)
            
        try:
            # –í—ã–ø–æ–ª–Ω—è–µ–º –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
            loop = asyncio.get_event_loop()
            embeddings = await loop.run_in_executor(
                None, 
                self.model.encode, 
                texts
            )
            return [emb.tolist() for emb in embeddings]
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {e}")
            return [None] * len(texts)
    
    def calculate_similarity(self, embedding1: List[float], embedding2: List[float]) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –º–µ–∂–¥—É –¥–≤—É–º—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏"""
        try:
            vec1 = np.array(embedding1)
            vec2 = np.array(embedding2)
            
            # –ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
            dot_product = np.dot(vec1, vec2)
            norm1 = np.linalg.norm(vec1)
            norm2 = np.linalg.norm(vec2)
            
            if norm1 == 0 or norm2 == 0:
                return 0.0
                
            similarity = dot_product / (norm1 * norm2)
            return float(similarity)
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Å—Ö–æ–¥—Å—Ç–≤–∞: {e}")
            return 0.0

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–µ—Ä–≤–∏—Å–∞
embeddings_service = EmbeddingsService()
