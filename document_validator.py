#!/usr/bin/env python3
"""
–í–∞–ª–∏–¥–∞—Ç–æ—Ä –ø—Ä–∞–≤–æ–≤—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç –ø—Ä–∞–≤–æ–≤—ã–º –∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–º –¥–ª—è RAG —Å–∏—Å—Ç–µ–º—ã
"""

import re
import json
import os
from datetime import datetime
from pathlib import Path

class DocumentValidator:
    """–í–∞–ª–∏–¥–∞—Ç–æ—Ä –ø—Ä–∞–≤–æ–≤—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    
    def __init__(self, output_dir="/root/advakod/validation_results"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # –°–æ–∑–¥–∞–µ–º –ø–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        (self.output_dir / "valid_documents").mkdir(exist_ok=True)
        (self.output_dir / "invalid_documents").mkdir(exist_ok=True)
        (self.output_dir / "reports").mkdir(exist_ok=True)
        (self.output_dir / "logs").mkdir(exist_ok=True)
        
        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø—Ä–∞–≤–æ–≤—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        self.legal_keywords = [
            # –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–∞–≤–æ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã
            '—Å—Ç–∞—Ç—å—è', '–≥–ª–∞–≤–∞', '—Ä–∞–∑–¥–µ–ª', '—á–∞—Å—Ç—å', '–ø—É–Ω–∫—Ç', '–ø–æ–¥–ø—É–Ω–∫—Ç',
            '–∫–æ–¥–µ–∫—Å', '–∑–∞–∫–æ–Ω', '—É–∫–∞–∑', '–ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ', '—Ä–∞—Å–ø–æ—Ä—è–∂–µ–Ω–∏–µ',
            '–ø—Ä–∏–∫–∞–∑', '–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è', '–ø–æ–ª–æ–∂–µ–Ω–∏–µ', '–ø—Ä–∞–≤–∏–ª–∞', '—Ä–µ–≥–ª–∞–º–µ–Ω—Ç',
            
            # –ü—Ä–∞–≤–æ–≤—ã–µ –æ–±–ª–∞—Å—Ç–∏
            '–≥—Ä–∞–∂–¥–∞–Ω—Å–∫–∏–π', '—É–≥–æ–ª–æ–≤–Ω—ã–π', '–∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω—ã–π', '—Ç—Ä—É–¥–æ–≤–æ–π',
            '–Ω–∞–ª–æ–≥–æ–≤—ã–π', '—Å–µ–º–µ–π–Ω—ã–π', '–∂–∏–ª–∏—â–Ω—ã–π', '–∑–µ–º–µ–ª—å–Ω—ã–π', '–≤–æ–¥–Ω—ã–π',
            '–ª–µ—Å–Ω–æ–π', '–≤–æ–∑–¥—É—à–Ω—ã–π', '—Ç–∞–º–æ–∂–µ–Ω–Ω—ã–π', '–±—é–¥–∂–µ—Ç–Ω—ã–π',
            '–∞—Ä–±–∏—Ç—Ä–∞–∂–Ω—ã–π', '–ø—Ä–æ—Ü–µ—Å—Å—É–∞–ª—å–Ω—ã–π', '–∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π',
            
            # –ü—Ä–∞–≤–æ–≤—ã–µ —Å—É–±—ä–µ–∫—Ç—ã
            '—Ä–æ—Å—Å–∏–π—Å–∫–∞—è —Ñ–µ–¥–µ—Ä–∞—Ü–∏—è', '—Ä—Ñ', '–≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–æ', '–æ—Ä–≥–∞–Ω',
            '–º–∏–Ω–∏—Å—Ç–µ—Ä—Å—Ç–≤–æ', '–≤–µ–¥–æ–º—Å—Ç–≤–æ', '—Å–ª—É–∂–±–∞', '–∞–≥–µ–Ω—Ç—Å—Ç–≤–æ',
            '—Å—É–¥', '–ø—Ä–æ–∫—É—Ä–∞—Ç—É—Ä–∞', '–ø–æ–ª–∏—Ü–∏—è', '–Ω–∞–ª–æ–≥–æ–≤–∞—è',
            
            # –ü—Ä–∞–≤–æ–≤—ã–µ –¥–µ–π—Å—Ç–≤–∏—è
            '–ø—Ä–∞–≤–æ', '–æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç—å', '–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å', '–Ω–∞—Ä—É—à–µ–Ω–∏–µ',
            '–ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏–µ', '–ø—Ä–∞–≤–æ–Ω–∞—Ä—É—à–µ–Ω–∏–µ', '—Å–∞–Ω–∫—Ü–∏—è', '–Ω–∞–∫–∞–∑–∞–Ω–∏–µ',
            '—à—Ç—Ä–∞—Ñ', '–ª–∏—à–µ–Ω–∏–µ', '–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ', '–ø—Ä–∏–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ'
        ]
        
        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è (–Ω–µ–ø—Ä–∞–≤–æ–≤—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã)
        self.exclusion_keywords = [
            '–Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ', '–æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ', '–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏–µ', '–ø–æ–æ—â—Ä–µ–Ω–∏–µ',
            '–ø–æ–∑–¥—Ä–∞–≤–ª–µ–Ω–∏–µ', '–ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ', '–±–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç—å', '—Å–æ–±–æ–ª–µ–∑–Ω–æ–≤–∞–Ω–∏–µ',
            '—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ', '—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–µ', '–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–∏',
            '—Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è', '–∫–∞—Ç–∞–ª–æ–≥', '–ø—Ä–µ–π—Å–∫—É—Ä–∞–Ω—Ç', '—Ç–∞—Ä–∏—Ñ',
            '—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ', '–≥—Ä–∞—Ñ–∏–∫ —Ä–∞–±–æ—Ç—ã', '–º–µ–Ω—é', '—Ä–µ—Ü–µ–ø—Ç'
        ]
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        self.document_patterns = {
            'federal_law': r'—Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–π –∑–∞–∫–æ–Ω|—Ñ–∑|‚Ññ\s*\d+',
            'presidential_decree': r'—É–∫–∞–∑ –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç–∞|—É–∫–∞–∑–æ–º –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç–∞',
            'government_resolution': r'–ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞|–ø–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ–º –ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞',
            'ministerial_order': r'–ø—Ä–∏–∫–∞–∑ –º–∏–Ω–∏—Å—Ç–µ—Ä—Å—Ç–≤–∞|–ø—Ä–∏–∫–∞–∑–æ–º –º–∏–Ω–∏—Å—Ç–µ—Ä—Å—Ç–≤–∞',
            'codex': r'–∫–æ–¥–µ–∫—Å|–∫–æ–¥–µ–∫—Å–∞|–∫–æ–¥–µ–∫—Å–æ–º',
            'constitution': r'–∫–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏—è|–∫–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–∏|–∫–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏–µ–π',
            'regulation': r'–ø–æ–ª–æ–∂–µ–Ω–∏–µ|–ø–æ–ª–æ–∂–µ–Ω–∏—è|–ø–æ–ª–æ–∂–µ–Ω–∏–µ–º',
            'instruction': r'–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è|–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏|–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–µ–π'
        }
        
        self.validation_results = []
        
        print(f"‚úÖ DocumentValidator –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        print(f"üìÅ –í—ã—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {self.output_dir}")
    
    def log(self, message, level="INFO"):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ"""
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        log_message = f"[{timestamp}] [{level}] {message}"
        print(log_message)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
        log_file = self.output_dir / "logs" / f"validator_{datetime.now().strftime('%Y%m%d')}.log"
        with open(log_file, 'a', encoding='utf-8') as f:
            f.write(log_message + "\n")
    
    def extract_text_from_html(self, html_content):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ HTML"""
        # –£–¥–∞–ª—è–µ–º HTML —Ç–µ–≥–∏
        text = re.sub(r'<[^>]+>', ' ', html_content)
        
        # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
        text = re.sub(r'\s+', ' ', text)
        
        # –£–¥–∞–ª—è–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
        text = re.sub(r'[^\w\s\-\.\,\:\;\(\)\[\]\"\'‚Ññ]', ' ', text)
        
        return text.strip()
    
    def extract_text_from_pdf(self, pdf_path):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ PDF (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)"""
        try:
            # –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã, —á–∏—Ç–∞–µ–º –∫–∞–∫ –±–∏–Ω–∞—Ä–Ω—ã–π —Ñ–∞–π–ª –∏ –∏—â–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
            with open(pdf_path, 'rb') as f:
                content = f.read()
            
            # –ü—ã—Ç–∞–µ–º—Å—è –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∫ —Ç–µ–∫—Å—Ç (—Ä–∞–±–æ—Ç–∞–µ—Ç –¥–ª—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö PDF)
            try:
                text = content.decode('utf-8', errors='ignore')
                # –û—á–∏—â–∞–µ–º –æ—Ç –±–∏–Ω–∞—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                text = re.sub(r'[^\x20-\x7E\u0400-\u04FF]', ' ', text)
                text = re.sub(r'\s+', ' ', text)
                return text.strip()
            except:
                return ""
                
        except Exception as e:
            self.log(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è PDF {pdf_path}: {e}", "ERROR")
            return ""
    
    def calculate_legal_score(self, text):
        """–í—ã—á–∏—Å–ª—è–µ—Ç –æ—Ü–µ–Ω–∫—É –ø—Ä–∞–≤–æ–≤–æ—Å—Ç–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        if not text:
            return 0
        
        text_lower = text.lower()
        score = 0
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–∞–≤–æ–≤—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        for keyword in self.legal_keywords:
            count = len(re.findall(r'\b' + re.escape(keyword) + r'\b', text_lower))
            score += count * 2  # –ö–∞–∂–¥–æ–µ –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ –¥–∞–µ—Ç 2 –±–∞–ª–ª–∞
        
        # –®—Ç—Ä–∞—Ñ—ã –∑–∞ –∏—Å–∫–ª—é—á–∞—é—â–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        for keyword in self.exclusion_keywords:
            count = len(re.findall(r'\b' + re.escape(keyword) + r'\b', text_lower))
            score -= count * 3  # –ö–∞–∂–¥–æ–µ –∏—Å–∫–ª—é—á–∞—é—â–µ–µ —Å–ª–æ–≤–æ –æ—Ç–Ω–∏–º–∞–µ—Ç 3 –±–∞–ª–ª–∞
        
        # –ë–æ–Ω—É—Å—ã –∑–∞ –ø—Ä–∞–≤–æ–≤—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        for pattern_name, pattern in self.document_patterns.items():
            if re.search(pattern, text_lower):
                score += 10  # –ö–∞–∂–¥—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω –¥–∞–µ—Ç 10 –±–∞–ª–ª–æ–≤
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –æ—Ü–µ–Ω–∫—É –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –¥–ª–∏–Ω—ã —Ç–µ–∫—Å—Ç–∞
        text_length = len(text.split())
        if text_length > 0:
            score = (score / text_length) * 100
        
        return max(0, min(100, score))  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –æ—Ç 0 –¥–æ 100
    
    def determine_document_type(self, text):
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        if not text:
            return "unknown"
        
        text_lower = text.lower()
        type_scores = {}
        
        for doc_type, pattern in self.document_patterns.items():
            matches = len(re.findall(pattern, text_lower))
            type_scores[doc_type] = matches
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–∏–ø —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
        if type_scores:
            best_type = max(type_scores, key=type_scores.get)
            if type_scores[best_type] > 0:
                return best_type
        
        return "general_legal"
    
    def validate_document(self, file_path, content=None):
        """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç"""
        file_path = Path(file_path)
        
        self.log(f"üîç –í–∞–ª–∏–¥–∏—Ä—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç: {file_path.name}")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞
        if file_path.suffix.lower() == '.pdf':
            text = self.extract_text_from_pdf(file_path)
        elif file_path.suffix.lower() in ['.html', '.htm']:
            if content:
                text = self.extract_text_from_html(content)
            else:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    html_content = f.read()
                text = self.extract_text_from_html(html_content)
        else:
            # –î–ª—è –¥—Ä—É–≥–∏—Ö —Ç–∏–ø–æ–≤ —Ñ–∞–π–ª–æ–≤ –ø—ã—Ç–∞–µ–º—Å—è —á–∏—Ç–∞—Ç—å –∫–∞–∫ —Ç–µ–∫—Å—Ç
            try:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    text = f.read()
            except:
                text = ""
        
        # –í—ã—á–∏—Å–ª—è–µ–º –æ—Ü–µ–Ω–∫—É –ø—Ä–∞–≤–æ–≤–æ—Å—Ç–∏
        legal_score = self.calculate_legal_score(text)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞
        doc_type = self.determine_document_type(text)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç –≤–∞–ª–∏–¥–Ω—ã–º
        is_valid = legal_score >= 30  # –ü–æ—Ä–æ–≥ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏
        
        # –°–æ–∑–¥–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        validation_result = {
            'file_path': str(file_path),
            'file_name': file_path.name,
            'file_size': file_path.stat().st_size if file_path.exists() else 0,
            'legal_score': legal_score,
            'document_type': doc_type,
            'is_valid': is_valid,
            'text_length': len(text),
            'validation_timestamp': datetime.now().isoformat(),
            'recommendations': self.get_recommendations(legal_score, doc_type)
        }
        
        self.validation_results.append(validation_result)
        
        # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        status = "‚úÖ –í–ê–õ–ò–î–ï–ù" if is_valid else "‚ùå –ù–ï–í–ê–õ–ò–î–ï–ù"
        self.log(f"{status} {file_path.name} (–æ—Ü–µ–Ω–∫–∞: {legal_score:.1f}, —Ç–∏–ø: {doc_type})")
        
        return validation_result
    
    def get_recommendations(self, legal_score, doc_type):
        """–ü–æ–ª—É—á–∞–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç—É"""
        recommendations = []
        
        if legal_score >= 70:
            recommendations.append("–û—Ç–ª–∏—á–Ω—ã–π –ø—Ä–∞–≤–æ–≤–æ–π –¥–æ–∫—É–º–µ–Ω—Ç, —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è RAG")
        elif legal_score >= 50:
            recommendations.append("–•–æ—Ä–æ—à–∏–π –ø—Ä–∞–≤–æ–≤–æ–π –¥–æ–∫—É–º–µ–Ω—Ç, –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è RAG")
        elif legal_score >= 30:
            recommendations.append("–°–ª–∞–±—ã–π –ø—Ä–∞–≤–æ–≤–æ–π –¥–æ–∫—É–º–µ–Ω—Ç, —Ç—Ä–µ–±—É–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏")
        else:
            recommendations.append("–ù–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è RAG —Å–∏—Å—Ç–µ–º—ã")
        
        if doc_type == "codex":
            recommendations.append("–ö–æ–¥–µ–∫—Å - –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç")
        elif doc_type == "federal_law":
            recommendations.append("–§–µ–¥–µ—Ä–∞–ª—å–Ω—ã–π –∑–∞–∫–æ–Ω - –≤–∞–∂–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç")
        elif doc_type == "constitution":
            recommendations.append("–ö–æ–Ω—Å—Ç–∏—Ç—É—Ü–∏—è - –±–∞–∑–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç")
        
        return recommendations
    
    def validate_directory(self, directory_path):
        """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"""
        directory_path = Path(directory_path)
        
        if not directory_path.exists():
            self.log(f"‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {directory_path}", "ERROR")
            return []
        
        self.log(f"üìÅ –í–∞–ª–∏–¥–∏—Ä—É–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é: {directory_path}")
        
        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —Ñ–∞–π–ª—ã
        file_extensions = ['.pdf', '.html', '.htm', '.txt', '.doc', '.docx']
        files = []
        
        for ext in file_extensions:
            files.extend(directory_path.glob(f"**/*{ext}"))
        
        self.log(f"üìÑ –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {len(files)}")
        
        # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π —Ñ–∞–π–ª
        for i, file_path in enumerate(files, 1):
            self.log(f"üîç –í–∞–ª–∏–¥–∏—Ä—É–µ–º —Ñ–∞–π–ª {i}/{len(files)}: {file_path.name}")
            self.validate_document(file_path)
        
        return self.validation_results
    
    def save_validation_report(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ—Ç—á–µ—Ç –æ –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
        if not self.validation_results:
            self.log("‚ö†Ô∏è –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è", "WARNING")
            return None
        
        # –°–æ–∑–¥–∞–µ–º —Å–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç
        total_files = len(self.validation_results)
        valid_files = len([r for r in self.validation_results if r['is_valid']])
        invalid_files = total_files - valid_files
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ç–∏–ø–∞–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        doc_types = {}
        for result in self.validation_results:
            doc_type = result['document_type']
            if doc_type not in doc_types:
                doc_types[doc_type] = {'count': 0, 'valid': 0, 'avg_score': 0}
            doc_types[doc_type]['count'] += 1
            if result['is_valid']:
                doc_types[doc_type]['valid'] += 1
            doc_types[doc_type]['avg_score'] += result['legal_score']
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ –æ—Ü–µ–Ω–∫–∏
        for doc_type in doc_types:
            if doc_types[doc_type]['count'] > 0:
                doc_types[doc_type]['avg_score'] /= doc_types[doc_type]['count']
        
        report = {
            'timestamp': datetime.now().isoformat(),
            'summary': {
                'total_files': total_files,
                'valid_files': valid_files,
                'invalid_files': invalid_files,
                'validation_rate': (valid_files / total_files * 100) if total_files > 0 else 0
            },
            'document_types': doc_types,
            'detailed_results': self.validation_results
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_file = self.output_dir / "reports" / f"validation_report_{timestamp}.json"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        self.log(f"üìä –û—Ç—á–µ—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_file}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–∞–ª–∏–¥–Ω—ã–µ –∏ –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –æ—Ç–¥–µ–ª—å–Ω–æ
        valid_file = self.output_dir / "reports" / f"valid_documents_{timestamp}.json"
        invalid_file = self.output_dir / "reports" / f"invalid_documents_{timestamp}.json"
        
        valid_docs = [r for r in self.validation_results if r['is_valid']]
        invalid_docs = [r for r in self.validation_results if not r['is_valid']]
        
        with open(valid_file, 'w', encoding='utf-8') as f:
            json.dump(valid_docs, f, ensure_ascii=False, indent=2)
        
        with open(invalid_file, 'w', encoding='utf-8') as f:
            json.dump(invalid_docs, f, ensure_ascii=False, indent=2)
        
        return report

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üöÄ –ó–∞–ø—É—Å–∫ –≤–∞–ª–∏–¥–∞—Ç–æ—Ä–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    print("=" * 50)
    
    validator = DocumentValidator()
    
    # –í–∞–ª–∏–¥–∏—Ä—É–µ–º —Å–∫–∞—á–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
    downloaded_dir = "/root/advakod/downloaded_documents"
    if Path(downloaded_dir).exists():
        validator.validate_directory(downloaded_dir)
    else:
        print(f"‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {downloaded_dir}")
        return
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
    report = validator.save_validation_report()
    
    if report:
        print(f"\nüìä –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢ –í–ê–õ–ò–î–ê–¶–ò–ò:")
        print(f"   üìÑ –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {report['summary']['total_files']}")
        print(f"   ‚úÖ –í–∞–ª–∏–¥–Ω—ã—Ö: {report['summary']['valid_files']}")
        print(f"   ‚ùå –ù–µ–≤–∞–ª–∏–¥–Ω—ã—Ö: {report['summary']['invalid_files']}")
        print(f"   üìä –ü—Ä–æ—Ü–µ–Ω—Ç –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏: {report['summary']['validation_rate']:.1f}%")
        
        if report['document_types']:
            print(f"\nüìã –¢–ò–ü–´ –î–û–ö–£–ú–ï–ù–¢–û–í:")
            for doc_type, stats in report['document_types'].items():
                print(f"   ‚Ä¢ {doc_type}: {stats['count']} —Ñ–∞–π–ª–æ–≤ (–≤–∞–ª–∏–¥–Ω—ã—Ö: {stats['valid']}, —Å—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞: {stats['avg_score']:.1f})")
    
    print(f"\nüéâ –í–∞–ª–∏–¥–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")

if __name__ == "__main__":
    main()

